{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0227457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import centralized as CP\n",
    "import davisyin as DY\n",
    "import admm as admm\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from numpy import linalg as LA\n",
    "from numpy.linalg import inv\n",
    "import matplotlib as plt\n",
    "from matplotlib import rc\n",
    "# Configura el tipo de letra globalmente\n",
    "rc('font', **{'family': 'serif', 'serif': ['Computer Modern Roman']})\n",
    "rc('text', usetex=True)\n",
    "#plt.rcParams['text.usetex'] = True\n",
    "import matplotlib.pyplot as plt\n",
    "import proyecciones as pro\n",
    "import time\n",
    "import briceno as BA\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.2f}\".format(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d1d966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.18, 0.02, 0.34, 0.13, 0.20, 0.13]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Caso 1: Caso base\n",
    "    \n",
    "# Cambiar criterio de parada por errores relativos.\n",
    "# Establecer la semilla\n",
    "seed = 40\n",
    "#41\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Seteamos los parámetros:\n",
    "N, M = 3, 6  # Son 2 tecnologías, 10 escenarios\n",
    "\n",
    "_g_ = 1\n",
    "\n",
    "# Probabilidades:\n",
    "inv_, mc_, voll_, d_ = [50.0,  1000.0, 10000.0, 1000.0]\n",
    "                       #[10.0, 2000.0, 10000.0, 1000.0]\n",
    "                       #[50.0,  1000.0, 10000.0, 1000.0]\n",
    "#Sigma = np.ones((1,M))\n",
    "Sigma = np.random.rand(1,M)\n",
    "Sigma /= Sigma.sum()\n",
    "Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1895a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      " [[5.0]\n",
      " [50.0]\n",
      " [95.0]]\n",
      "MC\n",
      " [[[1000.0 0.0 0.0]\n",
      "  [0.0 21000.0 0.0]\n",
      "  [0.0 0.0 41000.0]]\n",
      "\n",
      " [[900.0 0.0 0.0]\n",
      "  [0.0 20500.0 0.0]\n",
      "  [0.0 0.0 42000.0]]\n",
      "\n",
      " [[1200.0 0.0 0.0]\n",
      "  [0.0 22000.0 0.0]\n",
      "  [0.0 0.0 39000.0]]\n",
      "\n",
      " [[700.0 0.0 0.0]\n",
      "  [0.0 19500.0 0.0]\n",
      "  [0.0 0.0 44000.0]]\n",
      "\n",
      " [[1400.0 0.0 0.0]\n",
      "  [0.0 23000.0 0.0]\n",
      "  [0.0 0.0 37000.0]]\n",
      "\n",
      " [[88000.0 0.0 0.0]\n",
      "  [0.0 88000.0 0.0]\n",
      "  [0.0 0.0 88000.0]]]\n",
      "VOLL\n",
      " 10000.0\n",
      "D\n",
      " [[200.0 750.0 1000.0 1250.0 1500.0 4000.0]]\n",
      "frobenius_norm: 595.1406870090601\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.1f}\".format(x)})\n",
    "Times = {}\n",
    "r_ = 1\n",
    "\n",
    "\n",
    "# Parámetros funciones:\n",
    "I    = (inv_ * np.ones((N, 1)) + r_*np.array([[-45], [0], [45]])) / _g_\n",
    "print(\"I\\n\",I)\n",
    "aux  = np.array([1/ _g_ + r_*20*i/ _g_ for i in range(N)])\n",
    "\n",
    "mc_11 = 100\n",
    "mc_22 = 500\n",
    "mc_33 = 1000\n",
    "MC   = (np.array([np.diag(mc_*aux/_g_ + r_*np.array([((-1)**m)*mc_11*m/_g_, ((-1)**m)*mc_22*m/_g_, ((-1)**(m+1))*mc_33*m/_g_]))/ _g_ for m in range(M)])) \n",
    "MC[-1]=(np.array([[1,0,0],[0,1,0],[0,0,1]])*88000) / _g_\n",
    "print(\"MC\\n\",MC)\n",
    "\n",
    "MC_pyomo = np.array([mc_*aux + r_*np.array([((-1)**m)*mc_11*m, ((-1)**m)*mc_22*m, ((-1)**(m+1))*mc_33*m]) for m in range(M)]).T.tolist()\n",
    "for i in range(N):\n",
    "    MC_pyomo[i][-1] = MC[-1][i][i]\n",
    "MC_pyomo\n",
    "\n",
    "VOLL = voll_ / _g_\n",
    "print(\"VOLL\\n\",VOLL)\n",
    "D    = (d_*np.ones((1,M)) + r_*np.array([-800, -250, 0, 250, 500, 3000])[np.newaxis])/ _g_\n",
    "print(\"D\\n\",D)\n",
    "\n",
    "e_ = 0\n",
    "\n",
    "e1  = e_\n",
    "e2  = e_\n",
    "e31 = e_*1e2/2\n",
    "e32 = e_\n",
    "\n",
    "Q1, B1 = np.zeros((N,N)), I\n",
    "Q2, B2 = 0.01*MC, np.zeros((N,M))\n",
    "Q3, B3 = np.zeros((1,M)), VOLL*np.ones((1,M))\n",
    "\n",
    "\n",
    "frobenius_norm = (e1+e2)*np.sqrt(N)+e31+e32+np.array([LA.norm(np.einsum('i,ikl->ikl',Sigma[0],0.01*MC)[xi], 'fro') for xi in range(M)]).sum()\n",
    "#frobenius_norm = max([e1*np.sqrt(N),e31+e32,e2*np.sqrt(N)+np.array([LA.norm(np.einsum('i,ikl->ikl',Sigma[0],0.01*MC)[xi], 'fro') for xi in range(M)]).sum()])\n",
    "print(\"frobenius_norm:\",frobenius_norm)\n",
    "\n",
    "def Grad_Phi_1(x1, Q_1 = np.zeros((N,N)), B_1 = I, e1 = e1, N = N):\n",
    "       return np.dot(Q_1,x1)+B_1# - e1*np.dot(np.identity(N),np.maximum(-x1,0))\n",
    "\n",
    "\n",
    "def Grad_Phi_2(x2, Q_2 = 0.01*MC, B_2 = np.zeros((N,M)), e2 = e2, N = N, M = M):\n",
    "\n",
    "    return np.einsum('ijk,ki->ji', Q_2, x2)+B_2# - e2*np.einsum('ijk,ki->ji', np.array([np.diag(np.ones(N)) for m in range(M)]), np.maximum(-x2,0))\n",
    "\n",
    "\n",
    "def Grad_Phi_3(x3, Q_3 = np.zeros((1,M)), B_3 = VOLL*np.ones((1,M)), D=D, e31=e31, e32= e32, M = M):\n",
    "    return Q_3*x3+B_3 #- e31*np.dot(np.maximum(-x3,0),np.identity(M)) - e32*np.dot(np.maximum(-D+x3,0),np.identity(M))\n",
    "\n",
    "\n",
    "def Grad_Phi(x1,x2,x3, P = Sigma):\n",
    "    return Grad_Phi_1(x1), P*Grad_Phi_2(x2), P*Grad_Phi_3(x3)\n",
    "\n",
    "def Grad_Phi_NA(x1,x2,x3, P = Sigma):\n",
    "    return P*Grad_Phi_1(x1), P*Grad_Phi_2(x2), P*Grad_Phi_3(x3)\n",
    "\n",
    "def Phi_1(x1, Q_1 = np.zeros((N,N)), B_1 = I, C_1 = 0.0, e1 = e1):\n",
    "    return 0.5*np.einsum('ij,ji -> i', x1.T,np.dot(Q_1,x1))[:,np.newaxis]+np.dot(x1.T, B_1)+C_1 + e1/2*LA.norm(np.maximum(-x1.flatten(),0))**2\n",
    "\n",
    "def Phi_2_xi(x2, Q_2 = 0.01*MC, B_2 = np.zeros((N,M)), C_2 = np.zeros((M, 1))):\n",
    "    return 0.5*np.einsum('ij,ji -> i', x2.T, np.einsum('ijk,ki -> ji', Q_2, x2))[:,np.newaxis]+np.einsum('ij,ji->i',x2.T,B_2)[:,np.newaxis]+C_2 + e2/2*LA.norm(np.maximum(-x2.flatten(),0))**2\n",
    "\n",
    "def Phi_3_xi(x3, Q_3 = np.zeros((1,M)), B_3 = VOLL*np.ones((1,M)), C_3 = -VOLL*D ):\n",
    "    return (0.5*x3*Q_3*x3+B_3*x3+C_3).T + e31/2*LA.norm(np.maximum(-x3.flatten(),0))**2 + e32/2*LA.norm(np.maximum((D-x3).flatten(),0))**2\n",
    "\n",
    "\n",
    "def objective_function(x1, x2, x3, P = Sigma, NA = True):\n",
    "\n",
    "# NA = True, cumple la funcion que si se impuso \n",
    "#      la condición de no anticipatividad para x1\n",
    "#      entonces, Phi_1(x1).shape == (M,1)\n",
    "    if NA:\n",
    "        return np.dot(P, Phi_1(x1) +Phi_2_xi(x2)+Phi_3_xi(x3))\n",
    "    else:\n",
    "        return Phi_1(x1)+ np.dot(P, Phi_2_xi(x2)+Phi_3_xi(x3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4f57c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp = time.time()\n",
    "x1, x2, x3, rho, mu = map(np.array, CP.modelo(Sigma, N, M, \\\n",
    "                                              parametros = [I.T[0].tolist(),\\\n",
    "                                                            MC_pyomo,\\\n",
    "                                                            VOLL,\\\n",
    "                                                            D[0]] , show = 0))\n",
    "fin = time.time()\n",
    "\n",
    "\n",
    "Times[\"CP\"] = fin - cp\n",
    "\n",
    "x1 = x1[:,np.newaxis]\n",
    "x2 = x2.T\n",
    "x3 = x3[np.newaxis,:][0]\n",
    "rho = rho[np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1265a4e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "primal:\n",
      "[[1188.2]\n",
      " [44.8]\n",
      " [25.7]]\n",
      "[[186.6 704.0 833.3 1188.2 714.3 11.4]\n",
      " [8.9 30.9 44.8 42.9 43.5 11.4]\n",
      " [4.6 15.1 25.6 19.0 25.7 11.4]]\n",
      "[[0.0 0.0 96.2 0.0 716.5 3965.9]]\n",
      "Dual:\n",
      "[[0.0 0.0 0.0 39.9 0.0 0.0]\n",
      " [0.0 0.0 145.4 0.0 0.0 0.0]\n",
      " [0.0 0.0 0.0 0.0 483.7 0.0]]\n",
      "[[1865.7 6336.1 10000.0 8357.0 10000.0 10000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"primal:\\n{x1}\\n{x2}\\n{x3}\")\n",
    "print(f\"Dual:\\n{mu}\\n{rho}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c84c5f51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beta: 0.0016802749699833185\n",
      "Gamma: 0.0031218162324379273\n",
      "Lambda_k: 1\n",
      "Iteration: 1 lambda_k: 1 Loss: 0.8310352033297772\n",
      "Iteration: 2 lambda_k: 1 Loss: 0.7073862252784012\n",
      "Iteration: 3 lambda_k: 1 Loss: 0.6279999442373778\n",
      "Iteration: 4 lambda_k: 1 Loss: 0.5762411807069783\n",
      "Iteration: 5 lambda_k: 1 Loss: 0.5498784584975096\n",
      "Iteration: 6 lambda_k: 1 Loss: 0.5316815468733749\n",
      "Iteration: 7 lambda_k: 1 Loss: 0.516868498733118\n",
      "Iteration: 8 lambda_k: 1 Loss: 0.5073995894005161\n",
      "Iteration: 9 lambda_k: 1 Loss: 0.5011011760404228\n",
      "Iteration: 10 lambda_k: 1 Loss: 0.4965083676440122\n",
      "Iteration: 11 lambda_k: 1 Loss: 0.4930361585580605\n",
      "Iteration: 12 lambda_k: 1 Loss: 0.4904892272916616\n",
      "Iteration: 13 lambda_k: 1 Loss: 0.48840373734393955\n",
      "Iteration: 14 lambda_k: 1 Loss: 0.48644188250347625\n",
      "Iteration: 15 lambda_k: 1 Loss: 0.48458791134431356\n",
      "Iteration: 16 lambda_k: 1 Loss: 0.4828285908045649\n",
      "Iteration: 17 lambda_k: 1 Loss: 0.4812012873159904\n",
      "Iteration: 18 lambda_k: 1 Loss: 0.4797652028790013\n",
      "Iteration: 19 lambda_k: 1 Loss: 0.4784107070493575\n",
      "Iteration: 20 lambda_k: 1 Loss: 0.47707120921904955\n",
      "Iteration: 21 lambda_k: 1 Loss: 0.47575536380071426\n",
      "Iteration: 22 lambda_k: 1 Loss: 0.47447467247513286\n",
      "Iteration: 23 lambda_k: 1 Loss: 0.47322912614308654\n",
      "Iteration: 24 lambda_k: 1 Loss: 0.47201430817719403\n",
      "Iteration: 25 lambda_k: 1 Loss: 0.4708264161145806\n",
      "Iteration: 26 lambda_k: 1 Loss: 0.46966291230678553\n",
      "Iteration: 27 lambda_k: 1 Loss: 0.46852188358680147\n",
      "Iteration: 28 lambda_k: 1 Loss: 0.4674016567155915\n",
      "Iteration: 29 lambda_k: 1 Loss: 0.46630073706071945\n",
      "Iteration: 30 lambda_k: 1 Loss: 0.46521783240890513\n",
      "Iteration: 31 lambda_k: 1 Loss: 0.46415185892722177\n",
      "Iteration: 32 lambda_k: 1 Loss: 0.46311022387840833\n",
      "Iteration: 33 lambda_k: 1 Loss: 0.46220275762241875\n",
      "Iteration: 34 lambda_k: 1 Loss: 0.46131277486195105\n",
      "Iteration: 35 lambda_k: 1 Loss: 0.46043900075074423\n",
      "Iteration: 36 lambda_k: 1 Loss: 0.4595916108316169\n",
      "Iteration: 37 lambda_k: 1 Loss: 0.4587987833777213\n",
      "Iteration: 38 lambda_k: 1 Loss: 0.45802637690277764\n",
      "Iteration: 39 lambda_k: 1 Loss: 0.4572630510785053\n",
      "Iteration: 40 lambda_k: 1 Loss: 0.45650918085801817\n",
      "Iteration: 41 lambda_k: 1 Loss: 0.455765466870404\n",
      "Iteration: 42 lambda_k: 1 Loss: 0.45503135235810593\n",
      "Iteration: 43 lambda_k: 1 Loss: 0.45430604264180174\n",
      "Iteration: 44 lambda_k: 1 Loss: 0.453588916239849\n",
      "Iteration: 45 lambda_k: 1 Loss: 0.45287947133795886\n",
      "Iteration: 46 lambda_k: 1 Loss: 0.4521772500055605\n",
      "Iteration: 47 lambda_k: 1 Loss: 0.45148182277461707\n",
      "Iteration: 48 lambda_k: 1 Loss: 0.4507927926030829\n",
      "Iteration: 49 lambda_k: 1 Loss: 0.4501097956236636\n",
      "Iteration: 50 lambda_k: 1 Loss: 0.4494324982831226\n",
      "Iteration: 51 lambda_k: 1 Loss: 0.4487605940577908\n",
      "Iteration: 52 lambda_k: 1 Loss: 0.4480938008209586\n",
      "Iteration: 53 lambda_k: 1 Loss: 0.4474318586233208\n",
      "Iteration: 54 lambda_k: 1 Loss: 0.4467745277764197\n",
      "Iteration: 55 lambda_k: 1 Loss: 0.4461215870933884\n",
      "Iteration: 56 lambda_k: 1 Loss: 0.4454728322910075\n",
      "Iteration: 57 lambda_k: 1 Loss: 0.44482807453866563\n",
      "Iteration: 58 lambda_k: 1 Loss: 0.44418713913653446\n",
      "Iteration: 59 lambda_k: 1 Loss: 0.44354986434085875\n",
      "Iteration: 60 lambda_k: 1 Loss: 0.44291610024896255\n",
      "Iteration: 61 lambda_k: 1 Loss: 0.4422857078376539\n",
      "Iteration: 62 lambda_k: 1 Loss: 0.44165855805414533\n",
      "Iteration: 63 lambda_k: 1 Loss: 0.4410345310087204\n",
      "Iteration: 64 lambda_k: 1 Loss: 0.44041351519982863\n",
      "Iteration: 65 lambda_k: 1 Loss: 0.4397954069191036\n",
      "Iteration: 66 lambda_k: 1 Loss: 0.43918010953299635\n",
      "Iteration: 67 lambda_k: 1 Loss: 0.43856753298013057\n",
      "Iteration: 68 lambda_k: 1 Loss: 0.43795759321468536\n",
      "Iteration: 69 lambda_k: 1 Loss: 0.4373502118070776\n",
      "Iteration: 70 lambda_k: 1 Loss: 0.4367453154273584\n",
      "Iteration: 71 lambda_k: 1 Loss: 0.436142835595979\n",
      "Iteration: 72 lambda_k: 1 Loss: 0.4355428237914712\n",
      "Iteration: 73 lambda_k: 1 Loss: 0.4349452833681091\n",
      "Iteration: 74 lambda_k: 1 Loss: 0.4343501261299609\n",
      "Iteration: 75 lambda_k: 1 Loss: 0.43375729222107495\n",
      "Iteration: 76 lambda_k: 1 Loss: 0.4331667212495714\n",
      "Iteration: 77 lambda_k: 1 Loss: 0.4325783544364432\n",
      "Iteration: 78 lambda_k: 1 Loss: 0.431992136343453\n",
      "Iteration: 79 lambda_k: 1 Loss: 0.4314080153584338\n",
      "Iteration: 80 lambda_k: 1 Loss: 0.4308259434043576\n",
      "Iteration: 81 lambda_k: 1 Loss: 0.4302458755050315\n",
      "Iteration: 82 lambda_k: 1 Loss: 0.42966776951101043\n",
      "Iteration: 83 lambda_k: 1 Loss: 0.42909158584782353\n",
      "Iteration: 84 lambda_k: 1 Loss: 0.42851728735693045\n",
      "Iteration: 85 lambda_k: 1 Loss: 0.4279448390927045\n",
      "Iteration: 86 lambda_k: 1 Loss: 0.42737420815965194\n",
      "Iteration: 87 lambda_k: 1 Loss: 0.42680536355815735\n",
      "Iteration: 88 lambda_k: 1 Loss: 0.42623827604724973\n",
      "Iteration: 89 lambda_k: 1 Loss: 0.42567291801125007\n",
      "Iteration: 90 lambda_k: 1 Loss: 0.42510926335254307\n",
      "Iteration: 91 lambda_k: 1 Loss: 0.42454728737905456\n",
      "Iteration: 92 lambda_k: 1 Loss: 0.42398696670798935\n",
      "Iteration: 93 lambda_k: 1 Loss: 0.42342827917574777\n",
      "Iteration: 94 lambda_k: 1 Loss: 0.42287120375252424\n",
      "Iteration: 95 lambda_k: 1 Loss: 0.4223157204756089\n",
      "Iteration: 96 lambda_k: 1 Loss: 0.42176181036544574\n",
      "Iteration: 97 lambda_k: 1 Loss: 0.42120945536866466\n",
      "Iteration: 98 lambda_k: 1 Loss: 0.4206586382961206\n",
      "Iteration: 99 lambda_k: 1 Loss: 0.42010934276706646\n",
      "Iteration: 100 lambda_k: 1 Loss: 0.41956155315739924\n",
      "Iteration: 101 lambda_k: 1 Loss: 0.41901525455165467\n",
      "Iteration: 102 lambda_k: 1 Loss: 0.41847043269837586\n",
      "Iteration: 103 lambda_k: 1 Loss: 0.41792707396885187\n",
      "Iteration: 104 lambda_k: 1 Loss: 0.4173851653183367\n",
      "Iteration: 105 lambda_k: 1 Loss: 0.4168446942502293\n",
      "Iteration: 106 lambda_k: 1 Loss: 0.416305648782643\n",
      "Iteration: 107 lambda_k: 1 Loss: 0.4157680174172061\n",
      "Iteration: 108 lambda_k: 1 Loss: 0.4152317891099542\n",
      "Iteration: 109 lambda_k: 1 Loss: 0.4146969532441586\n",
      "Iteration: 110 lambda_k: 1 Loss: 0.4141634996049467\n",
      "Iteration: 111 lambda_k: 1 Loss: 0.4136314183555791\n",
      "Iteration: 112 lambda_k: 1 Loss: 0.4131007000152658\n",
      "Iteration: 113 lambda_k: 1 Loss: 0.41257133543982644\n",
      "Iteration: 114 lambda_k: 1 Loss: 0.41204331579705555\n",
      "Iteration: 115 lambda_k: 1 Loss: 0.4115166325555858\n",
      "Iteration: 116 lambda_k: 1 Loss: 0.41099127746369013\n",
      "Iteration: 117 lambda_k: 1 Loss: 0.4104672425341678\n",
      "Iteration: 118 lambda_k: 1 Loss: 0.40994452002937487\n",
      "Iteration: 119 lambda_k: 1 Loss: 0.40942310244717506\n",
      "Iteration: 120 lambda_k: 1 Loss: 0.40890298250775664\n",
      "Iteration: 121 lambda_k: 1 Loss: 0.4083841531412555\n",
      "Iteration: 122 lambda_k: 1 Loss: 0.40786660747613557\n",
      "Iteration: 123 lambda_k: 1 Loss: 0.4073503388282761\n",
      "Iteration: 124 lambda_k: 1 Loss: 0.4068353406907195\n",
      "Iteration: 125 lambda_k: 1 Loss: 0.40632160672403705\n",
      "Iteration: 126 lambda_k: 1 Loss: 0.4058091307472744\n",
      "Iteration: 127 lambda_k: 1 Loss: 0.40529790672943683\n",
      "Iteration: 128 lambda_k: 1 Loss: 0.40478792878148323\n",
      "Iteration: 129 lambda_k: 1 Loss: 0.40427919114879507\n",
      "Iteration: 130 lambda_k: 1 Loss: 0.40377168820409093\n",
      "Iteration: 131 lambda_k: 1 Loss: 0.4032654144407591\n",
      "Iteration: 132 lambda_k: 1 Loss: 0.4027603644665819\n",
      "Iteration: 133 lambda_k: 1 Loss: 0.4022565329978286\n",
      "Iteration: 134 lambda_k: 1 Loss: 0.4017539148536918\n",
      "Iteration: 135 lambda_k: 1 Loss: 0.40125250495105075\n",
      "Iteration: 136 lambda_k: 1 Loss: 0.40075229829953607\n",
      "Iteration: 137 lambda_k: 1 Loss: 0.40025328999688264\n",
      "Iteration: 138 lambda_k: 1 Loss: 0.39975547522455046\n",
      "Iteration: 139 lambda_k: 1 Loss: 0.3992588492435975\n",
      "Iteration: 140 lambda_k: 1 Loss: 0.3987634073907908\n",
      "Iteration: 141 lambda_k: 1 Loss: 0.3982691450749412\n",
      "Iteration: 142 lambda_k: 1 Loss: 0.39777605777344804\n",
      "Iteration: 143 lambda_k: 1 Loss: 0.3972841410276136\n",
      "Iteration: 144 lambda_k: 1 Loss: 0.3967933904447848\n",
      "Iteration: 145 lambda_k: 1 Loss: 0.3963038016884082\n",
      "Iteration: 146 lambda_k: 1 Loss: 0.39581537048084053\n",
      "Iteration: 147 lambda_k: 1 Loss: 0.39532809259472584\n",
      "Iteration: 148 lambda_k: 1 Loss: 0.39484196385757486\n",
      "Iteration: 149 lambda_k: 1 Loss: 0.3943569801453472\n",
      "Iteration: 150 lambda_k: 1 Loss: 0.3938731373811381\n",
      "Iteration: 151 lambda_k: 1 Loss: 0.39339043153314407\n",
      "Iteration: 152 lambda_k: 1 Loss: 0.3929088586127399\n",
      "Iteration: 153 lambda_k: 1 Loss: 0.3924284146726577\n",
      "Iteration: 154 lambda_k: 1 Loss: 0.39194909580526627\n",
      "Iteration: 155 lambda_k: 1 Loss: 0.3914708981409467\n",
      "Iteration: 156 lambda_k: 1 Loss: 0.390993817846561\n",
      "Iteration: 157 lambda_k: 1 Loss: 0.390517851124002\n",
      "Iteration: 158 lambda_k: 1 Loss: 0.3900429942088263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 159 lambda_k: 1 Loss: 0.3895692433689621\n",
      "Iteration: 160 lambda_k: 1 Loss: 0.38909659490348875\n",
      "Iteration: 161 lambda_k: 1 Loss: 0.3886250451414834\n",
      "Iteration: 162 lambda_k: 1 Loss: 0.3881545904409313\n",
      "Iteration: 163 lambda_k: 1 Loss: 0.3876852271876959\n",
      "Iteration: 164 lambda_k: 1 Loss: 0.3872169517945448\n",
      "Iteration: 165 lambda_k: 1 Loss: 0.38674976070023004\n",
      "Iteration: 166 lambda_k: 1 Loss: 0.38628365036861767\n",
      "Iteration: 167 lambda_k: 1 Loss: 0.38581861728786476\n",
      "Iteration: 168 lambda_k: 1 Loss: 0.3853546579696416\n",
      "Iteration: 169 lambda_k: 1 Loss: 0.3848917689483953\n",
      "Iteration: 170 lambda_k: 1 Loss: 0.38442994678065373\n",
      "Iteration: 171 lambda_k: 1 Loss: 0.3839691880443666\n",
      "Iteration: 172 lambda_k: 1 Loss: 0.3835094893382817\n",
      "Iteration: 173 lambda_k: 1 Loss: 0.38305084728135563\n",
      "Iteration: 174 lambda_k: 1 Loss: 0.382593258512194\n",
      "Iteration: 175 lambda_k: 1 Loss: 0.3821367196885231\n",
      "Iteration: 176 lambda_k: 1 Loss: 0.381681227486689\n",
      "Iteration: 177 lambda_k: 1 Loss: 0.38122677860118254\n",
      "Iteration: 178 lambda_k: 1 Loss: 0.3807733697441905\n",
      "Iteration: 179 lambda_k: 1 Loss: 0.38032099764516775\n",
      "Iteration: 180 lambda_k: 1 Loss: 0.37986965905043635\n",
      "Iteration: 181 lambda_k: 1 Loss: 0.37941935072280103\n",
      "Iteration: 182 lambda_k: 1 Loss: 0.3789700694411855\n",
      "Iteration: 183 lambda_k: 1 Loss: 0.3785218120002877\n",
      "Iteration: 184 lambda_k: 1 Loss: 0.3780745752102544\n",
      "Iteration: 185 lambda_k: 1 Loss: 0.37762835589637017\n",
      "Iteration: 186 lambda_k: 1 Loss: 0.37718315089876236\n",
      "Iteration: 187 lambda_k: 1 Loss: 0.3767389570721222\n",
      "Iteration: 188 lambda_k: 1 Loss: 0.3762957712854382\n",
      "Iteration: 189 lambda_k: 1 Loss: 0.37585359042174377\n",
      "Iteration: 190 lambda_k: 1 Loss: 0.3754124113778769\n",
      "Iteration: 191 lambda_k: 1 Loss: 0.37497223106425154\n",
      "Iteration: 192 lambda_k: 1 Loss: 0.37453304640464047\n",
      "Iteration: 193 lambda_k: 1 Loss: 0.37409485433596795\n",
      "Iteration: 194 lambda_k: 1 Loss: 0.37365765180811256\n",
      "Iteration: 195 lambda_k: 1 Loss: 0.37322143578371975\n",
      "Iteration: 196 lambda_k: 1 Loss: 0.3727862032380224\n",
      "Iteration: 197 lambda_k: 1 Loss: 0.37235195115867026\n",
      "Iteration: 198 lambda_k: 1 Loss: 0.3719186765455669\n",
      "Iteration: 199 lambda_k: 1 Loss: 0.37148637641071414\n",
      "Iteration: 200 lambda_k: 1 Loss: 0.37105504777806336\n",
      "Iteration: 201 lambda_k: 1 Loss: 0.3706246876833741\n",
      "Iteration: 202 lambda_k: 1 Loss: 0.37019529317407707\n",
      "Iteration: 203 lambda_k: 1 Loss: 0.3697668613091455\n",
      "Iteration: 204 lambda_k: 1 Loss: 0.3693393891589696\n",
      "Iteration: 205 lambda_k: 1 Loss: 0.3689128738052381\n",
      "Iteration: 206 lambda_k: 1 Loss: 0.3684873123408237\n",
      "Iteration: 207 lambda_k: 1 Loss: 0.3680627018696734\n",
      "Iteration: 208 lambda_k: 1 Loss: 0.3676390395067032\n",
      "Iteration: 209 lambda_k: 1 Loss: 0.3672163223776973\n",
      "Iteration: 210 lambda_k: 1 Loss: 0.3667945476192107\n",
      "Iteration: 211 lambda_k: 1 Loss: 0.3663737123784755\n",
      "Iteration: 212 lambda_k: 1 Loss: 0.3659538138133114\n",
      "Iteration: 213 lambda_k: 1 Loss: 0.3655348490920386\n",
      "Iteration: 214 lambda_k: 1 Loss: 0.36511681539339425\n",
      "Iteration: 215 lambda_k: 1 Loss: 0.36469970990645195\n",
      "Iteration: 216 lambda_k: 1 Loss: 0.36428352983054374\n",
      "Iteration: 217 lambda_k: 1 Loss: 0.363868272375185\n",
      "Iteration: 218 lambda_k: 1 Loss: 0.3634539347600011\n",
      "Iteration: 219 lambda_k: 1 Loss: 0.3630405142146578\n",
      "Iteration: 220 lambda_k: 1 Loss: 0.3626280079787922\n",
      "Iteration: 221 lambda_k: 1 Loss: 0.3622164133019472\n",
      "Iteration: 222 lambda_k: 1 Loss: 0.36180572744350675\n",
      "Iteration: 223 lambda_k: 1 Loss: 0.3613959476726341\n",
      "Iteration: 224 lambda_k: 1 Loss: 0.36098707126821056\n",
      "Iteration: 225 lambda_k: 1 Loss: 0.36057909551877737\n",
      "Iteration: 226 lambda_k: 1 Loss: 0.36017201772247776\n",
      "Iteration: 227 lambda_k: 1 Loss: 0.35976583518700134\n",
      "Iteration: 228 lambda_k: 1 Loss: 0.3593605452295297\n",
      "Iteration: 229 lambda_k: 1 Loss: 0.3589561451766834\n",
      "Iteration: 230 lambda_k: 1 Loss: 0.35855263236446994\n",
      "Iteration: 231 lambda_k: 1 Loss: 0.358150004138233\n",
      "Iteration: 232 lambda_k: 1 Loss: 0.3577482578526038\n",
      "Iteration: 233 lambda_k: 1 Loss: 0.35734739087145123\n",
      "Iteration: 234 lambda_k: 1 Loss: 0.35694740056783586\n",
      "Iteration: 235 lambda_k: 1 Loss: 0.35654828432396246\n",
      "Iteration: 236 lambda_k: 1 Loss: 0.3561500395311352\n",
      "Iteration: 237 lambda_k: 1 Loss: 0.3557526635897124\n",
      "Iteration: 238 lambda_k: 1 Loss: 0.35535615390906305\n",
      "Iteration: 239 lambda_k: 1 Loss: 0.3549605079075235\n",
      "Iteration: 240 lambda_k: 1 Loss: 0.3545657230123553\n",
      "Iteration: 241 lambda_k: 1 Loss: 0.3541717966597036\n",
      "Iteration: 242 lambda_k: 1 Loss: 0.3537787262945558\n",
      "Iteration: 243 lambda_k: 1 Loss: 0.3533865093707018\n",
      "Iteration: 244 lambda_k: 1 Loss: 0.35299514335069404\n",
      "Iteration: 245 lambda_k: 1 Loss: 0.352604625705808\n",
      "Iteration: 246 lambda_k: 1 Loss: 0.35221495391600405\n",
      "Iteration: 247 lambda_k: 1 Loss: 0.35182612546988945\n",
      "Iteration: 248 lambda_k: 1 Loss: 0.3514381378646803\n",
      "Iteration: 249 lambda_k: 1 Loss: 0.35105098860616474\n",
      "Iteration: 250 lambda_k: 1 Loss: 0.35066467520866623\n",
      "Iteration: 251 lambda_k: 1 Loss: 0.35027919519500744\n",
      "Iteration: 252 lambda_k: 1 Loss: 0.3498945460964744\n",
      "Iteration: 253 lambda_k: 1 Loss: 0.3495107254527807\n",
      "Iteration: 254 lambda_k: 1 Loss: 0.34912773081203535\n",
      "Iteration: 255 lambda_k: 1 Loss: 0.34874555973070476\n",
      "Iteration: 256 lambda_k: 1 Loss: 0.3483642097735748\n",
      "Iteration: 257 lambda_k: 1 Loss: 0.34798367851372425\n",
      "Iteration: 258 lambda_k: 1 Loss: 0.3476039635323427\n",
      "Iteration: 259 lambda_k: 1 Loss: 0.34722506241925827\n",
      "Iteration: 260 lambda_k: 1 Loss: 0.3468469727721038\n",
      "Iteration: 261 lambda_k: 1 Loss: 0.34646969219677554\n",
      "Iteration: 262 lambda_k: 1 Loss: 0.3460932183073024\n",
      "Iteration: 263 lambda_k: 1 Loss: 0.3457175487259677\n",
      "Iteration: 264 lambda_k: 1 Loss: 0.345342681082655\n",
      "Iteration: 265 lambda_k: 1 Loss: 0.34496861301571186\n",
      "Iteration: 266 lambda_k: 1 Loss: 0.344595342171347\n",
      "Iteration: 267 lambda_k: 1 Loss: 0.3442228662037347\n",
      "Iteration: 268 lambda_k: 1 Loss: 0.3438511827749844\n",
      "Iteration: 269 lambda_k: 1 Loss: 0.34348028955511\n",
      "Iteration: 270 lambda_k: 1 Loss: 0.34311018422199874\n",
      "Iteration: 271 lambda_k: 1 Loss: 0.34274086446102964\n",
      "Iteration: 272 lambda_k: 1 Loss: 0.34237232796643396\n",
      "Iteration: 273 lambda_k: 1 Loss: 0.3420045724392032\n",
      "Iteration: 274 lambda_k: 1 Loss: 0.34163759558841716\n",
      "Iteration: 275 lambda_k: 1 Loss: 0.3412713951308794\n",
      "Iteration: 276 lambda_k: 1 Loss: 0.3409059687910877\n",
      "Iteration: 277 lambda_k: 1 Loss: 0.34054131430120477\n",
      "Iteration: 278 lambda_k: 1 Loss: 0.34017742940102924\n",
      "Iteration: 279 lambda_k: 1 Loss: 0.3398143118379668\n",
      "Iteration: 280 lambda_k: 1 Loss: 0.3394519593670013\n",
      "Iteration: 281 lambda_k: 1 Loss: 0.3390903697506663\n",
      "Iteration: 282 lambda_k: 1 Loss: 0.3387295407590165\n",
      "Iteration: 283 lambda_k: 1 Loss: 0.3383694701695998\n",
      "Iteration: 284 lambda_k: 1 Loss: 0.3380101557674289\n",
      "Iteration: 285 lambda_k: 1 Loss: 0.3376515953449533\n",
      "Iteration: 286 lambda_k: 1 Loss: 0.33729378670203175\n",
      "Iteration: 287 lambda_k: 1 Loss: 0.3369367276459045\n",
      "Iteration: 288 lambda_k: 1 Loss: 0.336580415991195\n",
      "Iteration: 289 lambda_k: 1 Loss: 0.3362248495597649\n",
      "Iteration: 290 lambda_k: 1 Loss: 0.3358700261808634\n",
      "Iteration: 291 lambda_k: 1 Loss: 0.3355159436909827\n",
      "Iteration: 292 lambda_k: 1 Loss: 0.33516259993386\n",
      "Iteration: 293 lambda_k: 1 Loss: 0.334809992760451\n",
      "Iteration: 294 lambda_k: 1 Loss: 0.33445812002890296\n",
      "Iteration: 295 lambda_k: 1 Loss: 0.3341069796045284\n",
      "Iteration: 296 lambda_k: 1 Loss: 0.33375656935977854\n",
      "Iteration: 297 lambda_k: 1 Loss: 0.33340688717421696\n",
      "Iteration: 298 lambda_k: 1 Loss: 0.33305793093449315\n",
      "Iteration: 299 lambda_k: 1 Loss: 0.332709698534317\n",
      "Iteration: 300 lambda_k: 1 Loss: 0.33236218787443245\n",
      "Iteration: 301 lambda_k: 1 Loss: 0.33201539686259174\n",
      "Iteration: 302 lambda_k: 1 Loss: 0.3316693234135299\n",
      "Iteration: 303 lambda_k: 1 Loss: 0.331323965448939\n",
      "Iteration: 304 lambda_k: 1 Loss: 0.33097932089744264\n",
      "Iteration: 305 lambda_k: 1 Loss: 0.3306353876945708\n",
      "Iteration: 306 lambda_k: 1 Loss: 0.3302921637827345\n",
      "Iteration: 307 lambda_k: 1 Loss: 0.3299496471112008\n",
      "Iteration: 308 lambda_k: 1 Loss: 0.3296078356360675\n",
      "Iteration: 309 lambda_k: 1 Loss: 0.3292667273202387\n",
      "Iteration: 310 lambda_k: 1 Loss: 0.32892632013339984\n",
      "Iteration: 311 lambda_k: 1 Loss: 0.328586612051993\n",
      "Iteration: 312 lambda_k: 1 Loss: 0.32824760105919243\n",
      "Iteration: 313 lambda_k: 1 Loss: 0.32790928514488\n",
      "Iteration: 314 lambda_k: 1 Loss: 0.32757166230562107\n",
      "Iteration: 315 lambda_k: 1 Loss: 0.3272347305446403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 316 lambda_k: 1 Loss: 0.32689848787179737\n",
      "Iteration: 317 lambda_k: 1 Loss: 0.32656293230356304\n",
      "Iteration: 318 lambda_k: 1 Loss: 0.32622806186299524\n",
      "Iteration: 319 lambda_k: 1 Loss: 0.3258938745797155\n",
      "Iteration: 320 lambda_k: 1 Loss: 0.3255603684898853\n",
      "Iteration: 321 lambda_k: 1 Loss: 0.3252275416332716\n",
      "Iteration: 322 lambda_k: 1 Loss: 0.3248953920638625\n",
      "Iteration: 323 lambda_k: 1 Loss: 0.32456391783573846\n",
      "Iteration: 324 lambda_k: 1 Loss: 0.3242331170107218\n",
      "Iteration: 325 lambda_k: 1 Loss: 0.3239029876571997\n",
      "Iteration: 326 lambda_k: 1 Loss: 0.32357352785012705\n",
      "Iteration: 327 lambda_k: 1 Loss: 0.32324473567082124\n",
      "Iteration: 328 lambda_k: 1 Loss: 0.32291660920692367\n",
      "Iteration: 329 lambda_k: 1 Loss: 0.32258914655239906\n",
      "Iteration: 330 lambda_k: 1 Loss: 0.3222623458075228\n",
      "Iteration: 331 lambda_k: 1 Loss: 0.3219362050788585\n",
      "Iteration: 332 lambda_k: 1 Loss: 0.3216107224792345\n",
      "Iteration: 333 lambda_k: 1 Loss: 0.3212858961277205\n",
      "Iteration: 334 lambda_k: 1 Loss: 0.32096172414960533\n",
      "Iteration: 335 lambda_k: 1 Loss: 0.32063820467637505\n",
      "Iteration: 336 lambda_k: 1 Loss: 0.3203153358456907\n",
      "Iteration: 337 lambda_k: 1 Loss: 0.3199931158013666\n",
      "Iteration: 338 lambda_k: 1 Loss: 0.3196715426933481\n",
      "Iteration: 339 lambda_k: 1 Loss: 0.31935061467769\n",
      "Iteration: 340 lambda_k: 1 Loss: 0.3190303299165352\n",
      "Iteration: 341 lambda_k: 1 Loss: 0.3187106865780922\n",
      "Iteration: 342 lambda_k: 1 Loss: 0.31839168283661473\n",
      "Iteration: 343 lambda_k: 1 Loss: 0.3180733168723792\n",
      "Iteration: 344 lambda_k: 1 Loss: 0.31775558687166433\n",
      "Iteration: 345 lambda_k: 1 Loss: 0.3174384910267294\n",
      "Iteration: 346 lambda_k: 1 Loss: 0.3171220275357932\n",
      "Iteration: 347 lambda_k: 1 Loss: 0.31680619460301346\n",
      "Iteration: 348 lambda_k: 1 Loss: 0.316490990438465\n",
      "Iteration: 349 lambda_k: 1 Loss: 0.31617641325811957\n",
      "Iteration: 350 lambda_k: 1 Loss: 0.3158624612838247\n",
      "Iteration: 351 lambda_k: 1 Loss: 0.3155491327419558\n",
      "Iteration: 352 lambda_k: 1 Loss: 0.31523642586821526\n",
      "Iteration: 353 lambda_k: 1 Loss: 0.3149243389011738\n",
      "Iteration: 354 lambda_k: 1 Loss: 0.31461287008595373\n",
      "Iteration: 355 lambda_k: 1 Loss: 0.3143020176734677\n",
      "Iteration: 356 lambda_k: 1 Loss: 0.3139917799203871\n",
      "Iteration: 357 lambda_k: 1 Loss: 0.3136821550891162\n",
      "Iteration: 358 lambda_k: 1 Loss: 0.31337314144777106\n",
      "Iteration: 359 lambda_k: 1 Loss: 0.3130647372701606\n",
      "Iteration: 360 lambda_k: 1 Loss: 0.31275694083576683\n",
      "Iteration: 361 lambda_k: 1 Loss: 0.3124497504297252\n",
      "Iteration: 362 lambda_k: 1 Loss: 0.3121431643428048\n",
      "Iteration: 363 lambda_k: 1 Loss: 0.3118371808713887\n",
      "Iteration: 364 lambda_k: 1 Loss: 0.3115317983174539\n",
      "Iteration: 365 lambda_k: 1 Loss: 0.31122701498855276\n",
      "Iteration: 366 lambda_k: 1 Loss: 0.3109228291977927\n",
      "Iteration: 367 lambda_k: 1 Loss: 0.3106192392638172\n",
      "Iteration: 368 lambda_k: 1 Loss: 0.31031624351078646\n",
      "Iteration: 369 lambda_k: 1 Loss: 0.3100138402683587\n",
      "Iteration: 370 lambda_k: 1 Loss: 0.30971202787167024\n",
      "Iteration: 371 lambda_k: 1 Loss: 0.30941080466131704\n",
      "Iteration: 372 lambda_k: 1 Loss: 0.3091101689833356\n",
      "Iteration: 373 lambda_k: 1 Loss: 0.3088101191891842\n",
      "Iteration: 374 lambda_k: 1 Loss: 0.3085106536357239\n",
      "Iteration: 375 lambda_k: 1 Loss: 0.3082117706852001\n",
      "Iteration: 376 lambda_k: 1 Loss: 0.3079134687052238\n",
      "Iteration: 377 lambda_k: 1 Loss: 0.30761574606875286\n",
      "Iteration: 378 lambda_k: 1 Loss: 0.3073186011540739\n",
      "Iteration: 379 lambda_k: 1 Loss: 0.30702203234478354\n",
      "Iteration: 380 lambda_k: 1 Loss: 0.3067260380297704\n",
      "Iteration: 381 lambda_k: 1 Loss: 0.3064306166031967\n",
      "Iteration: 382 lambda_k: 1 Loss: 0.3061357664644798\n",
      "Iteration: 383 lambda_k: 1 Loss: 0.3058414860182748\n",
      "Iteration: 384 lambda_k: 1 Loss: 0.30554777367445574\n",
      "Iteration: 385 lambda_k: 1 Loss: 0.3052546278480982\n",
      "Iteration: 386 lambda_k: 1 Loss: 0.3049620469594612\n",
      "Iteration: 387 lambda_k: 1 Loss: 0.3046700294339693\n",
      "Iteration: 388 lambda_k: 1 Loss: 0.3043785737021953\n",
      "Iteration: 389 lambda_k: 1 Loss: 0.3040876781998417\n",
      "Iteration: 390 lambda_k: 1 Loss: 0.3037973413677244\n",
      "Iteration: 391 lambda_k: 1 Loss: 0.3035075616517538\n",
      "Iteration: 392 lambda_k: 1 Loss: 0.30321833750291843\n",
      "Iteration: 393 lambda_k: 1 Loss: 0.3029296673772669\n",
      "Iteration: 394 lambda_k: 1 Loss: 0.3026415497497491\n",
      "Iteration: 395 lambda_k: 1 Loss: 0.30235398304929373\n",
      "Iteration: 396 lambda_k: 1 Loss: 0.3020669657759027\n",
      "Iteration: 397 lambda_k: 1 Loss: 0.30178049640371857\n",
      "Iteration: 398 lambda_k: 1 Loss: 0.30149457341105895\n",
      "Iteration: 399 lambda_k: 1 Loss: 0.30120919528287693\n",
      "Iteration: 400 lambda_k: 1 Loss: 0.3009243605102536\n",
      "Iteration: 401 lambda_k: 1 Loss: 0.300640067589292\n",
      "Iteration: 402 lambda_k: 1 Loss: 0.3003563150208626\n",
      "Iteration: 403 lambda_k: 1 Loss: 0.3000731013106651\n",
      "Iteration: 404 lambda_k: 1 Loss: 0.29979042496927233\n",
      "Iteration: 405 lambda_k: 1 Loss: 0.2995082845121229\n",
      "Iteration: 406 lambda_k: 1 Loss: 0.2992266784595002\n",
      "Iteration: 407 lambda_k: 1 Loss: 0.2989456053365111\n",
      "Iteration: 408 lambda_k: 1 Loss: 0.29866506367306994\n",
      "Iteration: 409 lambda_k: 1 Loss: 0.2983850520038824\n",
      "Iteration: 410 lambda_k: 1 Loss: 0.29810556886842937\n",
      "Iteration: 411 lambda_k: 1 Loss: 0.29782661281095096\n",
      "Iteration: 412 lambda_k: 1 Loss: 0.29754818238043007\n",
      "Iteration: 413 lambda_k: 1 Loss: 0.29727027613057655\n",
      "Iteration: 414 lambda_k: 1 Loss: 0.2969928926198113\n",
      "Iteration: 415 lambda_k: 1 Loss: 0.2967160304150932\n",
      "Iteration: 416 lambda_k: 1 Loss: 0.29643968807775994\n",
      "Iteration: 417 lambda_k: 1 Loss: 0.29616386418240187\n",
      "Iteration: 418 lambda_k: 1 Loss: 0.2958885573064952\n",
      "Iteration: 419 lambda_k: 1 Loss: 0.2956137660319349\n",
      "Iteration: 420 lambda_k: 1 Loss: 0.29533948894501416\n",
      "Iteration: 421 lambda_k: 1 Loss: 0.2950657246366491\n",
      "Iteration: 422 lambda_k: 1 Loss: 0.2947924717023794\n",
      "Iteration: 423 lambda_k: 1 Loss: 0.29451972874232357\n",
      "Iteration: 424 lambda_k: 1 Loss: 0.29424749436115144\n",
      "Iteration: 425 lambda_k: 1 Loss: 0.29397576716806956\n",
      "Iteration: 426 lambda_k: 1 Loss: 0.29370454577680705\n",
      "Iteration: 427 lambda_k: 1 Loss: 0.29343382880560176\n",
      "Iteration: 428 lambda_k: 1 Loss: 0.2931636148771846\n",
      "Iteration: 429 lambda_k: 1 Loss: 0.29289390261876475\n",
      "Iteration: 430 lambda_k: 1 Loss: 0.2926246906620142\n",
      "Iteration: 431 lambda_k: 1 Loss: 0.29235597764305327\n",
      "Iteration: 432 lambda_k: 1 Loss: 0.29208776220243526\n",
      "Iteration: 433 lambda_k: 1 Loss: 0.2918200429851321\n",
      "Iteration: 434 lambda_k: 1 Loss: 0.2915528186405191\n",
      "Iteration: 435 lambda_k: 1 Loss: 0.2912860878223605\n",
      "Iteration: 436 lambda_k: 1 Loss: 0.29101984918879464\n",
      "Iteration: 437 lambda_k: 1 Loss: 0.2907541014023195\n",
      "Iteration: 438 lambda_k: 1 Loss: 0.2904888431297781\n",
      "Iteration: 439 lambda_k: 1 Loss: 0.29022407304234354\n",
      "Iteration: 440 lambda_k: 1 Loss: 0.2899597898155053\n",
      "Iteration: 441 lambda_k: 1 Loss: 0.2896959921290544\n",
      "Iteration: 442 lambda_k: 1 Loss: 0.28943267866706895\n",
      "Iteration: 443 lambda_k: 1 Loss: 0.2891698481179\n",
      "Iteration: 444 lambda_k: 1 Loss: 0.2889074991741573\n",
      "Iteration: 445 lambda_k: 1 Loss: 0.2886456305326952\n",
      "Iteration: 446 lambda_k: 1 Loss: 0.28838424089459813\n",
      "Iteration: 447 lambda_k: 1 Loss: 0.288123328965167\n",
      "Iteration: 448 lambda_k: 1 Loss: 0.2878628934539048\n",
      "Iteration: 449 lambda_k: 1 Loss: 0.28760293307450285\n",
      "Iteration: 450 lambda_k: 1 Loss: 0.2873434465448265\n",
      "Iteration: 451 lambda_k: 1 Loss: 0.2870844325869019\n",
      "Iteration: 452 lambda_k: 1 Loss: 0.28682588992690145\n",
      "Iteration: 453 lambda_k: 1 Loss: 0.2865678172951306\n",
      "Iteration: 454 lambda_k: 1 Loss: 0.2863102134260135\n",
      "Iteration: 455 lambda_k: 1 Loss: 0.28605307705808014\n",
      "Iteration: 456 lambda_k: 1 Loss: 0.2857964069339519\n",
      "Iteration: 457 lambda_k: 1 Loss: 0.2855402018003287\n",
      "Iteration: 458 lambda_k: 1 Loss: 0.2852844604079748\n",
      "Iteration: 459 lambda_k: 1 Loss: 0.28502918151170575\n",
      "Iteration: 460 lambda_k: 1 Loss: 0.2847743638703751\n",
      "Iteration: 461 lambda_k: 1 Loss: 0.2845200062468605\n",
      "Iteration: 462 lambda_k: 1 Loss: 0.2842661074080508\n",
      "Iteration: 463 lambda_k: 1 Loss: 0.2840126661248325\n",
      "Iteration: 464 lambda_k: 1 Loss: 0.28375968117207695\n",
      "Iteration: 465 lambda_k: 1 Loss: 0.2835071513286267\n",
      "Iteration: 466 lambda_k: 1 Loss: 0.2832550753772824\n",
      "Iteration: 467 lambda_k: 1 Loss: 0.28300345210479017\n",
      "Iteration: 468 lambda_k: 1 Loss: 0.2827522803018281\n",
      "Iteration: 469 lambda_k: 1 Loss: 0.2825015587629935\n",
      "Iteration: 470 lambda_k: 1 Loss: 0.2822512862867898\n",
      "Iteration: 471 lambda_k: 1 Loss: 0.28200146167561385\n",
      "Iteration: 472 lambda_k: 1 Loss: 0.281752083735743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 473 lambda_k: 1 Loss: 0.28150315127732217\n",
      "Iteration: 474 lambda_k: 1 Loss: 0.2812546631143513\n",
      "Iteration: 475 lambda_k: 1 Loss: 0.28100661806467253\n",
      "Iteration: 476 lambda_k: 1 Loss: 0.28075901494995764\n",
      "Iteration: 477 lambda_k: 1 Loss: 0.28051185259569517\n",
      "Iteration: 478 lambda_k: 1 Loss: 0.2802651298311784\n",
      "Iteration: 479 lambda_k: 1 Loss: 0.28001884548949224\n",
      "Iteration: 480 lambda_k: 1 Loss: 0.27977299840750103\n",
      "Iteration: 481 lambda_k: 1 Loss: 0.2795275874258363\n",
      "Iteration: 482 lambda_k: 1 Loss: 0.27928261138888383\n",
      "Iteration: 483 lambda_k: 1 Loss: 0.279038069144772\n",
      "Iteration: 484 lambda_k: 1 Loss: 0.2787939595453591\n",
      "Iteration: 485 lambda_k: 1 Loss: 0.27855028144622096\n",
      "Iteration: 486 lambda_k: 1 Loss: 0.2783070337066392\n",
      "Iteration: 487 lambda_k: 1 Loss: 0.27806421518958846\n",
      "Iteration: 488 lambda_k: 1 Loss: 0.27782182476172507\n",
      "Iteration: 489 lambda_k: 1 Loss: 0.27757986129337425\n",
      "Iteration: 490 lambda_k: 1 Loss: 0.27733832365851846\n",
      "Iteration: 491 lambda_k: 1 Loss: 0.27709721073478544\n",
      "Iteration: 492 lambda_k: 1 Loss: 0.27685652140343586\n",
      "Iteration: 493 lambda_k: 1 Loss: 0.27661625454935207\n",
      "Iteration: 494 lambda_k: 1 Loss: 0.2763764090610258\n",
      "Iteration: 495 lambda_k: 1 Loss: 0.27613698383054636\n",
      "Iteration: 496 lambda_k: 1 Loss: 0.2758979777535891\n",
      "Iteration: 497 lambda_k: 1 Loss: 0.27565938972940357\n",
      "Iteration: 498 lambda_k: 1 Loss: 0.27542121866080166\n",
      "Iteration: 499 lambda_k: 1 Loss: 0.2751834634541463\n",
      "Iteration: 500 lambda_k: 1 Loss: 0.2749461230193396\n",
      "Iteration: 501 lambda_k: 1 Loss: 0.27470919626981133\n",
      "Iteration: 502 lambda_k: 1 Loss: 0.2744726821225076\n",
      "Iteration: 503 lambda_k: 1 Loss: 0.2742365794978792\n",
      "Iteration: 504 lambda_k: 1 Loss: 0.27400088731987005\n",
      "Iteration: 505 lambda_k: 1 Loss: 0.2737656045159062\n",
      "Iteration: 506 lambda_k: 1 Loss: 0.27353073001688405\n",
      "Iteration: 507 lambda_k: 1 Loss: 0.2732962627571594\n",
      "Iteration: 508 lambda_k: 1 Loss: 0.2730622016745359\n",
      "Iteration: 509 lambda_k: 1 Loss: 0.272828545710254\n",
      "Iteration: 510 lambda_k: 1 Loss: 0.2725952938089798\n",
      "Iteration: 511 lambda_k: 1 Loss: 0.2723624449187936\n",
      "Iteration: 512 lambda_k: 1 Loss: 0.2721299979911791\n",
      "Iteration: 513 lambda_k: 1 Loss: 0.2718979519810123\n",
      "Iteration: 514 lambda_k: 1 Loss: 0.27166630584655027\n",
      "Iteration: 515 lambda_k: 1 Loss: 0.27143505854942046\n",
      "Iteration: 516 lambda_k: 1 Loss: 0.2712042090546094\n",
      "Iteration: 517 lambda_k: 1 Loss: 0.2709737563304521\n",
      "Iteration: 518 lambda_k: 1 Loss: 0.27074369934862114\n",
      "Iteration: 519 lambda_k: 1 Loss: 0.2705140370841154\n",
      "Iteration: 520 lambda_k: 1 Loss: 0.2702847685152501\n",
      "Iteration: 521 lambda_k: 1 Loss: 0.27005589262364516\n",
      "Iteration: 522 lambda_k: 1 Loss: 0.2698274083942152\n",
      "Iteration: 523 lambda_k: 1 Loss: 0.26959931481515836\n",
      "Iteration: 524 lambda_k: 1 Loss: 0.26937161087794587\n",
      "Iteration: 525 lambda_k: 1 Loss: 0.26914429557731145\n",
      "Iteration: 526 lambda_k: 1 Loss: 0.2689173679112408\n",
      "Iteration: 527 lambda_k: 1 Loss: 0.26869082688096096\n",
      "Iteration: 528 lambda_k: 1 Loss: 0.2684646714909299\n",
      "Iteration: 529 lambda_k: 1 Loss: 0.2682389007488259\n",
      "Iteration: 530 lambda_k: 1 Loss: 0.2680135136655375\n",
      "Iteration: 531 lambda_k: 1 Loss: 0.26778850925515263\n",
      "Iteration: 532 lambda_k: 1 Loss: 0.2675638865349487\n",
      "Iteration: 533 lambda_k: 1 Loss: 0.2673396445253822\n",
      "Iteration: 534 lambda_k: 1 Loss: 0.2671157822500783\n",
      "Iteration: 535 lambda_k: 1 Loss: 0.2668922987358206\n",
      "Iteration: 536 lambda_k: 1 Loss: 0.2666691930125412\n",
      "Iteration: 537 lambda_k: 1 Loss: 0.26644646411331036\n",
      "Iteration: 538 lambda_k: 1 Loss: 0.26622411107432625\n",
      "Iteration: 539 lambda_k: 1 Loss: 0.2660021329349053\n",
      "Iteration: 540 lambda_k: 1 Loss: 0.2657805287374716\n",
      "Iteration: 541 lambda_k: 1 Loss: 0.26555929752754737\n",
      "Iteration: 542 lambda_k: 1 Loss: 0.2653384383537426\n",
      "Iteration: 543 lambda_k: 1 Loss: 0.2651179502677455\n",
      "Iteration: 544 lambda_k: 1 Loss: 0.2648978323243123\n",
      "Iteration: 545 lambda_k: 1 Loss: 0.26467808358125755\n",
      "Iteration: 546 lambda_k: 1 Loss: 0.26445870309944414\n",
      "Iteration: 547 lambda_k: 1 Loss: 0.2642396899427737\n",
      "Iteration: 548 lambda_k: 1 Loss: 0.2640210431781766\n",
      "Iteration: 549 lambda_k: 1 Loss: 0.2638027618756026\n",
      "Iteration: 550 lambda_k: 1 Loss: 0.2635848451080106\n",
      "Iteration: 551 lambda_k: 1 Loss: 0.26336729195135966\n",
      "Iteration: 552 lambda_k: 1 Loss: 0.26315010148459883\n",
      "Iteration: 553 lambda_k: 1 Loss: 0.262933272789658\n",
      "Iteration: 554 lambda_k: 1 Loss: 0.2627168049514378\n",
      "Iteration: 555 lambda_k: 1 Loss: 0.26250069705780077\n",
      "Iteration: 556 lambda_k: 1 Loss: 0.26228494819956133\n",
      "Iteration: 557 lambda_k: 1 Loss: 0.2620695574451084\n",
      "Iteration: 558 lambda_k: 1 Loss: 0.261854523933286\n",
      "Iteration: 559 lambda_k: 1 Loss: 0.26163984675330665\n",
      "Iteration: 560 lambda_k: 1 Loss: 0.2614255250017436\n",
      "Iteration: 561 lambda_k: 1 Loss: 0.26121155778290645\n",
      "Iteration: 562 lambda_k: 1 Loss: 0.2609979442055815\n",
      "Iteration: 563 lambda_k: 1 Loss: 0.2607846833812265\n",
      "Iteration: 564 lambda_k: 1 Loss: 0.26057177442392193\n",
      "Iteration: 565 lambda_k: 1 Loss: 0.26035921645058036\n",
      "Iteration: 566 lambda_k: 1 Loss: 0.26014700858099854\n",
      "Iteration: 567 lambda_k: 1 Loss: 0.25993514993783373\n",
      "Iteration: 568 lambda_k: 1 Loss: 0.2597236396465829\n",
      "Iteration: 569 lambda_k: 1 Loss: 0.25951247683557316\n",
      "Iteration: 570 lambda_k: 1 Loss: 0.25930166063595456\n",
      "Iteration: 571 lambda_k: 1 Loss: 0.259091190181691\n",
      "Iteration: 572 lambda_k: 1 Loss: 0.2588810646095513\n",
      "Iteration: 573 lambda_k: 1 Loss: 0.2586712830590999\n",
      "Iteration: 574 lambda_k: 1 Loss: 0.258461844672688\n",
      "Iteration: 575 lambda_k: 1 Loss: 0.2582527485954446\n",
      "Iteration: 576 lambda_k: 1 Loss: 0.25804399397526745\n",
      "Iteration: 577 lambda_k: 1 Loss: 0.25783557996281437\n",
      "Iteration: 578 lambda_k: 1 Loss: 0.2576275057182672\n",
      "Iteration: 579 lambda_k: 1 Loss: 0.2574197703863156\n",
      "Iteration: 580 lambda_k: 1 Loss: 0.2572123731292515\n",
      "Iteration: 581 lambda_k: 1 Loss: 0.25700531310979785\n",
      "Iteration: 582 lambda_k: 1 Loss: 0.25679858949256723\n",
      "Iteration: 583 lambda_k: 1 Loss: 0.2565922014444766\n",
      "Iteration: 584 lambda_k: 1 Loss: 0.25638614813519306\n",
      "Iteration: 585 lambda_k: 1 Loss: 0.2561804287371419\n",
      "Iteration: 586 lambda_k: 1 Loss: 0.2559750424254427\n",
      "Iteration: 587 lambda_k: 1 Loss: 0.2557699883778823\n",
      "Iteration: 588 lambda_k: 1 Loss: 0.2555652657749086\n",
      "Iteration: 589 lambda_k: 1 Loss: 0.2553608737996254\n",
      "Iteration: 590 lambda_k: 1 Loss: 0.25515681163778436\n",
      "Iteration: 591 lambda_k: 1 Loss: 0.2549530784905289\n",
      "Iteration: 592 lambda_k: 1 Loss: 0.25474967352778266\n",
      "Iteration: 593 lambda_k: 1 Loss: 0.2545465959481239\n",
      "Iteration: 594 lambda_k: 1 Loss: 0.2543438449510721\n",
      "Iteration: 595 lambda_k: 1 Loss: 0.25414141973606696\n",
      "Iteration: 596 lambda_k: 1 Loss: 0.25393931950434384\n",
      "Iteration: 597 lambda_k: 1 Loss: 0.25373754345984195\n",
      "Iteration: 598 lambda_k: 1 Loss: 0.2535360908092104\n",
      "Iteration: 599 lambda_k: 1 Loss: 0.253334960761689\n",
      "Iteration: 600 lambda_k: 1 Loss: 0.2531341525290712\n",
      "Iteration: 601 lambda_k: 1 Loss: 0.25293366532570405\n",
      "Iteration: 602 lambda_k: 1 Loss: 0.2527334983325222\n",
      "Iteration: 603 lambda_k: 1 Loss: 0.2525336508283043\n",
      "Iteration: 604 lambda_k: 1 Loss: 0.2523341220206753\n",
      "Iteration: 605 lambda_k: 1 Loss: 0.25213491112557657\n",
      "Iteration: 606 lambda_k: 1 Loss: 0.2519360173684281\n",
      "Iteration: 607 lambda_k: 1 Loss: 0.2517374399793858\n",
      "Iteration: 608 lambda_k: 1 Loss: 0.25153917819080324\n",
      "Iteration: 609 lambda_k: 1 Loss: 0.2513412312371717\n",
      "Iteration: 610 lambda_k: 1 Loss: 0.2511435983554201\n",
      "Iteration: 611 lambda_k: 1 Loss: 0.2509462787849909\n",
      "Iteration: 612 lambda_k: 1 Loss: 0.2507492717678115\n",
      "Iteration: 613 lambda_k: 1 Loss: 0.2505525765482707\n",
      "Iteration: 614 lambda_k: 1 Loss: 0.25035619237320816\n",
      "Iteration: 615 lambda_k: 1 Loss: 0.2501601185007145\n",
      "Iteration: 616 lambda_k: 1 Loss: 0.2499643541675999\n",
      "Iteration: 617 lambda_k: 1 Loss: 0.24976889863227789\n",
      "Iteration: 618 lambda_k: 1 Loss: 0.249573751152986\n",
      "Iteration: 619 lambda_k: 1 Loss: 0.24937891098910153\n",
      "Iteration: 620 lambda_k: 1 Loss: 0.2491843774018768\n",
      "Iteration: 621 lambda_k: 1 Loss: 0.2489901496550358\n",
      "Iteration: 622 lambda_k: 1 Loss: 0.2487962270147847\n",
      "Iteration: 623 lambda_k: 1 Loss: 0.24860260874973086\n",
      "Iteration: 624 lambda_k: 1 Loss: 0.2484092941308516\n",
      "Iteration: 625 lambda_k: 1 Loss: 0.24821628243149077\n",
      "Iteration: 626 lambda_k: 1 Loss: 0.2480235729273556\n",
      "Iteration: 627 lambda_k: 1 Loss: 0.24783116489650947\n",
      "Iteration: 628 lambda_k: 1 Loss: 0.24763905761936456\n",
      "Iteration: 629 lambda_k: 1 Loss: 0.24744725037867402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 630 lambda_k: 1 Loss: 0.24725574245952506\n",
      "Iteration: 631 lambda_k: 1 Loss: 0.24706453314933136\n",
      "Iteration: 632 lambda_k: 1 Loss: 0.24687362173782598\n",
      "Iteration: 633 lambda_k: 1 Loss: 0.24668300751705435\n",
      "Iteration: 634 lambda_k: 1 Loss: 0.24649268978136682\n",
      "Iteration: 635 lambda_k: 1 Loss: 0.24630266782741161\n",
      "Iteration: 636 lambda_k: 1 Loss: 0.24611294095412764\n",
      "Iteration: 637 lambda_k: 1 Loss: 0.24592350846273733\n",
      "Iteration: 638 lambda_k: 1 Loss: 0.2457343696567399\n",
      "Iteration: 639 lambda_k: 1 Loss: 0.2455455238419038\n",
      "Iteration: 640 lambda_k: 1 Loss: 0.2453569703262602\n",
      "Iteration: 641 lambda_k: 1 Loss: 0.24516870842009544\n",
      "Iteration: 642 lambda_k: 1 Loss: 0.2449807374359448\n",
      "Iteration: 643 lambda_k: 1 Loss: 0.24479305668858503\n",
      "Iteration: 644 lambda_k: 1 Loss: 0.24460566549502757\n",
      "Iteration: 645 lambda_k: 1 Loss: 0.24441856317451222\n",
      "Iteration: 646 lambda_k: 1 Loss: 0.2442317490484995\n",
      "Iteration: 647 lambda_k: 1 Loss: 0.24404522244066487\n",
      "Iteration: 648 lambda_k: 1 Loss: 0.24385898267689154\n",
      "Iteration: 649 lambda_k: 1 Loss: 0.24367302908526395\n",
      "Iteration: 650 lambda_k: 1 Loss: 0.2434873609960615\n",
      "Iteration: 651 lambda_k: 1 Loss: 0.24330197774175197\n",
      "Iteration: 652 lambda_k: 1 Loss: 0.24311687865698528\n",
      "Iteration: 653 lambda_k: 1 Loss: 0.24293206307858733\n",
      "Iteration: 654 lambda_k: 1 Loss: 0.24274753034555405\n",
      "Iteration: 655 lambda_k: 1 Loss: 0.2425632797990456\n",
      "Iteration: 656 lambda_k: 1 Loss: 0.24237931078238048\n",
      "Iteration: 657 lambda_k: 1 Loss: 0.24219562264103056\n",
      "Iteration: 658 lambda_k: 1 Loss: 0.24201221472261547\n",
      "Iteration: 659 lambda_k: 1 Loss: 0.24182908637689815\n",
      "Iteration: 660 lambda_k: 1 Loss: 0.24164623695578064\n",
      "Iteration: 661 lambda_k: 1 Loss: 0.24146366581329967\n",
      "Iteration: 662 lambda_k: 1 Loss: 0.24128137230562358\n",
      "Iteration: 663 lambda_k: 1 Loss: 0.24109935579104982\n",
      "Iteration: 664 lambda_k: 1 Loss: 0.24091761563000272\n",
      "Iteration: 665 lambda_k: 1 Loss: 0.24073615118503267\n",
      "Iteration: 666 lambda_k: 1 Loss: 0.24055496182081632\n",
      "Iteration: 667 lambda_k: 1 Loss: 0.24037404690415803\n",
      "Iteration: 668 lambda_k: 1 Loss: 0.24019340575014858\n",
      "Iteration: 669 lambda_k: 1 Loss: 0.24001303781122976\n",
      "Iteration: 670 lambda_k: 1 Loss: 0.23983294244319842\n",
      "Iteration: 671 lambda_k: 1 Loss: 0.23965311900896166\n",
      "Iteration: 672 lambda_k: 1 Loss: 0.23947356688313604\n",
      "Iteration: 673 lambda_k: 1 Loss: 0.23929428544543546\n",
      "Iteration: 674 lambda_k: 1 Loss: 0.2391152740772459\n",
      "Iteration: 675 lambda_k: 1 Loss: 0.2389365321615168\n",
      "Iteration: 676 lambda_k: 1 Loss: 0.23875805908316008\n",
      "Iteration: 677 lambda_k: 1 Loss: 0.2385798542291546\n",
      "Iteration: 678 lambda_k: 1 Loss: 0.2384019169885124\n",
      "Iteration: 679 lambda_k: 1 Loss: 0.23822424675225165\n",
      "Iteration: 680 lambda_k: 1 Loss: 0.2380468429133923\n",
      "Iteration: 681 lambda_k: 1 Loss: 0.23786970486695536\n",
      "Iteration: 682 lambda_k: 1 Loss: 0.23769283200996108\n",
      "Iteration: 683 lambda_k: 1 Loss: 0.23751622374142625\n",
      "Iteration: 684 lambda_k: 1 Loss: 0.23733987946236332\n",
      "Iteration: 685 lambda_k: 1 Loss: 0.23716379857578299\n",
      "Iteration: 686 lambda_k: 1 Loss: 0.2369879804866992\n",
      "Iteration: 687 lambda_k: 1 Loss: 0.23681242460213925\n",
      "Iteration: 688 lambda_k: 1 Loss: 0.2366371303311602\n",
      "Iteration: 689 lambda_k: 1 Loss: 0.23646209708487442\n",
      "Iteration: 690 lambda_k: 1 Loss: 0.23628732427648622\n",
      "Iteration: 691 lambda_k: 1 Loss: 0.236112811321347\n",
      "Iteration: 692 lambda_k: 1 Loss: 0.23593855763703322\n",
      "Iteration: 693 lambda_k: 1 Loss: 0.2357645626434565\n",
      "Iteration: 694 lambda_k: 1 Loss: 0.23559082576301824\n",
      "Iteration: 695 lambda_k: 1 Loss: 0.23541734642082446\n",
      "Iteration: 696 lambda_k: 1 Loss: 0.23524412404498224\n",
      "Iteration: 697 lambda_k: 1 Loss: 0.235071157822993\n",
      "Iteration: 698 lambda_k: 1 Loss: 0.23489844752790742\n",
      "Iteration: 699 lambda_k: 1 Loss: 0.23472599252192275\n",
      "Iteration: 700 lambda_k: 1 Loss: 0.23455379218879235\n",
      "Iteration: 701 lambda_k: 1 Loss: 0.23438184599828418\n",
      "Iteration: 702 lambda_k: 1 Loss: 0.2342101533138073\n",
      "Iteration: 703 lambda_k: 1 Loss: 0.23403871359378534\n",
      "Iteration: 704 lambda_k: 1 Loss: 0.23386752628936872\n",
      "Iteration: 705 lambda_k: 1 Loss: 0.2336965908452806\n",
      "Iteration: 706 lambda_k: 1 Loss: 0.23352590670727094\n",
      "Iteration: 707 lambda_k: 1 Loss: 0.23335547332688542\n",
      "Iteration: 708 lambda_k: 1 Loss: 0.2331852901645978\n",
      "Iteration: 709 lambda_k: 1 Loss: 0.23301535669530685\n",
      "Iteration: 710 lambda_k: 1 Loss: 0.23284567241894233\n",
      "Iteration: 711 lambda_k: 1 Loss: 0.23267623603997348\n",
      "Iteration: 712 lambda_k: 1 Loss: 0.23250704794582422\n",
      "Iteration: 713 lambda_k: 1 Loss: 0.23233810758747198\n",
      "Iteration: 714 lambda_k: 1 Loss: 0.23216941414417316\n",
      "Iteration: 715 lambda_k: 1 Loss: 0.2320009672614652\n",
      "Iteration: 716 lambda_k: 1 Loss: 0.2318327654031579\n",
      "Iteration: 717 lambda_k: 1 Loss: 0.23166480939404532\n",
      "Iteration: 718 lambda_k: 1 Loss: 0.23149710084852015\n",
      "Iteration: 719 lambda_k: 1 Loss: 0.23132964107914106\n",
      "Iteration: 720 lambda_k: 1 Loss: 0.23116246280018202\n",
      "Iteration: 721 lambda_k: 1 Loss: 0.23099556355879156\n",
      "Iteration: 722 lambda_k: 1 Loss: 0.23082894452847044\n",
      "Iteration: 723 lambda_k: 1 Loss: 0.23066260373547598\n",
      "Iteration: 724 lambda_k: 1 Loss: 0.2304965400618835\n",
      "Iteration: 725 lambda_k: 1 Loss: 0.23033075152364207\n",
      "Iteration: 726 lambda_k: 1 Loss: 0.23016523642698833\n",
      "Iteration: 727 lambda_k: 1 Loss: 0.2299999932170727\n",
      "Iteration: 728 lambda_k: 1 Loss: 0.22983502009996348\n",
      "Iteration: 729 lambda_k: 1 Loss: 0.22967031552837605\n",
      "Iteration: 730 lambda_k: 1 Loss: 0.22950587792362936\n",
      "Iteration: 731 lambda_k: 1 Loss: 0.2293417057706114\n",
      "Iteration: 732 lambda_k: 1 Loss: 0.2291777974635245\n",
      "Iteration: 733 lambda_k: 1 Loss: 0.2290141515248508\n",
      "Iteration: 734 lambda_k: 1 Loss: 0.22885076646707495\n",
      "Iteration: 735 lambda_k: 1 Loss: 0.22868764081987936\n",
      "Iteration: 736 lambda_k: 1 Loss: 0.22852477312986236\n",
      "Iteration: 737 lambda_k: 1 Loss: 0.22836216195073483\n",
      "Iteration: 738 lambda_k: 1 Loss: 0.22819980587270808\n",
      "Iteration: 739 lambda_k: 1 Loss: 0.2280377035093271\n",
      "Iteration: 740 lambda_k: 1 Loss: 0.22787585343382016\n",
      "Iteration: 741 lambda_k: 1 Loss: 0.2277142542733172\n",
      "Iteration: 742 lambda_k: 1 Loss: 0.2275529046609248\n",
      "Iteration: 743 lambda_k: 1 Loss: 0.22739180323870156\n",
      "Iteration: 744 lambda_k: 1 Loss: 0.22723094866749008\n",
      "Iteration: 745 lambda_k: 1 Loss: 0.22707033961451192\n",
      "Iteration: 746 lambda_k: 1 Loss: 0.2269099747529534\n",
      "Iteration: 747 lambda_k: 1 Loss: 0.22674985277973003\n",
      "Iteration: 748 lambda_k: 1 Loss: 0.22658997240849976\n",
      "Iteration: 749 lambda_k: 1 Loss: 0.22643033232631196\n",
      "Iteration: 750 lambda_k: 1 Loss: 0.22627093125846817\n",
      "Iteration: 751 lambda_k: 1 Loss: 0.2261117679352626\n",
      "Iteration: 752 lambda_k: 1 Loss: 0.22595284109649094\n",
      "Iteration: 753 lambda_k: 1 Loss: 0.22579414949098592\n",
      "Iteration: 754 lambda_k: 1 Loss: 0.22563569187672547\n",
      "Iteration: 755 lambda_k: 1 Loss: 0.22547746702072832\n",
      "Iteration: 756 lambda_k: 1 Loss: 0.22531947369891675\n",
      "Iteration: 757 lambda_k: 1 Loss: 0.22516171069599847\n",
      "Iteration: 758 lambda_k: 1 Loss: 0.22500417680536142\n",
      "Iteration: 759 lambda_k: 1 Loss: 0.22484687082897092\n",
      "Iteration: 760 lambda_k: 1 Loss: 0.22468979157726857\n",
      "Iteration: 761 lambda_k: 1 Loss: 0.2245329378690732\n",
      "Iteration: 762 lambda_k: 1 Loss: 0.22437630853148668\n",
      "Iteration: 763 lambda_k: 1 Loss: 0.2242199023998037\n",
      "Iteration: 764 lambda_k: 1 Loss: 0.2240637183191434\n",
      "Iteration: 765 lambda_k: 1 Loss: 0.2239077551380556\n",
      "Iteration: 766 lambda_k: 1 Loss: 0.22375201171699288\n",
      "Iteration: 767 lambda_k: 1 Loss: 0.2235964869232123\n",
      "Iteration: 768 lambda_k: 1 Loss: 0.22344117963174592\n",
      "Iteration: 769 lambda_k: 1 Loss: 0.22328608872533426\n",
      "Iteration: 770 lambda_k: 1 Loss: 0.22313121309436362\n",
      "Iteration: 771 lambda_k: 1 Loss: 0.22297655163679916\n",
      "Iteration: 772 lambda_k: 1 Loss: 0.22282210325811702\n",
      "Iteration: 773 lambda_k: 1 Loss: 0.22266786687123866\n",
      "Iteration: 774 lambda_k: 1 Loss: 0.22251384139646627\n",
      "Iteration: 775 lambda_k: 1 Loss: 0.222360025761421\n",
      "Iteration: 776 lambda_k: 1 Loss: 0.22220641890098128\n",
      "Iteration: 777 lambda_k: 1 Loss: 0.22205301975722352\n",
      "Iteration: 778 lambda_k: 1 Loss: 0.22189982727936272\n",
      "Iteration: 779 lambda_k: 1 Loss: 0.22174684042369505\n",
      "Iteration: 780 lambda_k: 1 Loss: 0.2215940581535412\n",
      "Iteration: 781 lambda_k: 1 Loss: 0.2214414794391906\n",
      "Iteration: 782 lambda_k: 1 Loss: 0.22128910325784665\n",
      "Iteration: 783 lambda_k: 1 Loss: 0.22113692859357276\n",
      "Iteration: 784 lambda_k: 1 Loss: 0.22098495443723937\n",
      "Iteration: 785 lambda_k: 1 Loss: 0.22083317978647177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 786 lambda_k: 1 Loss: 0.22068160364559836\n",
      "Iteration: 787 lambda_k: 1 Loss: 0.22053022502560013\n",
      "Iteration: 788 lambda_k: 1 Loss: 0.2203790429440606\n",
      "Iteration: 789 lambda_k: 1 Loss: 0.2202280564251165\n",
      "Iteration: 790 lambda_k: 1 Loss: 0.22007726449940915\n",
      "Iteration: 791 lambda_k: 1 Loss: 0.21992666620403617\n",
      "Iteration: 792 lambda_k: 1 Loss: 0.21977626058250443\n",
      "Iteration: 793 lambda_k: 1 Loss: 0.21962604668468316\n",
      "Iteration: 794 lambda_k: 1 Loss: 0.2194760235667576\n",
      "Iteration: 795 lambda_k: 1 Loss: 0.21932619029118375\n",
      "Iteration: 796 lambda_k: 1 Loss: 0.2191765459266427\n",
      "Iteration: 797 lambda_k: 1 Loss: 0.21902708954799666\n",
      "Iteration: 798 lambda_k: 1 Loss: 0.2188778202362447\n",
      "Iteration: 799 lambda_k: 1 Loss: 0.21872873707847934\n",
      "Iteration: 800 lambda_k: 1 Loss: 0.21857983916784338\n",
      "Iteration: 801 lambda_k: 1 Loss: 0.21843112560348768\n",
      "Iteration: 802 lambda_k: 1 Loss: 0.21828259549052897\n",
      "Iteration: 803 lambda_k: 1 Loss: 0.21813424794000805\n",
      "Iteration: 804 lambda_k: 1 Loss: 0.21798608206884917\n",
      "Iteration: 805 lambda_k: 1 Loss: 0.21783809699981907\n",
      "Iteration: 806 lambda_k: 1 Loss: 0.21769029186148658\n",
      "Iteration: 807 lambda_k: 1 Loss: 0.2175426657881832\n",
      "Iteration: 808 lambda_k: 1 Loss: 0.2173952179199634\n",
      "Iteration: 809 lambda_k: 1 Loss: 0.21724794740256564\n",
      "Iteration: 810 lambda_k: 1 Loss: 0.21710085338737398\n",
      "Iteration: 811 lambda_k: 1 Loss: 0.21695393503137966\n",
      "Iteration: 812 lambda_k: 1 Loss: 0.21680719149714353\n",
      "Iteration: 813 lambda_k: 1 Loss: 0.21666062195275806\n",
      "Iteration: 814 lambda_k: 1 Loss: 0.21651422557181096\n",
      "Iteration: 815 lambda_k: 1 Loss: 0.21636800153334793\n",
      "Iteration: 816 lambda_k: 1 Loss: 0.21622194902183645\n",
      "Iteration: 817 lambda_k: 1 Loss: 0.2160760672271298\n",
      "Iteration: 818 lambda_k: 1 Loss: 0.21593035534443128\n",
      "Iteration: 819 lambda_k: 1 Loss: 0.21578481257425908\n",
      "Iteration: 820 lambda_k: 1 Loss: 0.21563943812241063\n",
      "Iteration: 821 lambda_k: 1 Loss: 0.21549423119992878\n",
      "Iteration: 822 lambda_k: 1 Loss: 0.21534919102306654\n",
      "Iteration: 823 lambda_k: 1 Loss: 0.21520431681325397\n",
      "Iteration: 824 lambda_k: 1 Loss: 0.215059607797064\n",
      "Iteration: 825 lambda_k: 1 Loss: 0.21491506320617804\n",
      "Iteration: 826 lambda_k: 1 Loss: 0.21477068227735355\n",
      "Iteration: 827 lambda_k: 1 Loss: 0.21462646425239126\n",
      "Iteration: 828 lambda_k: 1 Loss: 0.2144824083781026\n",
      "Iteration: 829 lambda_k: 1 Loss: 0.2143385139062772\n",
      "Iteration: 830 lambda_k: 1 Loss: 0.21419478009098003\n",
      "Iteration: 831 lambda_k: 1 Loss: 0.21405120619795884\n",
      "Iteration: 832 lambda_k: 1 Loss: 0.2139077914924216\n",
      "Iteration: 833 lambda_k: 1 Loss: 0.21376453524580616\n",
      "Iteration: 834 lambda_k: 1 Loss: 0.21362143673417022\n",
      "Iteration: 835 lambda_k: 1 Loss: 0.21347849523852647\n",
      "Iteration: 836 lambda_k: 1 Loss: 0.21333571004466192\n",
      "Iteration: 837 lambda_k: 1 Loss: 0.21319308044306606\n",
      "Iteration: 838 lambda_k: 1 Loss: 0.21305060572891363\n",
      "Iteration: 839 lambda_k: 1 Loss: 0.21290828520204863\n",
      "Iteration: 840 lambda_k: 1 Loss: 0.2127661181669582\n",
      "Iteration: 841 lambda_k: 1 Loss: 0.21262410393274167\n",
      "Iteration: 842 lambda_k: 1 Loss: 0.21248224181308023\n",
      "Iteration: 843 lambda_k: 1 Loss: 0.21234053112620788\n",
      "Iteration: 844 lambda_k: 1 Loss: 0.21219897119488282\n",
      "Iteration: 845 lambda_k: 1 Loss: 0.21205756134635914\n",
      "Iteration: 846 lambda_k: 1 Loss: 0.21191630091235872\n",
      "Iteration: 847 lambda_k: 1 Loss: 0.2117751892290435\n",
      "Iteration: 848 lambda_k: 1 Loss: 0.2116342256369871\n",
      "Iteration: 849 lambda_k: 1 Loss: 0.211493409481148\n",
      "Iteration: 850 lambda_k: 1 Loss: 0.21135274011084165\n",
      "Iteration: 851 lambda_k: 1 Loss: 0.21121221687971364\n",
      "Iteration: 852 lambda_k: 1 Loss: 0.21107183914571273\n",
      "Iteration: 853 lambda_k: 1 Loss: 0.2109316062710641\n",
      "Iteration: 854 lambda_k: 1 Loss: 0.210791517622243\n",
      "Iteration: 855 lambda_k: 1 Loss: 0.2106515725699482\n",
      "Iteration: 856 lambda_k: 1 Loss: 0.21051177048907602\n",
      "Iteration: 857 lambda_k: 1 Loss: 0.21037211075869425\n",
      "Iteration: 858 lambda_k: 1 Loss: 0.21023259276201667\n",
      "Iteration: 859 lambda_k: 1 Loss: 0.21009321588637725\n",
      "Iteration: 860 lambda_k: 1 Loss: 0.20995397952320494\n",
      "Iteration: 861 lambda_k: 1 Loss: 0.20981488306799842\n",
      "Iteration: 862 lambda_k: 1 Loss: 0.20967592592030118\n",
      "Iteration: 863 lambda_k: 1 Loss: 0.20953710748367638\n",
      "Iteration: 864 lambda_k: 1 Loss: 0.2093984271656828\n",
      "Iteration: 865 lambda_k: 1 Loss: 0.20925988437784987\n",
      "Iteration: 866 lambda_k: 1 Loss: 0.20912147853565338\n",
      "Iteration: 867 lambda_k: 1 Loss: 0.20898320905849171\n",
      "Iteration: 868 lambda_k: 1 Loss: 0.20884507536966168\n",
      "Iteration: 869 lambda_k: 1 Loss: 0.20870707689633466\n",
      "Iteration: 870 lambda_k: 1 Loss: 0.2085692130695332\n",
      "Iteration: 871 lambda_k: 1 Loss: 0.2084314833241071\n",
      "Iteration: 872 lambda_k: 1 Loss: 0.20829388709871083\n",
      "Iteration: 873 lambda_k: 1 Loss: 0.20815642383577979\n",
      "Iteration: 874 lambda_k: 1 Loss: 0.2080190929815078\n",
      "Iteration: 875 lambda_k: 1 Loss: 0.20788189398582382\n",
      "Iteration: 876 lambda_k: 1 Loss: 0.2077448263023697\n",
      "Iteration: 877 lambda_k: 1 Loss: 0.20760788938847743\n",
      "Iteration: 878 lambda_k: 1 Loss: 0.20747108270514686\n",
      "Iteration: 879 lambda_k: 1 Loss: 0.20733440571702375\n",
      "Iteration: 880 lambda_k: 1 Loss: 0.20719785789237727\n",
      "Iteration: 881 lambda_k: 1 Loss: 0.20706143870307855\n",
      "Iteration: 882 lambda_k: 1 Loss: 0.20692514762457873\n",
      "Iteration: 883 lambda_k: 1 Loss: 0.20678898413588723\n",
      "Iteration: 884 lambda_k: 1 Loss: 0.2066529477195508\n",
      "Iteration: 885 lambda_k: 1 Loss: 0.20651703786428588\n",
      "Iteration: 886 lambda_k: 1 Loss: 0.2063812540554052\n",
      "Iteration: 887 lambda_k: 1 Loss: 0.20624559578752164\n",
      "Iteration: 888 lambda_k: 1 Loss: 0.20611006255697237\n",
      "Iteration: 889 lambda_k: 1 Loss: 0.2059746538638208\n",
      "Iteration: 890 lambda_k: 1 Loss: 0.2058393692113753\n",
      "Iteration: 891 lambda_k: 1 Loss: 0.20570420810631918\n",
      "Iteration: 892 lambda_k: 1 Loss: 0.2055691700587335\n",
      "Iteration: 893 lambda_k: 1 Loss: 0.20543425458312678\n",
      "Iteration: 894 lambda_k: 1 Loss: 0.20529946119359613\n",
      "Iteration: 895 lambda_k: 1 Loss: 0.2051647894118798\n",
      "Iteration: 896 lambda_k: 1 Loss: 0.20503023876173893\n",
      "Iteration: 897 lambda_k: 1 Loss: 0.20489580876954383\n",
      "Iteration: 898 lambda_k: 1 Loss: 0.20476149896501347\n",
      "Iteration: 899 lambda_k: 1 Loss: 0.2046273088812543\n",
      "Iteration: 900 lambda_k: 1 Loss: 0.20449323805463207\n",
      "Iteration: 901 lambda_k: 1 Loss: 0.20435928602469414\n",
      "Iteration: 902 lambda_k: 1 Loss: 0.20422545233414754\n",
      "Iteration: 903 lambda_k: 1 Loss: 0.2040917365288512\n",
      "Iteration: 904 lambda_k: 1 Loss: 0.20395813815780184\n",
      "Iteration: 905 lambda_k: 1 Loss: 0.20382465677311593\n",
      "Iteration: 906 lambda_k: 1 Loss: 0.20369129193000934\n",
      "Iteration: 907 lambda_k: 1 Loss: 0.20355804318677959\n",
      "Iteration: 908 lambda_k: 1 Loss: 0.2034249101047864\n",
      "Iteration: 909 lambda_k: 1 Loss: 0.2032918922484346\n",
      "Iteration: 910 lambda_k: 1 Loss: 0.2031589891851556\n",
      "Iteration: 911 lambda_k: 1 Loss: 0.20302620048538972\n",
      "Iteration: 912 lambda_k: 1 Loss: 0.20289352572256805\n",
      "Iteration: 913 lambda_k: 1 Loss: 0.20276096447309502\n",
      "Iteration: 914 lambda_k: 1 Loss: 0.20262851631633091\n",
      "Iteration: 915 lambda_k: 1 Loss: 0.20249618083457407\n",
      "Iteration: 916 lambda_k: 1 Loss: 0.20236395761304385\n",
      "Iteration: 917 lambda_k: 1 Loss: 0.202231846239863\n",
      "Iteration: 918 lambda_k: 1 Loss: 0.2020998463060411\n",
      "Iteration: 919 lambda_k: 1 Loss: 0.20196795740545698\n",
      "Iteration: 920 lambda_k: 1 Loss: 0.20183617913484195\n",
      "Iteration: 921 lambda_k: 1 Loss: 0.20170451109376336\n",
      "Iteration: 922 lambda_k: 1 Loss: 0.20157295288460747\n",
      "Iteration: 923 lambda_k: 1 Loss: 0.2014415041125629\n",
      "Iteration: 924 lambda_k: 1 Loss: 0.2013101643856045\n",
      "Iteration: 925 lambda_k: 1 Loss: 0.20117893331447653\n",
      "Iteration: 926 lambda_k: 1 Loss: 0.20104781051267673\n",
      "Iteration: 927 lambda_k: 1 Loss: 0.20091679559643988\n",
      "Iteration: 928 lambda_k: 1 Loss: 0.20078588818472198\n",
      "Iteration: 929 lambda_k: 1 Loss: 0.2006550878991841\n",
      "Iteration: 930 lambda_k: 1 Loss: 0.20052439436417666\n",
      "Iteration: 931 lambda_k: 1 Loss: 0.20039380720672362\n",
      "Iteration: 932 lambda_k: 1 Loss: 0.20026332605650674\n",
      "Iteration: 933 lambda_k: 1 Loss: 0.20013295054585015\n",
      "Iteration: 934 lambda_k: 1 Loss: 0.2000026803097048\n",
      "Iteration: 935 lambda_k: 1 Loss: 0.19987251498563322\n",
      "Iteration: 936 lambda_k: 1 Loss: 0.19974245421379402\n",
      "Iteration: 937 lambda_k: 1 Loss: 0.19961249763692704\n",
      "Iteration: 938 lambda_k: 1 Loss: 0.19948264490033804\n",
      "Iteration: 939 lambda_k: 1 Loss: 0.19935289565188385\n",
      "Iteration: 940 lambda_k: 1 Loss: 0.19922324954195741\n",
      "Iteration: 941 lambda_k: 1 Loss: 0.1990937062234731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 942 lambda_k: 1 Loss: 0.1989642653518519\n",
      "Iteration: 943 lambda_k: 1 Loss: 0.19883492658500698\n",
      "Iteration: 944 lambda_k: 1 Loss: 0.19870568958332901\n",
      "Iteration: 945 lambda_k: 1 Loss: 0.19857655400967195\n",
      "Iteration: 946 lambda_k: 1 Loss: 0.19844751952933848\n",
      "Iteration: 947 lambda_k: 1 Loss: 0.19831858581006606\n",
      "Iteration: 948 lambda_k: 1 Loss: 0.19818975252201254\n",
      "Iteration: 949 lambda_k: 1 Loss: 0.1980610193377423\n",
      "Iteration: 950 lambda_k: 1 Loss: 0.19793238593221207\n",
      "Iteration: 951 lambda_k: 1 Loss: 0.19780385198275757\n",
      "Iteration: 952 lambda_k: 1 Loss: 0.19767541716907888\n",
      "Iteration: 953 lambda_k: 1 Loss: 0.19754708117322747\n",
      "Iteration: 954 lambda_k: 1 Loss: 0.1974188436795925\n",
      "Iteration: 955 lambda_k: 1 Loss: 0.19729070437488683\n",
      "Iteration: 956 lambda_k: 1 Loss: 0.19716266294813414\n",
      "Iteration: 957 lambda_k: 1 Loss: 0.1970347190906552\n",
      "Iteration: 958 lambda_k: 1 Loss: 0.19690687249605493\n",
      "Iteration: 959 lambda_k: 1 Loss: 0.19677912286020874\n",
      "Iteration: 960 lambda_k: 1 Loss: 0.19665146988125004\n",
      "Iteration: 961 lambda_k: 1 Loss: 0.19652391325955665\n",
      "Iteration: 962 lambda_k: 1 Loss: 0.19639645269773826\n",
      "Iteration: 963 lambda_k: 1 Loss: 0.19626908790062345\n",
      "Iteration: 964 lambda_k: 1 Loss: 0.1961418185752468\n",
      "Iteration: 965 lambda_k: 1 Loss: 0.19601464443083627\n",
      "Iteration: 966 lambda_k: 1 Loss: 0.19588756517880096\n",
      "Iteration: 967 lambda_k: 1 Loss: 0.19576058053271783\n",
      "Iteration: 968 lambda_k: 1 Loss: 0.1956336902083199\n",
      "Iteration: 969 lambda_k: 1 Loss: 0.1955068939234835\n",
      "Iteration: 970 lambda_k: 1 Loss: 0.1953801913982161\n",
      "Iteration: 971 lambda_k: 1 Loss: 0.19525358235464435\n",
      "Iteration: 972 lambda_k: 1 Loss: 0.19512706651700143\n",
      "Iteration: 973 lambda_k: 1 Loss: 0.19500064361161523\n",
      "Iteration: 974 lambda_k: 1 Loss: 0.19487431336689656\n",
      "Iteration: 975 lambda_k: 1 Loss: 0.19474807551332693\n",
      "Iteration: 976 lambda_k: 1 Loss: 0.19462192978344672\n",
      "Iteration: 977 lambda_k: 1 Loss: 0.19449587591184378\n",
      "Iteration: 978 lambda_k: 1 Loss: 0.19436991363514125\n",
      "Iteration: 979 lambda_k: 1 Loss: 0.19424404269198636\n",
      "Iteration: 980 lambda_k: 1 Loss: 0.19411826282303846\n",
      "Iteration: 981 lambda_k: 1 Loss: 0.19399257377095805\n",
      "Iteration: 982 lambda_k: 1 Loss: 0.19386697528039495\n",
      "Iteration: 983 lambda_k: 1 Loss: 0.19374146709797715\n",
      "Iteration: 984 lambda_k: 1 Loss: 0.19361604897229964\n",
      "Iteration: 985 lambda_k: 1 Loss: 0.19349072065391298\n",
      "Iteration: 986 lambda_k: 1 Loss: 0.19336548189531247\n",
      "Iteration: 987 lambda_k: 1 Loss: 0.19324033245092684\n",
      "Iteration: 988 lambda_k: 1 Loss: 0.19311527207710735\n",
      "Iteration: 989 lambda_k: 1 Loss: 0.19299030053211713\n",
      "Iteration: 990 lambda_k: 1 Loss: 0.19286541757612002\n",
      "Iteration: 991 lambda_k: 1 Loss: 0.1927406229711698\n",
      "Iteration: 992 lambda_k: 1 Loss: 0.1926159164811998\n",
      "Iteration: 993 lambda_k: 1 Loss: 0.19249129787201186\n",
      "Iteration: 994 lambda_k: 1 Loss: 0.19236676691126606\n",
      "Iteration: 995 lambda_k: 1 Loss: 0.19224232336847003\n",
      "Iteration: 996 lambda_k: 1 Loss: 0.1921179670149686\n",
      "Iteration: 997 lambda_k: 1 Loss: 0.1919936976239335\n",
      "Iteration: 998 lambda_k: 1 Loss: 0.1918695149703529\n",
      "Iteration: 999 lambda_k: 1 Loss: 0.1917454188310212\n",
      "Iteration: 1000 lambda_k: 1 Loss: 0.19162140898452887\n",
      "Iteration: 1001 lambda_k: 1 Loss: 0.19149748521125226\n",
      "Iteration: 1002 lambda_k: 1 Loss: 0.1913736472933438\n",
      "Iteration: 1003 lambda_k: 1 Loss: 0.1912498950147217\n",
      "Iteration: 1004 lambda_k: 1 Loss: 0.19112622816106015\n",
      "Iteration: 1005 lambda_k: 1 Loss: 0.19100264651977944\n",
      "Iteration: 1006 lambda_k: 1 Loss: 0.19087914988003626\n",
      "Iteration: 1007 lambda_k: 1 Loss: 0.19075573803271362\n",
      "Iteration: 1008 lambda_k: 1 Loss: 0.19063241077041157\n",
      "Iteration: 1009 lambda_k: 1 Loss: 0.19050916788743746\n",
      "Iteration: 1010 lambda_k: 1 Loss: 0.19038600917979606\n",
      "Iteration: 1011 lambda_k: 1 Loss: 0.1902629344451805\n",
      "Iteration: 1012 lambda_k: 1 Loss: 0.19013994348296265\n",
      "Iteration: 1013 lambda_k: 1 Loss: 0.1900170360941836\n",
      "Iteration: 1014 lambda_k: 1 Loss: 0.1898942120815445\n",
      "Iteration: 1015 lambda_k: 1 Loss: 0.18977147124939722\n",
      "Iteration: 1016 lambda_k: 1 Loss: 0.18964881340373502\n",
      "Iteration: 1017 lambda_k: 1 Loss: 0.1895262383521838\n",
      "Iteration: 1018 lambda_k: 1 Loss: 0.18940374590399248\n",
      "Iteration: 1019 lambda_k: 1 Loss: 0.18928133587002427\n",
      "Iteration: 1020 lambda_k: 1 Loss: 0.18915900806274755\n",
      "Iteration: 1021 lambda_k: 1 Loss: 0.18903676229622707\n",
      "Iteration: 1022 lambda_k: 1 Loss: 0.1889145983861149\n",
      "Iteration: 1023 lambda_k: 1 Loss: 0.1887925161496417\n",
      "Iteration: 1024 lambda_k: 1 Loss: 0.1886705154056081\n",
      "Iteration: 1025 lambda_k: 1 Loss: 0.18854859597437565\n",
      "Iteration: 1026 lambda_k: 1 Loss: 0.18842675767785844\n",
      "Iteration: 1027 lambda_k: 1 Loss: 0.1883050003395143\n",
      "Iteration: 1028 lambda_k: 1 Loss: 0.18818332378433647\n",
      "Iteration: 1029 lambda_k: 1 Loss: 0.18806172783884495\n",
      "Iteration: 1030 lambda_k: 1 Loss: 0.1879402123310779\n",
      "Iteration: 1031 lambda_k: 1 Loss: 0.18781877709058367\n",
      "Iteration: 1032 lambda_k: 1 Loss: 0.18769742194841205\n",
      "Iteration: 1033 lambda_k: 1 Loss: 0.18757614673710613\n",
      "Iteration: 1034 lambda_k: 1 Loss: 0.187454951290694\n",
      "Iteration: 1035 lambda_k: 1 Loss: 0.18733383544468074\n",
      "Iteration: 1036 lambda_k: 1 Loss: 0.18721279903604018\n",
      "Iteration: 1037 lambda_k: 1 Loss: 0.18709184190320646\n",
      "Iteration: 1038 lambda_k: 1 Loss: 0.1869709638860666\n",
      "Iteration: 1039 lambda_k: 1 Loss: 0.18685016482595213\n",
      "Iteration: 1040 lambda_k: 1 Loss: 0.18672944456563126\n",
      "Iteration: 1041 lambda_k: 1 Loss: 0.18660880294930068\n",
      "Iteration: 1042 lambda_k: 1 Loss: 0.18648823982257845\n",
      "Iteration: 1043 lambda_k: 1 Loss: 0.18636775503249534\n",
      "Iteration: 1044 lambda_k: 1 Loss: 0.18624734842748744\n",
      "Iteration: 1045 lambda_k: 1 Loss: 0.18612701985738875\n",
      "Iteration: 1046 lambda_k: 1 Loss: 0.1860067691734231\n",
      "Iteration: 1047 lambda_k: 1 Loss: 0.18588659622819675\n",
      "Iteration: 1048 lambda_k: 1 Loss: 0.18576650087569055\n",
      "Iteration: 1049 lambda_k: 1 Loss: 0.18564648297125297\n",
      "Iteration: 1050 lambda_k: 1 Loss: 0.1855265423715919\n",
      "Iteration: 1051 lambda_k: 1 Loss: 0.18540667893476798\n",
      "Iteration: 1052 lambda_k: 1 Loss: 0.1852868925201865\n",
      "Iteration: 1053 lambda_k: 1 Loss: 0.18516718298859078\n",
      "Iteration: 1054 lambda_k: 1 Loss: 0.18504755020205416\n",
      "Iteration: 1055 lambda_k: 1 Loss: 0.1849279940239732\n",
      "Iteration: 1056 lambda_k: 1 Loss: 0.18480851431906042\n",
      "Iteration: 1057 lambda_k: 1 Loss: 0.184689110953337\n",
      "Iteration: 1058 lambda_k: 1 Loss: 0.18456978379412586\n",
      "Iteration: 1059 lambda_k: 1 Loss: 0.18445053271004422\n",
      "Iteration: 1060 lambda_k: 1 Loss: 0.18433135757099708\n",
      "Iteration: 1061 lambda_k: 1 Loss: 0.1842122582481698\n",
      "Iteration: 1062 lambda_k: 1 Loss: 0.18409323461402133\n",
      "Iteration: 1063 lambda_k: 1 Loss: 0.18397428654227718\n",
      "Iteration: 1064 lambda_k: 1 Loss: 0.1838554139079229\n",
      "Iteration: 1065 lambda_k: 1 Loss: 0.1837366165871967\n",
      "Iteration: 1066 lambda_k: 1 Loss: 0.18361789445758317\n",
      "Iteration: 1067 lambda_k: 1 Loss: 0.18349924739780624\n",
      "Iteration: 1068 lambda_k: 1 Loss: 0.1833806752878225\n",
      "Iteration: 1069 lambda_k: 1 Loss: 0.1832621780088148\n",
      "Iteration: 1070 lambda_k: 1 Loss: 0.18314375544318526\n",
      "Iteration: 1071 lambda_k: 1 Loss: 0.1830254074745488\n",
      "Iteration: 1072 lambda_k: 1 Loss: 0.1829071339877268\n",
      "Iteration: 1073 lambda_k: 1 Loss: 0.18278893486874026\n",
      "Iteration: 1074 lambda_k: 1 Loss: 0.18267081000480365\n",
      "Iteration: 1075 lambda_k: 1 Loss: 0.1825527592843183\n",
      "Iteration: 1076 lambda_k: 1 Loss: 0.18243478259686596\n",
      "Iteration: 1077 lambda_k: 1 Loss: 0.18231687983320252\n",
      "Iteration: 1078 lambda_k: 1 Loss: 0.18219905088525185\n",
      "Iteration: 1079 lambda_k: 1 Loss: 0.1820812956460991\n",
      "Iteration: 1080 lambda_k: 1 Loss: 0.18196361400998504\n",
      "Iteration: 1081 lambda_k: 1 Loss: 0.18184600587229932\n",
      "Iteration: 1082 lambda_k: 1 Loss: 0.18172847112957452\n",
      "Iteration: 1083 lambda_k: 1 Loss: 0.18161100967948005\n",
      "Iteration: 1084 lambda_k: 1 Loss: 0.181493621420816\n",
      "Iteration: 1085 lambda_k: 1 Loss: 0.1813763062535071\n",
      "Iteration: 1086 lambda_k: 1 Loss: 0.18125906407859668\n",
      "Iteration: 1087 lambda_k: 1 Loss: 0.1811418947982406\n",
      "Iteration: 1088 lambda_k: 1 Loss: 0.18102479831570148\n",
      "Iteration: 1089 lambda_k: 1 Loss: 0.18090777453534262\n",
      "Iteration: 1090 lambda_k: 1 Loss: 0.1807908233626221\n",
      "Iteration: 1091 lambda_k: 1 Loss: 0.18067394470408704\n",
      "Iteration: 1092 lambda_k: 1 Loss: 0.1805571384673677\n",
      "Iteration: 1093 lambda_k: 1 Loss: 0.18044040456117177\n",
      "Iteration: 1094 lambda_k: 1 Loss: 0.1803237428952785\n",
      "Iteration: 1095 lambda_k: 1 Loss: 0.1802071533805331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1096 lambda_k: 1 Loss: 0.18009063592884086\n",
      "Iteration: 1097 lambda_k: 1 Loss: 0.1799741904531618\n",
      "Iteration: 1098 lambda_k: 1 Loss: 0.17985781686750474\n",
      "Iteration: 1099 lambda_k: 1 Loss: 0.17974151508692196\n",
      "Iteration: 1100 lambda_k: 1 Loss: 0.1796252850275035\n",
      "Iteration: 1101 lambda_k: 1 Loss: 0.1795091266063716\n",
      "Iteration: 1102 lambda_k: 1 Loss: 0.17939303974167536\n",
      "Iteration: 1103 lambda_k: 1 Loss: 0.17927702435258516\n",
      "Iteration: 1104 lambda_k: 1 Loss: 0.17916108035928727\n",
      "Iteration: 1105 lambda_k: 1 Loss: 0.1790452076829783\n",
      "Iteration: 1106 lambda_k: 1 Loss: 0.17892940624586015\n",
      "Iteration: 1107 lambda_k: 1 Loss: 0.17881367597113446\n",
      "Iteration: 1108 lambda_k: 1 Loss: 0.17869801678299727\n",
      "Iteration: 1109 lambda_k: 1 Loss: 0.1785824286066338\n",
      "Iteration: 1110 lambda_k: 1 Loss: 0.17846691136821322\n",
      "Iteration: 1111 lambda_k: 1 Loss: 0.17835146499488344\n",
      "Iteration: 1112 lambda_k: 1 Loss: 0.1782360894147659\n",
      "Iteration: 1113 lambda_k: 1 Loss: 0.17812078455695032\n",
      "Iteration: 1114 lambda_k: 1 Loss: 0.17800555035148968\n",
      "Iteration: 1115 lambda_k: 1 Loss: 0.1778903867293952\n",
      "Iteration: 1116 lambda_k: 1 Loss: 0.17777529362263103\n",
      "Iteration: 1117 lambda_k: 1 Loss: 0.17766027096410938\n",
      "Iteration: 1118 lambda_k: 1 Loss: 0.17754531868768544\n",
      "Iteration: 1119 lambda_k: 1 Loss: 0.17743043672815242\n",
      "Iteration: 1120 lambda_k: 1 Loss: 0.1773156250212366\n",
      "Iteration: 1121 lambda_k: 1 Loss: 0.1772008835035923\n",
      "Iteration: 1122 lambda_k: 1 Loss: 0.1770862121127971\n",
      "Iteration: 1123 lambda_k: 1 Loss: 0.17697161078734697\n",
      "Iteration: 1124 lambda_k: 1 Loss: 0.17685707946665125\n",
      "Iteration: 1125 lambda_k: 1 Loss: 0.17674261809102795\n",
      "Iteration: 1126 lambda_k: 1 Loss: 0.1766282266016991\n",
      "Iteration: 1127 lambda_k: 1 Loss: 0.1765139049407857\n",
      "Iteration: 1128 lambda_k: 1 Loss: 0.17639965305130298\n",
      "Iteration: 1129 lambda_k: 1 Loss: 0.1762854708771561\n",
      "Iteration: 1130 lambda_k: 1 Loss: 0.17617135836313497\n",
      "Iteration: 1131 lambda_k: 1 Loss: 0.1760573154549097\n",
      "Iteration: 1132 lambda_k: 1 Loss: 0.1759433420990264\n",
      "Iteration: 1133 lambda_k: 1 Loss: 0.17582943824290187\n",
      "Iteration: 1134 lambda_k: 1 Loss: 0.17571560383481952\n",
      "Iteration: 1135 lambda_k: 1 Loss: 0.17560183882392463\n",
      "Iteration: 1136 lambda_k: 1 Loss: 0.17548814316021982\n",
      "Iteration: 1137 lambda_k: 1 Loss: 0.1753745167945606\n",
      "Iteration: 1138 lambda_k: 1 Loss: 0.17526095967865088\n",
      "Iteration: 1139 lambda_k: 1 Loss: 0.17514747176503834\n",
      "Iteration: 1140 lambda_k: 1 Loss: 0.1750340530071103\n",
      "Iteration: 1141 lambda_k: 1 Loss: 0.1749207033590891\n",
      "Iteration: 1142 lambda_k: 1 Loss: 0.1748074227760277\n",
      "Iteration: 1143 lambda_k: 1 Loss: 0.17469421121380552\n",
      "Iteration: 1144 lambda_k: 1 Loss: 0.17458106862912384\n",
      "Iteration: 1145 lambda_k: 1 Loss: 0.17446799497950172\n",
      "Iteration: 1146 lambda_k: 1 Loss: 0.17435499022327167\n",
      "Iteration: 1147 lambda_k: 1 Loss: 0.17424205431957515\n",
      "Iteration: 1148 lambda_k: 1 Loss: 0.17412918722835885\n",
      "Iteration: 1149 lambda_k: 1 Loss: 0.1740163889103698\n",
      "Iteration: 1150 lambda_k: 1 Loss: 0.1739036593271518\n",
      "Iteration: 1151 lambda_k: 1 Loss: 0.17379099844104093\n",
      "Iteration: 1152 lambda_k: 1 Loss: 0.17367840621516137\n",
      "Iteration: 1153 lambda_k: 1 Loss: 0.1735658826134216\n",
      "Iteration: 1154 lambda_k: 1 Loss: 0.17345342760050997\n",
      "Iteration: 1155 lambda_k: 1 Loss: 0.17334104114189072\n",
      "Iteration: 1156 lambda_k: 1 Loss: 0.17322872320380012\n",
      "Iteration: 1157 lambda_k: 1 Loss: 0.1731164737532422\n",
      "Iteration: 1158 lambda_k: 1 Loss: 0.17300429275798496\n",
      "Iteration: 1159 lambda_k: 1 Loss: 0.17289218018655628\n",
      "Iteration: 1160 lambda_k: 1 Loss: 0.17278013600823985\n",
      "Iteration: 1161 lambda_k: 1 Loss: 0.1726681601930716\n",
      "Iteration: 1162 lambda_k: 1 Loss: 0.17255625271183545\n",
      "Iteration: 1163 lambda_k: 1 Loss: 0.17244441353605958\n",
      "Iteration: 1164 lambda_k: 1 Loss: 0.1723326426380127\n",
      "Iteration: 1165 lambda_k: 1 Loss: 0.17222093999069985\n",
      "Iteration: 1166 lambda_k: 1 Loss: 0.172109305567859\n",
      "Iteration: 1167 lambda_k: 1 Loss: 0.17199773934395696\n",
      "Iteration: 1168 lambda_k: 1 Loss: 0.1718862412941859\n",
      "Iteration: 1169 lambda_k: 1 Loss: 0.17177481139445933\n",
      "Iteration: 1170 lambda_k: 1 Loss: 0.17166344962140853\n",
      "Iteration: 1171 lambda_k: 1 Loss: 0.1715521559523788\n",
      "Iteration: 1172 lambda_k: 1 Loss: 0.17144093036542601\n",
      "Iteration: 1173 lambda_k: 1 Loss: 0.17132977283931256\n",
      "Iteration: 1174 lambda_k: 1 Loss: 0.17121868335350407\n",
      "Iteration: 1175 lambda_k: 1 Loss: 0.17110766188816565\n",
      "Iteration: 1176 lambda_k: 1 Loss: 0.17099670842415846\n",
      "Iteration: 1177 lambda_k: 1 Loss: 0.17088582294303595\n",
      "Iteration: 1178 lambda_k: 1 Loss: 0.17077500542704047\n",
      "Iteration: 1179 lambda_k: 1 Loss: 0.17066425585909978\n",
      "Iteration: 1180 lambda_k: 1 Loss: 0.1705535742228235\n",
      "Iteration: 1181 lambda_k: 1 Loss: 0.17044296050249969\n",
      "Iteration: 1182 lambda_k: 1 Loss: 0.17033241468309135\n",
      "Iteration: 1183 lambda_k: 1 Loss: 0.17022193675023325\n",
      "Iteration: 1184 lambda_k: 1 Loss: 0.1701115266902282\n",
      "Iteration: 1185 lambda_k: 1 Loss: 0.17000118449004378\n",
      "Iteration: 1186 lambda_k: 1 Loss: 0.16989091013730934\n",
      "Iteration: 1187 lambda_k: 1 Loss: 0.16978070362031214\n",
      "Iteration: 1188 lambda_k: 1 Loss: 0.16967056492799454\n",
      "Iteration: 1189 lambda_k: 1 Loss: 0.16956049404995047\n",
      "Iteration: 1190 lambda_k: 1 Loss: 0.1694504909764223\n",
      "Iteration: 1191 lambda_k: 1 Loss: 0.16934055569829748\n",
      "Iteration: 1192 lambda_k: 1 Loss: 0.16923068820710563\n",
      "Iteration: 1193 lambda_k: 1 Loss: 0.16912088849501491\n",
      "Iteration: 1194 lambda_k: 1 Loss: 0.16901115655482937\n",
      "Iteration: 1195 lambda_k: 1 Loss: 0.16890149237998564\n",
      "Iteration: 1196 lambda_k: 1 Loss: 0.16879189596454963\n",
      "Iteration: 1197 lambda_k: 1 Loss: 0.16868236730321384\n",
      "Iteration: 1198 lambda_k: 1 Loss: 0.16857290639129396\n",
      "Iteration: 1199 lambda_k: 1 Loss: 0.16846351322472614\n",
      "Iteration: 1200 lambda_k: 1 Loss: 0.16835418780006375\n",
      "Iteration: 1201 lambda_k: 1 Loss: 0.16824493011447458\n",
      "Iteration: 1202 lambda_k: 1 Loss: 0.1681357401657379\n",
      "Iteration: 1203 lambda_k: 1 Loss: 0.16802661795224139\n",
      "Iteration: 1204 lambda_k: 1 Loss: 0.16791756347297837\n",
      "Iteration: 1205 lambda_k: 1 Loss: 0.16780857672754496\n",
      "Iteration: 1206 lambda_k: 1 Loss: 0.16769965771613712\n",
      "Iteration: 1207 lambda_k: 1 Loss: 0.16759080643954793\n",
      "Iteration: 1208 lambda_k: 1 Loss: 0.16748202289916472\n",
      "Iteration: 1209 lambda_k: 1 Loss: 0.16737330709696638\n",
      "Iteration: 1210 lambda_k: 1 Loss: 0.1672646590355207\n",
      "Iteration: 1211 lambda_k: 1 Loss: 0.16715607871798135\n",
      "Iteration: 1212 lambda_k: 1 Loss: 0.16704756614808564\n",
      "Iteration: 1213 lambda_k: 1 Loss: 0.1669391213301513\n",
      "Iteration: 1214 lambda_k: 1 Loss: 0.16683074426907454\n",
      "Iteration: 1215 lambda_k: 1 Loss: 0.16672243497032688\n",
      "Iteration: 1216 lambda_k: 1 Loss: 0.1666141934399527\n",
      "Iteration: 1217 lambda_k: 1 Loss: 0.1665060196845669\n",
      "Iteration: 1218 lambda_k: 1 Loss: 0.16639791371135226\n",
      "Iteration: 1219 lambda_k: 1 Loss: 0.16628987552805666\n",
      "Iteration: 1220 lambda_k: 1 Loss: 0.16618190873033922\n",
      "Iteration: 1221 lambda_k: 1 Loss: 0.16607471500866214\n",
      "Iteration: 1222 lambda_k: 1 Loss: 0.16596758613834275\n",
      "Iteration: 1223 lambda_k: 1 Loss: 0.16586052214176952\n",
      "Iteration: 1224 lambda_k: 1 Loss: 0.16575352304183222\n",
      "Iteration: 1225 lambda_k: 1 Loss: 0.1656465888619202\n",
      "Iteration: 1226 lambda_k: 1 Loss: 0.16553971962591968\n",
      "Iteration: 1227 lambda_k: 1 Loss: 0.16543291535821225\n",
      "Iteration: 1228 lambda_k: 1 Loss: 0.16532617608367245\n",
      "Iteration: 1229 lambda_k: 1 Loss: 0.16521950182766604\n",
      "Iteration: 1230 lambda_k: 1 Loss: 0.1651128926160477\n",
      "Iteration: 1231 lambda_k: 1 Loss: 0.16500634847515946\n",
      "Iteration: 1232 lambda_k: 1 Loss: 0.16489986943182855\n",
      "Iteration: 1233 lambda_k: 1 Loss: 0.1647934555133654\n",
      "Iteration: 1234 lambda_k: 1 Loss: 0.1646871067475621\n",
      "Iteration: 1235 lambda_k: 1 Loss: 0.1645808231626902\n",
      "Iteration: 1236 lambda_k: 1 Loss: 0.16447460478749923\n",
      "Iteration: 1237 lambda_k: 1 Loss: 0.16436845165121455\n",
      "Iteration: 1238 lambda_k: 1 Loss: 0.16426236378353598\n",
      "Iteration: 1239 lambda_k: 1 Loss: 0.16415634121463565\n",
      "Iteration: 1240 lambda_k: 1 Loss: 0.1640503839751567\n",
      "Iteration: 1241 lambda_k: 1 Loss: 0.16394449209621137\n",
      "Iteration: 1242 lambda_k: 1 Loss: 0.16383866560937935\n",
      "Iteration: 1243 lambda_k: 1 Loss: 0.16373290454670628\n",
      "Iteration: 1244 lambda_k: 1 Loss: 0.163627208940702\n",
      "Iteration: 1245 lambda_k: 1 Loss: 0.16352157882433924\n",
      "Iteration: 1246 lambda_k: 1 Loss: 0.16341601423105168\n",
      "Iteration: 1247 lambda_k: 1 Loss: 0.16331051519473283\n",
      "Iteration: 1248 lambda_k: 1 Loss: 0.16320508174973436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1249 lambda_k: 1 Loss: 0.16309971393086473\n",
      "Iteration: 1250 lambda_k: 1 Loss: 0.16299441177338758\n",
      "Iteration: 1251 lambda_k: 1 Loss: 0.16288917531302055\n",
      "Iteration: 1252 lambda_k: 1 Loss: 0.16278400458593378\n",
      "Iteration: 1253 lambda_k: 1 Loss: 0.16267889962874868\n",
      "Iteration: 1254 lambda_k: 1 Loss: 0.1625738604785364\n",
      "Iteration: 1255 lambda_k: 1 Loss: 0.16246888717281682\n",
      "Iteration: 1256 lambda_k: 1 Loss: 0.16236397974955705\n",
      "Iteration: 1257 lambda_k: 1 Loss: 0.16225913824717028\n",
      "Iteration: 1258 lambda_k: 1 Loss: 0.1621543627045147\n",
      "Iteration: 1259 lambda_k: 1 Loss: 0.16204965316089204\n",
      "Iteration: 1260 lambda_k: 1 Loss: 0.1619450096560466\n",
      "Iteration: 1261 lambda_k: 1 Loss: 0.16184043223016414\n",
      "Iteration: 1262 lambda_k: 1 Loss: 0.16173592092387076\n",
      "Iteration: 1263 lambda_k: 1 Loss: 0.16163147577823164\n",
      "Iteration: 1264 lambda_k: 1 Loss: 0.16152709683475033\n",
      "Iteration: 1265 lambda_k: 1 Loss: 0.16142278413536734\n",
      "Iteration: 1266 lambda_k: 1 Loss: 0.1613185377224595\n",
      "Iteration: 1267 lambda_k: 1 Loss: 0.16121435763883873\n",
      "Iteration: 1268 lambda_k: 1 Loss: 0.1611102439277512\n",
      "Iteration: 1269 lambda_k: 1 Loss: 0.16100619663287635\n",
      "Iteration: 1270 lambda_k: 1 Loss: 0.16090221579832606\n",
      "Iteration: 1271 lambda_k: 1 Loss: 0.1607983014686437\n",
      "Iteration: 1272 lambda_k: 1 Loss: 0.1606944536888034\n",
      "Iteration: 1273 lambda_k: 1 Loss: 0.16059067250420966\n",
      "Iteration: 1274 lambda_k: 1 Loss: 0.16048695796069554\n",
      "Iteration: 1275 lambda_k: 1 Loss: 0.1603833101045222\n",
      "Iteration: 1276 lambda_k: 1 Loss: 0.1602797289823774\n",
      "Iteration: 1277 lambda_k: 1 Loss: 0.16017621464137707\n",
      "Iteration: 1278 lambda_k: 1 Loss: 0.16007276712906324\n",
      "Iteration: 1279 lambda_k: 1 Loss: 0.159969386493403\n",
      "Iteration: 1280 lambda_k: 1 Loss: 0.15986607278278828\n",
      "Iteration: 1281 lambda_k: 1 Loss: 0.15976282604603476\n",
      "Iteration: 1282 lambda_k: 1 Loss: 0.15965964633238183\n",
      "Iteration: 1283 lambda_k: 1 Loss: 0.1595565336914917\n",
      "Iteration: 1284 lambda_k: 1 Loss: 0.15945348817344882\n",
      "Iteration: 1285 lambda_k: 1 Loss: 0.1593505098287593\n",
      "Iteration: 1286 lambda_k: 1 Loss: 0.15924759870835062\n",
      "Iteration: 1287 lambda_k: 1 Loss: 0.15914475486357071\n",
      "Iteration: 1288 lambda_k: 1 Loss: 0.1590419783461876\n",
      "Iteration: 1289 lambda_k: 1 Loss: 0.15893926920838927\n",
      "Iteration: 1290 lambda_k: 1 Loss: 0.1588366275027826\n",
      "Iteration: 1291 lambda_k: 1 Loss: 0.15873405328239337\n",
      "Iteration: 1292 lambda_k: 1 Loss: 0.15863154660066564\n",
      "Iteration: 1293 lambda_k: 1 Loss: 0.1585291075114614\n",
      "Iteration: 1294 lambda_k: 1 Loss: 0.15842673606906016\n",
      "Iteration: 1295 lambda_k: 1 Loss: 0.15832443232815846\n",
      "Iteration: 1296 lambda_k: 1 Loss: 0.15822219634386975\n",
      "Iteration: 1297 lambda_k: 1 Loss: 0.1581203710478692\n",
      "Iteration: 1298 lambda_k: 1 Loss: 0.15801921366706914\n",
      "Iteration: 1299 lambda_k: 1 Loss: 0.15791811826991006\n",
      "Iteration: 1300 lambda_k: 1 Loss: 0.1578170849505985\n",
      "Iteration: 1301 lambda_k: 1 Loss: 0.15771611380352055\n",
      "Iteration: 1302 lambda_k: 1 Loss: 0.15761520492324282\n",
      "Iteration: 1303 lambda_k: 1 Loss: 0.1575143584045136\n",
      "Iteration: 1304 lambda_k: 1 Loss: 0.15741357434226427\n",
      "Iteration: 1305 lambda_k: 1 Loss: 0.1573128528316104\n",
      "Iteration: 1306 lambda_k: 1 Loss: 0.15721219396785285\n",
      "Iteration: 1307 lambda_k: 1 Loss: 0.1571115978464793\n",
      "Iteration: 1308 lambda_k: 1 Loss: 0.15701106456316513\n",
      "Iteration: 1309 lambda_k: 1 Loss: 0.15691059421377493\n",
      "Iteration: 1310 lambda_k: 1 Loss: 0.1568101868943635\n",
      "Iteration: 1311 lambda_k: 1 Loss: 0.15670984270117722\n",
      "Iteration: 1312 lambda_k: 1 Loss: 0.15660956173065518\n",
      "Iteration: 1313 lambda_k: 1 Loss: 0.15650934407943048\n",
      "Iteration: 1314 lambda_k: 1 Loss: 0.156409189845154\n",
      "Iteration: 1315 lambda_k: 1 Loss: 0.15630909912362242\n",
      "Iteration: 1316 lambda_k: 1 Loss: 0.15620907201203527\n",
      "Iteration: 1317 lambda_k: 1 Loss: 0.1561091086081642\n",
      "Iteration: 1318 lambda_k: 1 Loss: 0.1560092090097618\n",
      "Iteration: 1319 lambda_k: 1 Loss: 0.1559093733146349\n",
      "Iteration: 1320 lambda_k: 1 Loss: 0.15580960162077534\n",
      "Iteration: 1321 lambda_k: 1 Loss: 0.15570989402640084\n",
      "Iteration: 1322 lambda_k: 1 Loss: 0.15561025062994707\n",
      "Iteration: 1323 lambda_k: 1 Loss: 0.15551067153005693\n",
      "Iteration: 1324 lambda_k: 1 Loss: 0.15541115682557813\n",
      "Iteration: 1325 lambda_k: 1 Loss: 0.1553117066155658\n",
      "Iteration: 1326 lambda_k: 1 Loss: 0.15521232099928473\n",
      "Iteration: 1327 lambda_k: 1 Loss: 0.15511300007621057\n",
      "Iteration: 1328 lambda_k: 1 Loss: 0.15501374394603104\n",
      "Iteration: 1329 lambda_k: 1 Loss: 0.15491455270864696\n",
      "Iteration: 1330 lambda_k: 1 Loss: 0.15481542646417346\n",
      "Iteration: 1331 lambda_k: 1 Loss: 0.15471636531294092\n",
      "Iteration: 1332 lambda_k: 1 Loss: 0.1546173693554964\n",
      "Iteration: 1333 lambda_k: 1 Loss: 0.15451843869260445\n",
      "Iteration: 1334 lambda_k: 1 Loss: 0.15441957342524854\n",
      "Iteration: 1335 lambda_k: 1 Loss: 0.1543207736546319\n",
      "Iteration: 1336 lambda_k: 1 Loss: 0.1542220394821788\n",
      "Iteration: 1337 lambda_k: 1 Loss: 0.1541233710095356\n",
      "Iteration: 1338 lambda_k: 1 Loss: 0.1540247683385716\n",
      "Iteration: 1339 lambda_k: 1 Loss: 0.15392623157138058\n",
      "Iteration: 1340 lambda_k: 1 Loss: 0.15382776081028135\n",
      "Iteration: 1341 lambda_k: 1 Loss: 0.15372935615781916\n",
      "Iteration: 1342 lambda_k: 1 Loss: 0.15363101771676652\n",
      "Iteration: 1343 lambda_k: 1 Loss: 0.15353274559012048\n",
      "Iteration: 1344 lambda_k: 1 Loss: 0.15343453988110417\n",
      "Iteration: 1345 lambda_k: 1 Loss: 0.15333640069318547\n",
      "Iteration: 1346 lambda_k: 1 Loss: 0.15323832813006152\n",
      "Iteration: 1347 lambda_k: 1 Loss: 0.1531403222956572\n",
      "Iteration: 1348 lambda_k: 1 Loss: 0.1530423832941293\n",
      "Iteration: 1349 lambda_k: 1 Loss: 0.15294451122986946\n",
      "Iteration: 1350 lambda_k: 1 Loss: 0.15284670620749527\n",
      "Iteration: 1351 lambda_k: 1 Loss: 0.15274896833186474\n",
      "Iteration: 1352 lambda_k: 1 Loss: 0.15265129770808833\n",
      "Iteration: 1353 lambda_k: 1 Loss: 0.1525536944415097\n",
      "Iteration: 1354 lambda_k: 1 Loss: 0.15245615863770548\n",
      "Iteration: 1355 lambda_k: 1 Loss: 0.15235869040249023\n",
      "Iteration: 1356 lambda_k: 1 Loss: 0.15226128984191975\n",
      "Iteration: 1357 lambda_k: 1 Loss: 0.15216395706229197\n",
      "Iteration: 1358 lambda_k: 1 Loss: 0.15206669217014673\n",
      "Iteration: 1359 lambda_k: 1 Loss: 0.15196949527180514\n",
      "Iteration: 1360 lambda_k: 1 Loss: 0.15187236647499838\n",
      "Iteration: 1361 lambda_k: 1 Loss: 0.15177530588699684\n",
      "Iteration: 1362 lambda_k: 1 Loss: 0.15167831361511355\n",
      "Iteration: 1363 lambda_k: 1 Loss: 0.1515813897670391\n",
      "Iteration: 1364 lambda_k: 1 Loss: 0.15148453445079307\n",
      "Iteration: 1365 lambda_k: 1 Loss: 0.15138774777465092\n",
      "Iteration: 1366 lambda_k: 1 Loss: 0.15129102984712306\n",
      "Iteration: 1367 lambda_k: 1 Loss: 0.15119438077696126\n",
      "Iteration: 1368 lambda_k: 1 Loss: 0.15109780067316644\n",
      "Iteration: 1369 lambda_k: 1 Loss: 0.15100128964499082\n",
      "Iteration: 1370 lambda_k: 1 Loss: 0.15090484780193797\n",
      "Iteration: 1371 lambda_k: 1 Loss: 0.15080847525376276\n",
      "Iteration: 1372 lambda_k: 1 Loss: 0.15071217211047194\n",
      "Iteration: 1373 lambda_k: 1 Loss: 0.150615938482325\n",
      "Iteration: 1374 lambda_k: 1 Loss: 0.15051977447983403\n",
      "Iteration: 1375 lambda_k: 1 Loss: 0.15042368021376454\n",
      "Iteration: 1376 lambda_k: 1 Loss: 0.15032765579513652\n",
      "Iteration: 1377 lambda_k: 1 Loss: 0.15023170133522454\n",
      "Iteration: 1378 lambda_k: 1 Loss: 0.15013581694555844\n",
      "Iteration: 1379 lambda_k: 1 Loss: 0.15004000273792364\n",
      "Iteration: 1380 lambda_k: 1 Loss: 0.14994425882436166\n",
      "Iteration: 1381 lambda_k: 1 Loss: 0.14984858531717055\n",
      "Iteration: 1382 lambda_k: 1 Loss: 0.14975298232890535\n",
      "Iteration: 1383 lambda_k: 1 Loss: 0.1496574499723785\n",
      "Iteration: 1384 lambda_k: 1 Loss: 0.14956198836066031\n",
      "Iteration: 1385 lambda_k: 1 Loss: 0.1494665976070791\n",
      "Iteration: 1386 lambda_k: 1 Loss: 0.14937127782522194\n",
      "Iteration: 1387 lambda_k: 1 Loss: 0.14927602912893462\n",
      "Iteration: 1388 lambda_k: 1 Loss: 0.14918085163232234\n",
      "Iteration: 1389 lambda_k: 1 Loss: 0.14908574544974973\n",
      "Iteration: 1390 lambda_k: 1 Loss: 0.14899071069584133\n",
      "Iteration: 1391 lambda_k: 1 Loss: 0.14889574748548184\n",
      "Iteration: 1392 lambda_k: 1 Loss: 0.1488008559338164\n",
      "Iteration: 1393 lambda_k: 1 Loss: 0.14870603615625075\n",
      "Iteration: 1394 lambda_k: 1 Loss: 0.1486112882684517\n",
      "Iteration: 1395 lambda_k: 1 Loss: 0.14851661238634709\n",
      "Iteration: 1396 lambda_k: 1 Loss: 0.1484220086261261\n",
      "Iteration: 1397 lambda_k: 1 Loss: 0.14832747710423966\n",
      "Iteration: 1398 lambda_k: 1 Loss: 0.14823301793740015\n",
      "Iteration: 1399 lambda_k: 1 Loss: 0.14813863124258211\n",
      "Iteration: 1400 lambda_k: 1 Loss: 0.14804431713702199\n",
      "Iteration: 1401 lambda_k: 1 Loss: 0.14795007573557398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1402 lambda_k: 1 Loss: 0.14785590716000555\n",
      "Iteration: 1403 lambda_k: 1 Loss: 0.14776181152712775\n",
      "Iteration: 1404 lambda_k: 1 Loss: 0.14766778895525826\n",
      "Iteration: 1405 lambda_k: 1 Loss: 0.14757383956278292\n",
      "Iteration: 1406 lambda_k: 1 Loss: 0.1474799634685276\n",
      "Iteration: 1407 lambda_k: 1 Loss: 0.14738616079159902\n",
      "Iteration: 1408 lambda_k: 1 Loss: 0.14729243165133923\n",
      "Iteration: 1409 lambda_k: 1 Loss: 0.14719877616733834\n",
      "Iteration: 1410 lambda_k: 1 Loss: 0.14710519445944914\n",
      "Iteration: 1411 lambda_k: 1 Loss: 0.14701168664779074\n",
      "Iteration: 1412 lambda_k: 1 Loss: 0.14691825285274687\n",
      "Iteration: 1413 lambda_k: 1 Loss: 0.1468248931949645\n",
      "Iteration: 1414 lambda_k: 1 Loss: 0.14673160779535344\n",
      "Iteration: 1415 lambda_k: 1 Loss: 0.1466383967750863\n",
      "Iteration: 1416 lambda_k: 1 Loss: 0.14654526026231957\n",
      "Iteration: 1417 lambda_k: 1 Loss: 0.14645219836832032\n",
      "Iteration: 1418 lambda_k: 1 Loss: 0.14635921121649534\n",
      "Iteration: 1419 lambda_k: 1 Loss: 0.14626629893083418\n",
      "Iteration: 1420 lambda_k: 1 Loss: 0.14617346163462389\n",
      "Iteration: 1421 lambda_k: 1 Loss: 0.14608069945048965\n",
      "Iteration: 1422 lambda_k: 1 Loss: 0.14598801250123133\n",
      "Iteration: 1423 lambda_k: 1 Loss: 0.1458954009100604\n",
      "Iteration: 1424 lambda_k: 1 Loss: 0.14580286480053156\n",
      "Iteration: 1425 lambda_k: 1 Loss: 0.1457104042964649\n",
      "Iteration: 1426 lambda_k: 1 Loss: 0.14561801952192654\n",
      "Iteration: 1427 lambda_k: 1 Loss: 0.14552571060123604\n",
      "Iteration: 1428 lambda_k: 1 Loss: 0.14543347765897352\n",
      "Iteration: 1429 lambda_k: 1 Loss: 0.1453413208199807\n",
      "Iteration: 1430 lambda_k: 1 Loss: 0.14524924020936006\n",
      "Iteration: 1431 lambda_k: 1 Loss: 0.1451572359524739\n",
      "Iteration: 1432 lambda_k: 1 Loss: 0.14506530817494515\n",
      "Iteration: 1433 lambda_k: 1 Loss: 0.14497345700267603\n",
      "Iteration: 1434 lambda_k: 1 Loss: 0.14488168256009257\n",
      "Iteration: 1435 lambda_k: 1 Loss: 0.14478998497618525\n",
      "Iteration: 1436 lambda_k: 1 Loss: 0.14469836437762576\n",
      "Iteration: 1437 lambda_k: 1 Loss: 0.14460682089056945\n",
      "Iteration: 1438 lambda_k: 1 Loss: 0.1445153546419244\n",
      "Iteration: 1439 lambda_k: 1 Loss: 0.14442396575916477\n",
      "Iteration: 1440 lambda_k: 1 Loss: 0.14433265437005358\n",
      "Iteration: 1441 lambda_k: 1 Loss: 0.14424142060256157\n",
      "Iteration: 1442 lambda_k: 1 Loss: 0.1441502645848891\n",
      "Iteration: 1443 lambda_k: 1 Loss: 0.14405918644549154\n",
      "Iteration: 1444 lambda_k: 1 Loss: 0.14396818631308575\n",
      "Iteration: 1445 lambda_k: 1 Loss: 0.14387726431664646\n",
      "Iteration: 1446 lambda_k: 1 Loss: 0.14378642058540372\n",
      "Iteration: 1447 lambda_k: 1 Loss: 0.14369565524884267\n",
      "Iteration: 1448 lambda_k: 1 Loss: 0.1436049684367031\n",
      "Iteration: 1449 lambda_k: 1 Loss: 0.1435143602789791\n",
      "Iteration: 1450 lambda_k: 1 Loss: 0.14342383090591895\n",
      "Iteration: 1451 lambda_k: 1 Loss: 0.14333338044802457\n",
      "Iteration: 1452 lambda_k: 1 Loss: 0.14324300903605108\n",
      "Iteration: 1453 lambda_k: 1 Loss: 0.14315271680100647\n",
      "Iteration: 1454 lambda_k: 1 Loss: 0.14306250387415112\n",
      "Iteration: 1455 lambda_k: 1 Loss: 0.14297237038699737\n",
      "Iteration: 1456 lambda_k: 1 Loss: 0.14288231647130906\n",
      "Iteration: 1457 lambda_k: 1 Loss: 0.14279234225910128\n",
      "Iteration: 1458 lambda_k: 1 Loss: 0.14270244788263967\n",
      "Iteration: 1459 lambda_k: 1 Loss: 0.14261263347444014\n",
      "Iteration: 1460 lambda_k: 1 Loss: 0.1425228991672684\n",
      "Iteration: 1461 lambda_k: 1 Loss: 0.14243324509413935\n",
      "Iteration: 1462 lambda_k: 1 Loss: 0.1423436713883169\n",
      "Iteration: 1463 lambda_k: 1 Loss: 0.14225417818331318\n",
      "Iteration: 1464 lambda_k: 1 Loss: 0.1421647656128883\n",
      "Iteration: 1465 lambda_k: 1 Loss: 0.14207543381104976\n",
      "Iteration: 1466 lambda_k: 1 Loss: 0.141986182912052\n",
      "Iteration: 1467 lambda_k: 1 Loss: 0.1418970130503959\n",
      "Iteration: 1468 lambda_k: 1 Loss: 0.14180792436082826\n",
      "Iteration: 1469 lambda_k: 1 Loss: 0.1417189169783413\n",
      "Iteration: 1470 lambda_k: 1 Loss: 0.14162999103817223\n",
      "Iteration: 1471 lambda_k: 1 Loss: 0.1415411466758027\n",
      "Iteration: 1472 lambda_k: 1 Loss: 0.1414523840269582\n",
      "Iteration: 1473 lambda_k: 1 Loss: 0.14136370322760766\n",
      "Iteration: 1474 lambda_k: 1 Loss: 0.14127510441396293\n",
      "Iteration: 1475 lambda_k: 1 Loss: 0.1411865877224781\n",
      "Iteration: 1476 lambda_k: 1 Loss: 0.1410981532898492\n",
      "Iteration: 1477 lambda_k: 1 Loss: 0.1410098012530135\n",
      "Iteration: 1478 lambda_k: 1 Loss: 0.140921531749149\n",
      "Iteration: 1479 lambda_k: 1 Loss: 0.14083334491567398\n",
      "Iteration: 1480 lambda_k: 1 Loss: 0.14074524089024626\n",
      "Iteration: 1481 lambda_k: 1 Loss: 0.14065721981076296\n",
      "Iteration: 1482 lambda_k: 1 Loss: 0.14056928181535958\n",
      "Iteration: 1483 lambda_k: 1 Loss: 0.14048142704240976\n",
      "Iteration: 1484 lambda_k: 1 Loss: 0.14039365563052467\n",
      "Iteration: 1485 lambda_k: 1 Loss: 0.14030596771855217\n",
      "Iteration: 1486 lambda_k: 1 Loss: 0.14021836344557664\n",
      "Iteration: 1487 lambda_k: 1 Loss: 0.14013084295091818\n",
      "Iteration: 1488 lambda_k: 1 Loss: 0.14004340637413204\n",
      "Iteration: 1489 lambda_k: 1 Loss: 0.13995605385500823\n",
      "Iteration: 1490 lambda_k: 1 Loss: 0.13986878553357068\n",
      "Iteration: 1491 lambda_k: 1 Loss: 0.13978160155007693\n",
      "Iteration: 1492 lambda_k: 1 Loss: 0.13969450204501735\n",
      "Iteration: 1493 lambda_k: 1 Loss: 0.1396074871591147\n",
      "Iteration: 1494 lambda_k: 1 Loss: 0.1395205570333234\n",
      "Iteration: 1495 lambda_k: 1 Loss: 0.13943371180882905\n",
      "Iteration: 1496 lambda_k: 1 Loss: 0.13934695162704788\n",
      "Iteration: 1497 lambda_k: 1 Loss: 0.13926027662962615\n",
      "Iteration: 1498 lambda_k: 1 Loss: 0.13917368695843937\n",
      "Iteration: 1499 lambda_k: 1 Loss: 0.13908718275559187\n",
      "Iteration: 1500 lambda_k: 1 Loss: 0.1390007641634163\n",
      "Iteration: 1501 lambda_k: 1 Loss: 0.13891443132447284\n",
      "Iteration: 1502 lambda_k: 1 Loss: 0.1388281843815486\n",
      "Iteration: 1503 lambda_k: 1 Loss: 0.13874202347765724\n",
      "Iteration: 1504 lambda_k: 1 Loss: 0.13865594875603815\n",
      "Iteration: 1505 lambda_k: 1 Loss: 0.13856996036015587\n",
      "Iteration: 1506 lambda_k: 1 Loss: 0.1384840584336996\n",
      "Iteration: 1507 lambda_k: 1 Loss: 0.13839824312058258\n",
      "Iteration: 1508 lambda_k: 1 Loss: 0.1383125145649413\n",
      "Iteration: 1509 lambda_k: 1 Loss: 0.13822687291113514\n",
      "Iteration: 1510 lambda_k: 1 Loss: 0.13814131830374551\n",
      "Iteration: 1511 lambda_k: 1 Loss: 0.1380558508875755\n",
      "Iteration: 1512 lambda_k: 1 Loss: 0.13797047080764904\n",
      "Iteration: 1513 lambda_k: 1 Loss: 0.1378851782092104\n",
      "Iteration: 1514 lambda_k: 1 Loss: 0.1377999732377236\n",
      "Iteration: 1515 lambda_k: 1 Loss: 0.13771485603887168\n",
      "Iteration: 1516 lambda_k: 1 Loss: 0.13762982675855615\n",
      "Iteration: 1517 lambda_k: 1 Loss: 0.1375448855428964\n",
      "Iteration: 1518 lambda_k: 1 Loss: 0.13746003253822908\n",
      "Iteration: 1519 lambda_k: 1 Loss: 0.13737526789110746\n",
      "Iteration: 1520 lambda_k: 1 Loss: 0.1372905917483007\n",
      "Iteration: 1521 lambda_k: 1 Loss: 0.13720600425679338\n",
      "Iteration: 1522 lambda_k: 1 Loss: 0.13712150556378488\n",
      "Iteration: 1523 lambda_k: 1 Loss: 0.13703709581668863\n",
      "Iteration: 1524 lambda_k: 1 Loss: 0.13695277516508286\n",
      "Iteration: 1525 lambda_k: 1 Loss: 0.13686854375376023\n",
      "Iteration: 1526 lambda_k: 1 Loss: 0.13678440173075923\n",
      "Iteration: 1527 lambda_k: 1 Loss: 0.13670034924527383\n",
      "Iteration: 1528 lambda_k: 1 Loss: 0.13661638644628843\n",
      "Iteration: 1529 lambda_k: 1 Loss: 0.1365325134808151\n",
      "Iteration: 1530 lambda_k: 1 Loss: 0.13644873049979134\n",
      "Iteration: 1531 lambda_k: 1 Loss: 0.1363650376523918\n",
      "Iteration: 1532 lambda_k: 1 Loss: 0.13628143508729174\n",
      "Iteration: 1533 lambda_k: 1 Loss: 0.13619792295377844\n",
      "Iteration: 1534 lambda_k: 1 Loss: 0.13611450139918002\n",
      "Iteration: 1535 lambda_k: 1 Loss: 0.13603117057725522\n",
      "Iteration: 1536 lambda_k: 1 Loss: 0.13594793063696245\n",
      "Iteration: 1537 lambda_k: 1 Loss: 0.135864781728677\n",
      "Iteration: 1538 lambda_k: 1 Loss: 0.13578172400278096\n",
      "Iteration: 1539 lambda_k: 1 Loss: 0.13569875761004313\n",
      "Iteration: 1540 lambda_k: 1 Loss: 0.1356158827014571\n",
      "Iteration: 1541 lambda_k: 1 Loss: 0.13553309942819217\n",
      "Iteration: 1542 lambda_k: 1 Loss: 0.13545040794160432\n",
      "Iteration: 1543 lambda_k: 1 Loss: 0.1353678083932506\n",
      "Iteration: 1544 lambda_k: 1 Loss: 0.13528530093489238\n",
      "Iteration: 1545 lambda_k: 1 Loss: 0.1352028857184932\n",
      "Iteration: 1546 lambda_k: 1 Loss: 0.13512056289621674\n",
      "Iteration: 1547 lambda_k: 1 Loss: 0.135038332620426\n",
      "Iteration: 1548 lambda_k: 1 Loss: 0.13495619504368245\n",
      "Iteration: 1549 lambda_k: 1 Loss: 0.134874150318746\n",
      "Iteration: 1550 lambda_k: 1 Loss: 0.13479219859857386\n",
      "Iteration: 1551 lambda_k: 1 Loss: 0.13471034003632035\n",
      "Iteration: 1552 lambda_k: 1 Loss: 0.13462857478533596\n",
      "Iteration: 1553 lambda_k: 1 Loss: 0.1345469029991669\n",
      "Iteration: 1554 lambda_k: 1 Loss: 0.13446532483155438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1555 lambda_k: 1 Loss: 0.13438384043643398\n",
      "Iteration: 1556 lambda_k: 1 Loss: 0.13430244996793517\n",
      "Iteration: 1557 lambda_k: 1 Loss: 0.1342211535803805\n",
      "Iteration: 1558 lambda_k: 1 Loss: 0.1341399514282852\n",
      "Iteration: 1559 lambda_k: 1 Loss: 0.13405884366635637\n",
      "Iteration: 1560 lambda_k: 1 Loss: 0.13397783044949266\n",
      "Iteration: 1561 lambda_k: 1 Loss: 0.1338969119350687\n",
      "Iteration: 1562 lambda_k: 1 Loss: 0.13381608827465385\n",
      "Iteration: 1563 lambda_k: 1 Loss: 0.1337353596250781\n",
      "Iteration: 1564 lambda_k: 1 Loss: 0.13365472614190838\n",
      "Iteration: 1565 lambda_k: 1 Loss: 0.13357418798115225\n",
      "Iteration: 1566 lambda_k: 1 Loss: 0.1334937452988265\n",
      "Iteration: 1567 lambda_k: 1 Loss: 0.13341339825111534\n",
      "Iteration: 1568 lambda_k: 1 Loss: 0.1333331469944172\n",
      "Iteration: 1569 lambda_k: 1 Loss: 0.13325299168533206\n",
      "Iteration: 1570 lambda_k: 1 Loss: 0.13317293248064602\n",
      "Iteration: 1571 lambda_k: 1 Loss: 0.13309296953732708\n",
      "Iteration: 1572 lambda_k: 1 Loss: 0.1330131030125259\n",
      "Iteration: 1573 lambda_k: 1 Loss: 0.13293333306357655\n",
      "Iteration: 1574 lambda_k: 1 Loss: 0.1328536598479965\n",
      "Iteration: 1575 lambda_k: 1 Loss: 0.13277408352353787\n",
      "Iteration: 1576 lambda_k: 1 Loss: 0.1326946042480021\n",
      "Iteration: 1577 lambda_k: 1 Loss: 0.1326152221794498\n",
      "Iteration: 1578 lambda_k: 1 Loss: 0.13253593747614945\n",
      "Iteration: 1579 lambda_k: 1 Loss: 0.13245675029654355\n",
      "Iteration: 1580 lambda_k: 1 Loss: 0.13237766079917315\n",
      "Iteration: 1581 lambda_k: 1 Loss: 0.13229866914289007\n",
      "Iteration: 1582 lambda_k: 1 Loss: 0.13221977548665909\n",
      "Iteration: 1583 lambda_k: 1 Loss: 0.1321409799895975\n",
      "Iteration: 1584 lambda_k: 1 Loss: 0.13206228281101232\n",
      "Iteration: 1585 lambda_k: 1 Loss: 0.1319836841103951\n",
      "Iteration: 1586 lambda_k: 1 Loss: 0.13190518404741355\n",
      "Iteration: 1587 lambda_k: 1 Loss: 0.1318267827819079\n",
      "Iteration: 1588 lambda_k: 1 Loss: 0.13174848047388976\n",
      "Iteration: 1589 lambda_k: 1 Loss: 0.13167027728354103\n",
      "Iteration: 1590 lambda_k: 1 Loss: 0.1315921733712209\n",
      "Iteration: 1591 lambda_k: 1 Loss: 0.13151416889742698\n",
      "Iteration: 1592 lambda_k: 1 Loss: 0.13143626402282568\n",
      "Iteration: 1593 lambda_k: 1 Loss: 0.13135845890827008\n",
      "Iteration: 1594 lambda_k: 1 Loss: 0.13128075371461922\n",
      "Iteration: 1595 lambda_k: 1 Loss: 0.1312031486028438\n",
      "Iteration: 1596 lambda_k: 1 Loss: 0.13112564373376717\n",
      "Iteration: 1597 lambda_k: 1 Loss: 0.13104823926559797\n",
      "Iteration: 1598 lambda_k: 1 Loss: 0.13097093535818646\n",
      "Iteration: 1599 lambda_k: 1 Loss: 0.1308937321654344\n",
      "Iteration: 1600 lambda_k: 1 Loss: 0.13081171489100743\n",
      "Iteration: 1601 lambda_k: 1 Loss: 0.1307169151746691\n",
      "Iteration: 1602 lambda_k: 1 Loss: 0.1306184631575779\n",
      "Iteration: 1603 lambda_k: 1 Loss: 0.13052275359073712\n",
      "Iteration: 1604 lambda_k: 1 Loss: 0.1304309108785573\n",
      "Iteration: 1605 lambda_k: 1 Loss: 0.13034444568754316\n",
      "Iteration: 1606 lambda_k: 1 Loss: 0.13026526021970383\n",
      "Iteration: 1607 lambda_k: 1 Loss: 0.13019154356344223\n",
      "Iteration: 1608 lambda_k: 1 Loss: 0.1301198520718698\n",
      "Iteration: 1609 lambda_k: 1 Loss: 0.1300481403430815\n",
      "Iteration: 1610 lambda_k: 1 Loss: 0.12997616306031476\n",
      "Iteration: 1611 lambda_k: 1 Loss: 0.12990381673235982\n",
      "Iteration: 1612 lambda_k: 1 Loss: 0.12983099425934572\n",
      "Iteration: 1613 lambda_k: 1 Loss: 0.12975765765848946\n",
      "Iteration: 1614 lambda_k: 1 Loss: 0.12968383158458488\n",
      "Iteration: 1615 lambda_k: 1 Loss: 0.12960956375326507\n",
      "Iteration: 1616 lambda_k: 1 Loss: 0.12953490523044922\n",
      "Iteration: 1617 lambda_k: 1 Loss: 0.1294599054281919\n",
      "Iteration: 1618 lambda_k: 1 Loss: 0.12938461009028313\n",
      "Iteration: 1619 lambda_k: 1 Loss: 0.1293093289685292\n",
      "Iteration: 1620 lambda_k: 1 Loss: 0.12923681315423732\n",
      "Iteration: 1621 lambda_k: 1 Loss: 0.12916389638562115\n",
      "Iteration: 1622 lambda_k: 1 Loss: 0.1290906218926789\n",
      "Iteration: 1623 lambda_k: 1 Loss: 0.12901702772345752\n",
      "Iteration: 1624 lambda_k: 1 Loss: 0.12894314756531292\n",
      "Iteration: 1625 lambda_k: 1 Loss: 0.12886901139965448\n",
      "Iteration: 1626 lambda_k: 1 Loss: 0.1287946459668466\n",
      "Iteration: 1627 lambda_k: 1 Loss: 0.12872007513926897\n",
      "Iteration: 1628 lambda_k: 1 Loss: 0.1286453202560188\n",
      "Iteration: 1629 lambda_k: 1 Loss: 0.12857040042582676\n",
      "Iteration: 1630 lambda_k: 1 Loss: 0.12849690503572328\n",
      "Iteration: 1631 lambda_k: 1 Loss: 0.12842381295923716\n",
      "Iteration: 1632 lambda_k: 1 Loss: 0.12835046901135586\n",
      "Iteration: 1633 lambda_k: 1 Loss: 0.1282768974128292\n",
      "Iteration: 1634 lambda_k: 1 Loss: 0.12820312018663424\n",
      "Iteration: 1635 lambda_k: 1 Loss: 0.12812915735463587\n",
      "Iteration: 1636 lambda_k: 1 Loss: 0.12805502711711417\n",
      "Iteration: 1637 lambda_k: 1 Loss: 0.12798074601666068\n",
      "Iteration: 1638 lambda_k: 1 Loss: 0.12790632908771757\n",
      "Iteration: 1639 lambda_k: 1 Loss: 0.1278317899929484\n",
      "Iteration: 1640 lambda_k: 1 Loss: 0.1277571411475424\n",
      "Iteration: 1641 lambda_k: 1 Loss: 0.12768239383247368\n",
      "Iteration: 1642 lambda_k: 1 Loss: 0.1276075582976563\n",
      "Iteration: 1643 lambda_k: 1 Loss: 0.1275326438558654\n",
      "Iteration: 1644 lambda_k: 1 Loss: 0.12745765896822217\n",
      "Iteration: 1645 lambda_k: 1 Loss: 0.1273826113219774\n",
      "Iteration: 1646 lambda_k: 1 Loss: 0.12730750790126907\n",
      "Iteration: 1647 lambda_k: 1 Loss: 0.12723235505147137\n",
      "Iteration: 1648 lambda_k: 1 Loss: 0.12715715853770326\n",
      "Iteration: 1649 lambda_k: 1 Loss: 0.12708192359801534\n",
      "Iteration: 1650 lambda_k: 1 Loss: 0.12700665499173\n",
      "Iteration: 1651 lambda_k: 1 Loss: 0.12693135704336994\n",
      "Iteration: 1652 lambda_k: 1 Loss: 0.12685603368257134\n",
      "Iteration: 1653 lambda_k: 1 Loss: 0.12678068848034466\n",
      "Iteration: 1654 lambda_k: 1 Loss: 0.12670532468201273\n",
      "Iteration: 1655 lambda_k: 1 Loss: 0.12662994523712906\n",
      "Iteration: 1656 lambda_k: 1 Loss: 0.12655455282664993\n",
      "Iteration: 1657 lambda_k: 1 Loss: 0.1264791498876112\n",
      "Iteration: 1658 lambda_k: 1 Loss: 0.1264037386355379\n",
      "Iteration: 1659 lambda_k: 1 Loss: 0.1263283210847937\n",
      "Iteration: 1660 lambda_k: 1 Loss: 0.12625289906705964\n",
      "Iteration: 1661 lambda_k: 1 Loss: 0.12617747424811274\n",
      "Iteration: 1662 lambda_k: 1 Loss: 0.12610204814306183\n",
      "Iteration: 1663 lambda_k: 1 Loss: 0.12602662213018187\n",
      "Iteration: 1664 lambda_k: 1 Loss: 0.12595119746347552\n",
      "Iteration: 1665 lambda_k: 1 Loss: 0.12587577528407973\n",
      "Iteration: 1666 lambda_k: 1 Loss: 0.1258003566306233\n",
      "Iteration: 1667 lambda_k: 1 Loss: 0.12572494244863236\n",
      "Iteration: 1668 lambda_k: 1 Loss: 0.12564953359907127\n",
      "Iteration: 1669 lambda_k: 1 Loss: 0.12557413086609892\n",
      "Iteration: 1670 lambda_k: 1 Loss: 0.12549873496411285\n",
      "Iteration: 1671 lambda_k: 1 Loss: 0.12542334654414666\n",
      "Iteration: 1672 lambda_k: 1 Loss: 0.1253479661996802\n",
      "Iteration: 1673 lambda_k: 1 Loss: 0.12527259447191738\n",
      "Iteration: 1674 lambda_k: 1 Loss: 0.12519723185457993\n",
      "Iteration: 1675 lambda_k: 1 Loss: 0.12512187879826223\n",
      "Iteration: 1676 lambda_k: 1 Loss: 0.12504653571438723\n",
      "Iteration: 1677 lambda_k: 1 Loss: 0.12497120297880109\n",
      "Iteration: 1678 lambda_k: 1 Loss: 0.12489588093503858\n",
      "Iteration: 1679 lambda_k: 1 Loss: 0.12482056989729055\n",
      "Iteration: 1680 lambda_k: 1 Loss: 0.12474527015310052\n",
      "Iteration: 1681 lambda_k: 1 Loss: 0.12466998196581537\n",
      "Iteration: 1682 lambda_k: 1 Loss: 0.12459470557681267\n",
      "Iteration: 1683 lambda_k: 1 Loss: 0.12451944120752548\n",
      "Iteration: 1684 lambda_k: 1 Loss: 0.12444418906128256\n",
      "Iteration: 1685 lambda_k: 1 Loss: 0.12436894932498213\n",
      "Iteration: 1686 lambda_k: 1 Loss: 0.12429372217061295\n",
      "Iteration: 1687 lambda_k: 1 Loss: 0.12421850775663826\n",
      "Iteration: 1688 lambda_k: 1 Loss: 0.12414330622925376\n",
      "Iteration: 1689 lambda_k: 1 Loss: 0.12406811772353259\n",
      "Iteration: 1690 lambda_k: 1 Loss: 0.12399294236446627\n",
      "Iteration: 1691 lambda_k: 1 Loss: 0.12391778026791234\n",
      "Iteration: 1692 lambda_k: 1 Loss: 0.12384263154145636\n",
      "Iteration: 1693 lambda_k: 1 Loss: 0.12376749628519665\n",
      "Iteration: 1694 lambda_k: 1 Loss: 0.12369237459245873\n",
      "Iteration: 1695 lambda_k: 1 Loss: 0.12361726655044575\n",
      "Iteration: 1696 lambda_k: 1 Loss: 0.1235421722408307\n",
      "Iteration: 1697 lambda_k: 1 Loss: 0.12346709174029623\n",
      "Iteration: 1698 lambda_k: 1 Loss: 0.12339202512102632\n",
      "Iteration: 1699 lambda_k: 1 Loss: 0.12331697245115442\n",
      "Iteration: 1700 lambda_k: 1 Loss: 0.1232419337951721\n",
      "Iteration: 1701 lambda_k: 1 Loss: 0.12316690921430276\n",
      "Iteration: 1702 lambda_k: 1 Loss: 0.12309189876683926\n",
      "Iteration: 1703 lambda_k: 1 Loss: 0.12301690250845575\n",
      "Iteration: 1704 lambda_k: 1 Loss: 0.12294192049249171\n",
      "Iteration: 1705 lambda_k: 1 Loss: 0.12286695277021051\n",
      "Iteration: 1706 lambda_k: 1 Loss: 0.12279199939103634\n",
      "Iteration: 1707 lambda_k: 1 Loss: 0.12271706040277051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1708 lambda_k: 1 Loss: 0.12264213585179018\n",
      "Iteration: 1709 lambda_k: 1 Loss: 0.12256722578322979\n",
      "Iteration: 1710 lambda_k: 1 Loss: 0.12249233024114788\n",
      "Iteration: 1711 lambda_k: 1 Loss: 0.12241744927087614\n",
      "Iteration: 1712 lambda_k: 1 Loss: 0.12234258291153383\n",
      "Iteration: 1713 lambda_k: 1 Loss: 0.12226773120448739\n",
      "Iteration: 1714 lambda_k: 1 Loss: 0.12219289419219766\n",
      "Iteration: 1715 lambda_k: 1 Loss: 0.1221180719156911\n",
      "Iteration: 1716 lambda_k: 1 Loss: 0.12204326441525658\n",
      "Iteration: 1717 lambda_k: 1 Loss: 0.12196847173099501\n",
      "Iteration: 1718 lambda_k: 1 Loss: 0.12189369390294824\n",
      "Iteration: 1719 lambda_k: 1 Loss: 0.12181893097111518\n",
      "Iteration: 1720 lambda_k: 1 Loss: 0.1217441829754996\n",
      "Iteration: 1721 lambda_k: 1 Loss: 0.12166944995618323\n",
      "Iteration: 1722 lambda_k: 1 Loss: 0.12159473195339701\n",
      "Iteration: 1723 lambda_k: 1 Loss: 0.12152002900758382\n",
      "Iteration: 1724 lambda_k: 1 Loss: 0.12144534115945545\n",
      "Iteration: 1725 lambda_k: 1 Loss: 0.12137066845004674\n",
      "Iteration: 1726 lambda_k: 1 Loss: 0.12129601092076703\n",
      "Iteration: 1727 lambda_k: 1 Loss: 0.12122136861344876\n",
      "Iteration: 1728 lambda_k: 1 Loss: 0.12114674157039433\n",
      "Iteration: 1729 lambda_k: 1 Loss: 0.12107212983442034\n",
      "Iteration: 1730 lambda_k: 1 Loss: 0.12099753344889995\n",
      "Iteration: 1731 lambda_k: 1 Loss: 0.12092295245780381\n",
      "Iteration: 1732 lambda_k: 1 Loss: 0.12084838690573937\n",
      "Iteration: 1733 lambda_k: 1 Loss: 0.12077383683798934\n",
      "Iteration: 1734 lambda_k: 1 Loss: 0.12069930230054833\n",
      "Iteration: 1735 lambda_k: 1 Loss: 0.12062478334015925\n",
      "Iteration: 1736 lambda_k: 1 Loss: 0.1205502800043486\n",
      "Iteration: 1737 lambda_k: 1 Loss: 0.12047579234412659\n",
      "Iteration: 1738 lambda_k: 1 Loss: 0.12040132040474882\n",
      "Iteration: 1739 lambda_k: 1 Loss: 0.12032686423585563\n",
      "Iteration: 1740 lambda_k: 1 Loss: 0.12025242389007126\n",
      "Iteration: 1741 lambda_k: 1 Loss: 0.1201779994197054\n",
      "Iteration: 1742 lambda_k: 1 Loss: 0.12010359087753436\n",
      "Iteration: 1743 lambda_k: 1 Loss: 0.1200291983174052\n",
      "Iteration: 1744 lambda_k: 1 Loss: 0.11995482179431974\n",
      "Iteration: 1745 lambda_k: 1 Loss: 0.11988046136438615\n",
      "Iteration: 1746 lambda_k: 1 Loss: 0.11980611708481784\n",
      "Iteration: 1747 lambda_k: 1 Loss: 0.11973178901397052\n",
      "Iteration: 1748 lambda_k: 1 Loss: 0.1196574772113828\n",
      "Iteration: 1749 lambda_k: 1 Loss: 0.1195831817378112\n",
      "Iteration: 1750 lambda_k: 1 Loss: 0.1195089026552636\n",
      "Iteration: 1751 lambda_k: 1 Loss: 0.11943464002703297\n",
      "Iteration: 1752 lambda_k: 1 Loss: 0.11936039391773243\n",
      "Iteration: 1753 lambda_k: 1 Loss: 0.11928616439333141\n",
      "Iteration: 1754 lambda_k: 1 Loss: 0.11921195152119228\n",
      "Iteration: 1755 lambda_k: 1 Loss: 0.11913775537010902\n",
      "Iteration: 1756 lambda_k: 1 Loss: 0.11906357601034799\n",
      "Iteration: 1757 lambda_k: 1 Loss: 0.11898941351369287\n",
      "Iteration: 1758 lambda_k: 1 Loss: 0.11891526795349897\n",
      "Iteration: 1759 lambda_k: 1 Loss: 0.11884113940768373\n",
      "Iteration: 1760 lambda_k: 1 Loss: 0.11876702795378888\n",
      "Iteration: 1761 lambda_k: 1 Loss: 0.11869293365308131\n",
      "Iteration: 1762 lambda_k: 1 Loss: 0.11861885660967667\n",
      "Iteration: 1763 lambda_k: 1 Loss: 0.11854479693886107\n",
      "Iteration: 1764 lambda_k: 1 Loss: 0.1184707546944758\n",
      "Iteration: 1765 lambda_k: 1 Loss: 0.11839773294662133\n",
      "Iteration: 1766 lambda_k: 1 Loss: 0.1183248783878018\n",
      "Iteration: 1767 lambda_k: 1 Loss: 0.11825204345130132\n",
      "Iteration: 1768 lambda_k: 1 Loss: 0.11817922811990121\n",
      "Iteration: 1769 lambda_k: 1 Loss: 0.1181064323313122\n",
      "Iteration: 1770 lambda_k: 1 Loss: 0.1180336560247219\n",
      "Iteration: 1771 lambda_k: 1 Loss: 0.11796089914076757\n",
      "Iteration: 1772 lambda_k: 1 Loss: 0.11788816162151966\n",
      "Iteration: 1773 lambda_k: 1 Loss: 0.11781544341044248\n",
      "Iteration: 1774 lambda_k: 1 Loss: 0.11774274445234438\n",
      "Iteration: 1775 lambda_k: 1 Loss: 0.11767006469333001\n",
      "Iteration: 1776 lambda_k: 1 Loss: 0.11759740408075633\n",
      "Iteration: 1777 lambda_k: 1 Loss: 0.1175247625631913\n",
      "Iteration: 1778 lambda_k: 1 Loss: 0.11745214009037404\n",
      "Iteration: 1779 lambda_k: 1 Loss: 0.11737953661317635\n",
      "Iteration: 1780 lambda_k: 1 Loss: 0.11730695208356579\n",
      "Iteration: 1781 lambda_k: 1 Loss: 0.11723438645457003\n",
      "Iteration: 1782 lambda_k: 1 Loss: 0.11716183968024296\n",
      "Iteration: 1783 lambda_k: 1 Loss: 0.1170893117156319\n",
      "Iteration: 1784 lambda_k: 1 Loss: 0.117016802516746\n",
      "Iteration: 1785 lambda_k: 1 Loss: 0.11694431204052634\n",
      "Iteration: 1786 lambda_k: 1 Loss: 0.1168718402448166\n",
      "Iteration: 1787 lambda_k: 1 Loss: 0.11679938708833541\n",
      "Iteration: 1788 lambda_k: 1 Loss: 0.11672695253064949\n",
      "Iteration: 1789 lambda_k: 1 Loss: 0.1166545365125564\n",
      "Iteration: 1790 lambda_k: 1 Loss: 0.11658213902727853\n",
      "Iteration: 1791 lambda_k: 1 Loss: 0.11650976003488743\n",
      "Iteration: 1792 lambda_k: 1 Loss: 0.11643739948814201\n",
      "Iteration: 1793 lambda_k: 1 Loss: 0.11636505734803602\n",
      "Iteration: 1794 lambda_k: 1 Loss: 0.11629273357968922\n",
      "Iteration: 1795 lambda_k: 1 Loss: 0.11622042814868398\n",
      "Iteration: 1796 lambda_k: 1 Loss: 0.11614814102061853\n",
      "Iteration: 1797 lambda_k: 1 Loss: 0.11607587216156767\n",
      "Iteration: 1798 lambda_k: 1 Loss: 0.11600362153829132\n",
      "Iteration: 1799 lambda_k: 1 Loss: 0.11593138911820898\n",
      "Iteration: 1800 lambda_k: 1 Loss: 0.11585917486934112\n",
      "Iteration: 1801 lambda_k: 1 Loss: 0.11578697876028163\n",
      "Iteration: 1802 lambda_k: 1 Loss: 0.1157148007601861\n",
      "Iteration: 1803 lambda_k: 1 Loss: 0.11564264083876057\n",
      "Iteration: 1804 lambda_k: 1 Loss: 0.11557049896624791\n",
      "Iteration: 1805 lambda_k: 1 Loss: 0.11549837511341365\n",
      "Iteration: 1806 lambda_k: 1 Loss: 0.11542626925153293\n",
      "Iteration: 1807 lambda_k: 1 Loss: 0.11535418135237768\n",
      "Iteration: 1808 lambda_k: 1 Loss: 0.11528211138820472\n",
      "Iteration: 1809 lambda_k: 1 Loss: 0.1152100593317441\n",
      "Iteration: 1810 lambda_k: 1 Loss: 0.11513802515618776\n",
      "Iteration: 1811 lambda_k: 1 Loss: 0.11506600883517888\n",
      "Iteration: 1812 lambda_k: 1 Loss: 0.11499401034280127\n",
      "Iteration: 1813 lambda_k: 1 Loss: 0.11492202965356936\n",
      "Iteration: 1814 lambda_k: 1 Loss: 0.11485006674241867\n",
      "Iteration: 1815 lambda_k: 1 Loss: 0.11477812158469625\n",
      "Iteration: 1816 lambda_k: 1 Loss: 0.11470619415615192\n",
      "Iteration: 1817 lambda_k: 1 Loss: 0.11463428443292939\n",
      "Iteration: 1818 lambda_k: 1 Loss: 0.11456239239155802\n",
      "Iteration: 1819 lambda_k: 1 Loss: 0.11449051800894484\n",
      "Iteration: 1820 lambda_k: 1 Loss: 0.11441866126236655\n",
      "Iteration: 1821 lambda_k: 1 Loss: 0.11434682212946225\n",
      "Iteration: 1822 lambda_k: 1 Loss: 0.114275000588226\n",
      "Iteration: 1823 lambda_k: 1 Loss: 0.11420319661700011\n",
      "Iteration: 1824 lambda_k: 1 Loss: 0.11413141019446812\n",
      "Iteration: 1825 lambda_k: 1 Loss: 0.11405964129964852\n",
      "Iteration: 1826 lambda_k: 1 Loss: 0.11398788991188835\n",
      "Iteration: 1827 lambda_k: 1 Loss: 0.11391615601085721\n",
      "Iteration: 1828 lambda_k: 1 Loss: 0.11384443957654133\n",
      "Iteration: 1829 lambda_k: 1 Loss: 0.11377274058923807\n",
      "Iteration: 1830 lambda_k: 1 Loss: 0.1137010590295502\n",
      "Iteration: 1831 lambda_k: 1 Loss: 0.11362939487838099\n",
      "Iteration: 1832 lambda_k: 1 Loss: 0.11355774811692868\n",
      "Iteration: 1833 lambda_k: 1 Loss: 0.11348611872668192\n",
      "Iteration: 1834 lambda_k: 1 Loss: 0.11341450668941484\n",
      "Iteration: 1835 lambda_k: 1 Loss: 0.11334291198718227\n",
      "Iteration: 1836 lambda_k: 1 Loss: 0.11327133460231573\n",
      "Iteration: 1837 lambda_k: 1 Loss: 0.11319977451741864\n",
      "Iteration: 1838 lambda_k: 1 Loss: 0.11312823171536228\n",
      "Iteration: 1839 lambda_k: 1 Loss: 0.11305670617928194\n",
      "Iteration: 1840 lambda_k: 1 Loss: 0.11298519789257282\n",
      "Iteration: 1841 lambda_k: 1 Loss: 0.1129137068388861\n",
      "Iteration: 1842 lambda_k: 1 Loss: 0.11284223300212559\n",
      "Iteration: 1843 lambda_k: 1 Loss: 0.11277077636644393\n",
      "Iteration: 1844 lambda_k: 1 Loss: 0.11269933691623915\n",
      "Iteration: 1845 lambda_k: 1 Loss: 0.11262791463615127\n",
      "Iteration: 1846 lambda_k: 1 Loss: 0.11255650951105933\n",
      "Iteration: 1847 lambda_k: 1 Loss: 0.11248512152607786\n",
      "Iteration: 1848 lambda_k: 1 Loss: 0.11241375066655404\n",
      "Iteration: 1849 lambda_k: 1 Loss: 0.11234239691806464\n",
      "Iteration: 1850 lambda_k: 1 Loss: 0.11227106026641312\n",
      "Iteration: 1851 lambda_k: 1 Loss: 0.11219974069762695\n",
      "Iteration: 1852 lambda_k: 1 Loss: 0.11212843819795469\n",
      "Iteration: 1853 lambda_k: 1 Loss: 0.11205715275386346\n",
      "Iteration: 1854 lambda_k: 1 Loss: 0.11198588435203626\n",
      "Iteration: 1855 lambda_k: 1 Loss: 0.11191463297936961\n",
      "Iteration: 1856 lambda_k: 1 Loss: 0.11184339862297102\n",
      "Iteration: 1857 lambda_k: 1 Loss: 0.11177218127015659\n",
      "Iteration: 1858 lambda_k: 1 Loss: 0.1117009809084488\n",
      "Iteration: 1859 lambda_k: 1 Loss: 0.11162979752557398\n",
      "Iteration: 1860 lambda_k: 1 Loss: 0.11155863110946064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1861 lambda_k: 1 Loss: 0.1114874816482368\n",
      "Iteration: 1862 lambda_k: 1 Loss: 0.11141634913022813\n",
      "Iteration: 1863 lambda_k: 1 Loss: 0.11134523354395595\n",
      "Iteration: 1864 lambda_k: 1 Loss: 0.11127413487813526\n",
      "Iteration: 1865 lambda_k: 1 Loss: 0.11120305312167268\n",
      "Iteration: 1866 lambda_k: 1 Loss: 0.11113198826366472\n",
      "Iteration: 1867 lambda_k: 1 Loss: 0.11106094029339572\n",
      "Iteration: 1868 lambda_k: 1 Loss: 0.11098990920033633\n",
      "Iteration: 1869 lambda_k: 1 Loss: 0.11091889497414166\n",
      "Iteration: 1870 lambda_k: 1 Loss: 0.1108478976046493\n",
      "Iteration: 1871 lambda_k: 1 Loss: 0.11077691708187815\n",
      "Iteration: 1872 lambda_k: 1 Loss: 0.11070595339602625\n",
      "Iteration: 1873 lambda_k: 1 Loss: 0.11063500653746965\n",
      "Iteration: 1874 lambda_k: 1 Loss: 0.11056407649676046\n",
      "Iteration: 1875 lambda_k: 1 Loss: 0.11049316326462556\n",
      "Iteration: 1876 lambda_k: 1 Loss: 0.11042226683196495\n",
      "Iteration: 1877 lambda_k: 1 Loss: 0.11035138718985041\n",
      "Iteration: 1878 lambda_k: 1 Loss: 0.11028052432952397\n",
      "Iteration: 1879 lambda_k: 1 Loss: 0.11020967824239658\n",
      "Iteration: 1880 lambda_k: 1 Loss: 0.11013884892004668\n",
      "Iteration: 1881 lambda_k: 1 Loss: 0.11006803635421872\n",
      "Iteration: 1882 lambda_k: 1 Loss: 0.10999724053682221\n",
      "Iteration: 1883 lambda_k: 1 Loss: 0.10992646145992996\n",
      "Iteration: 1884 lambda_k: 1 Loss: 0.10985569911577708\n",
      "Iteration: 1885 lambda_k: 1 Loss: 0.10978495349675974\n",
      "Iteration: 1886 lambda_k: 1 Loss: 0.1097142245954338\n",
      "Iteration: 1887 lambda_k: 1 Loss: 0.10964351240451373\n",
      "Iteration: 1888 lambda_k: 1 Loss: 0.10957281691687139\n",
      "Iteration: 1889 lambda_k: 1 Loss: 0.10950213812553476\n",
      "Iteration: 1890 lambda_k: 1 Loss: 0.109431476023687\n",
      "Iteration: 1891 lambda_k: 1 Loss: 0.10936083060466514\n",
      "Iteration: 1892 lambda_k: 1 Loss: 0.10929020186195922\n",
      "Iteration: 1893 lambda_k: 1 Loss: 0.10921958978921087\n",
      "Iteration: 1894 lambda_k: 1 Loss: 0.10914899438021256\n",
      "Iteration: 1895 lambda_k: 1 Loss: 0.10907841562890637\n",
      "Iteration: 1896 lambda_k: 1 Loss: 0.10900785352938304\n",
      "Iteration: 1897 lambda_k: 1 Loss: 0.10893730807588094\n",
      "Iteration: 1898 lambda_k: 1 Loss: 0.10886677926278507\n",
      "Iteration: 1899 lambda_k: 1 Loss: 0.1087962670846261\n",
      "Iteration: 1900 lambda_k: 1 Loss: 0.10872577153607937\n",
      "Iteration: 1901 lambda_k: 1 Loss: 0.10865529261196398\n",
      "Iteration: 1902 lambda_k: 1 Loss: 0.10858483030724181\n",
      "Iteration: 1903 lambda_k: 1 Loss: 0.10851438461701668\n",
      "Iteration: 1904 lambda_k: 1 Loss: 0.10844395553653338\n",
      "Iteration: 1905 lambda_k: 1 Loss: 0.10837354306117676\n",
      "Iteration: 1906 lambda_k: 1 Loss: 0.10830314718647087\n",
      "Iteration: 1907 lambda_k: 1 Loss: 0.10823276790807826\n",
      "Iteration: 1908 lambda_k: 1 Loss: 0.10816240522179875\n",
      "Iteration: 1909 lambda_k: 1 Loss: 0.10809205912356899\n",
      "Iteration: 1910 lambda_k: 1 Loss: 0.10802172960946141\n",
      "Iteration: 1911 lambda_k: 1 Loss: 0.1079514166756834\n",
      "Iteration: 1912 lambda_k: 1 Loss: 0.10788112031857663\n",
      "Iteration: 1913 lambda_k: 1 Loss: 0.1078108405346161\n",
      "Iteration: 1914 lambda_k: 1 Loss: 0.10774057732040952\n",
      "Iteration: 1915 lambda_k: 1 Loss: 0.10767033067269632\n",
      "Iteration: 1916 lambda_k: 1 Loss: 0.10760010058834717\n",
      "Iteration: 1917 lambda_k: 1 Loss: 0.10752988706436291\n",
      "Iteration: 1918 lambda_k: 1 Loss: 0.10745969009787419\n",
      "Iteration: 1919 lambda_k: 1 Loss: 0.10738950968614035\n",
      "Iteration: 1920 lambda_k: 1 Loss: 0.10731934582654883\n",
      "Iteration: 1921 lambda_k: 1 Loss: 0.10724919851661463\n",
      "Iteration: 1922 lambda_k: 1 Loss: 0.10717906775397942\n",
      "Iteration: 1923 lambda_k: 1 Loss: 0.1071089535364109\n",
      "Iteration: 1924 lambda_k: 1 Loss: 0.10703885586180195\n",
      "Iteration: 1925 lambda_k: 1 Loss: 0.10696877472817035\n",
      "Iteration: 1926 lambda_k: 1 Loss: 0.10689871013365765\n",
      "Iteration: 1927 lambda_k: 1 Loss: 0.10682866207652887\n",
      "Iteration: 1928 lambda_k: 1 Loss: 0.10675863055517161\n",
      "Iteration: 1929 lambda_k: 1 Loss: 0.1066886155680955\n",
      "Iteration: 1930 lambda_k: 1 Loss: 0.10661861711393157\n",
      "Iteration: 1931 lambda_k: 1 Loss: 0.1065486351914316\n",
      "Iteration: 1932 lambda_k: 1 Loss: 0.1064786697994675\n",
      "Iteration: 1933 lambda_k: 1 Loss: 0.10640872093703066\n",
      "Iteration: 1934 lambda_k: 1 Loss: 0.1063387886032314\n",
      "Iteration: 1935 lambda_k: 1 Loss: 0.10626887279729835\n",
      "Iteration: 1936 lambda_k: 1 Loss: 0.10619897351857788\n",
      "Iteration: 1937 lambda_k: 1 Loss: 0.1061290907665334\n",
      "Iteration: 1938 lambda_k: 1 Loss: 0.10605922454074489\n",
      "Iteration: 1939 lambda_k: 1 Loss: 0.10598937484090835\n",
      "Iteration: 1940 lambda_k: 1 Loss: 0.10591954166683507\n",
      "Iteration: 1941 lambda_k: 1 Loss: 0.10584972501845138\n",
      "Iteration: 1942 lambda_k: 1 Loss: 0.10577992489579766\n",
      "Iteration: 1943 lambda_k: 1 Loss: 0.10571014129902816\n",
      "Iteration: 1944 lambda_k: 1 Loss: 0.10564037422841037\n",
      "Iteration: 1945 lambda_k: 1 Loss: 0.10557062368432428\n",
      "Iteration: 1946 lambda_k: 1 Loss: 0.10550088966726216\n",
      "Iteration: 1947 lambda_k: 1 Loss: 0.10543117217782792\n",
      "Iteration: 1948 lambda_k: 1 Loss: 0.10536147121673635\n",
      "Iteration: 1949 lambda_k: 1 Loss: 0.10529178678481307\n",
      "Iteration: 1950 lambda_k: 1 Loss: 0.10522211888299361\n",
      "Iteration: 1951 lambda_k: 1 Loss: 0.10515246751232311\n",
      "Iteration: 1952 lambda_k: 1 Loss: 0.10508283267395585\n",
      "Iteration: 1953 lambda_k: 1 Loss: 0.10501321436915467\n",
      "Iteration: 1954 lambda_k: 1 Loss: 0.10494361259929047\n",
      "Iteration: 1955 lambda_k: 1 Loss: 0.10487402736584188\n",
      "Iteration: 1956 lambda_k: 1 Loss: 0.10480445867039456\n",
      "Iteration: 1957 lambda_k: 1 Loss: 0.10473490651464094\n",
      "Iteration: 1958 lambda_k: 1 Loss: 0.10466537090037975\n",
      "Iteration: 1959 lambda_k: 1 Loss: 0.10459585182951538\n",
      "Iteration: 1960 lambda_k: 1 Loss: 0.10452634930405758\n",
      "Iteration: 1961 lambda_k: 1 Loss: 0.1044568633261209\n",
      "Iteration: 1962 lambda_k: 1 Loss: 0.10438739389792445\n",
      "Iteration: 1963 lambda_k: 1 Loss: 0.1043179410217912\n",
      "Iteration: 1964 lambda_k: 1 Loss: 0.10424850470014782\n",
      "Iteration: 1965 lambda_k: 1 Loss: 0.10417908493552401\n",
      "Iteration: 1966 lambda_k: 1 Loss: 0.10410968173055217\n",
      "Iteration: 1967 lambda_k: 1 Loss: 0.10404029508796714\n",
      "Iteration: 1968 lambda_k: 1 Loss: 0.10397092501060547\n",
      "Iteration: 1969 lambda_k: 1 Loss: 0.10390157150140518\n",
      "Iteration: 1970 lambda_k: 1 Loss: 0.10383223456340548\n",
      "Iteration: 1971 lambda_k: 1 Loss: 0.10376291419974619\n",
      "Iteration: 1972 lambda_k: 1 Loss: 0.10369361041366737\n",
      "Iteration: 1973 lambda_k: 1 Loss: 0.10362432320850899\n",
      "Iteration: 1974 lambda_k: 1 Loss: 0.10355505258771051\n",
      "Iteration: 1975 lambda_k: 1 Loss: 0.1034857985548105\n",
      "Iteration: 1976 lambda_k: 1 Loss: 0.10341656111344621\n",
      "Iteration: 1977 lambda_k: 1 Loss: 0.1033473402673534\n",
      "Iteration: 1978 lambda_k: 1 Loss: 0.10327813602036563\n",
      "Iteration: 1979 lambda_k: 1 Loss: 0.10320894837641424\n",
      "Iteration: 1980 lambda_k: 1 Loss: 0.10313977733952766\n",
      "Iteration: 1981 lambda_k: 1 Loss: 0.10307062291383141\n",
      "Iteration: 1982 lambda_k: 1 Loss: 0.1030014851035475\n",
      "Iteration: 1983 lambda_k: 1 Loss: 0.10293236391299412\n",
      "Iteration: 1984 lambda_k: 1 Loss: 0.10286325934658533\n",
      "Iteration: 1985 lambda_k: 1 Loss: 0.1027941714088307\n",
      "Iteration: 1986 lambda_k: 1 Loss: 0.102725100104335\n",
      "Iteration: 1987 lambda_k: 1 Loss: 0.10265604543779788\n",
      "Iteration: 1988 lambda_k: 1 Loss: 0.10258700741401341\n",
      "Iteration: 1989 lambda_k: 1 Loss: 0.10251798603786999\n",
      "Iteration: 1990 lambda_k: 1 Loss: 0.10244898131434976\n",
      "Iteration: 1991 lambda_k: 1 Loss: 0.10237999324852858\n",
      "Iteration: 1992 lambda_k: 1 Loss: 0.10231102184557533\n",
      "Iteration: 1993 lambda_k: 1 Loss: 0.10224206711075201\n",
      "Iteration: 1994 lambda_k: 1 Loss: 0.10217312904941317\n",
      "Iteration: 1995 lambda_k: 1 Loss: 0.10210420766700569\n",
      "Iteration: 1996 lambda_k: 1 Loss: 0.10203530296906844\n",
      "Iteration: 1997 lambda_k: 1 Loss: 0.10196641496123203\n",
      "Iteration: 1998 lambda_k: 1 Loss: 0.10189754364921852\n",
      "Iteration: 1999 lambda_k: 1 Loss: 0.1018286890388412\n",
      "Iteration: 2000 lambda_k: 1 Loss: 0.10175985113600403\n",
      "Iteration: 2001 lambda_k: 1 Loss: 0.10169102994670175\n",
      "Iteration: 2002 lambda_k: 1 Loss: 0.1016222254770192\n",
      "Iteration: 2003 lambda_k: 1 Loss: 0.10155343773313143\n",
      "Iteration: 2004 lambda_k: 1 Loss: 0.10148466672130306\n",
      "Iteration: 2005 lambda_k: 1 Loss: 0.10141591244788839\n",
      "Iteration: 2006 lambda_k: 1 Loss: 0.10134717491933078\n",
      "Iteration: 2007 lambda_k: 1 Loss: 0.10127845414216266\n",
      "Iteration: 2008 lambda_k: 1 Loss: 0.10120975012300511\n",
      "Iteration: 2009 lambda_k: 1 Loss: 0.10114106286856761\n",
      "Iteration: 2010 lambda_k: 1 Loss: 0.10107239238564793\n",
      "Iteration: 2011 lambda_k: 1 Loss: 0.10100373868113173\n",
      "Iteration: 2012 lambda_k: 1 Loss: 0.10093510176199239\n",
      "Iteration: 2013 lambda_k: 1 Loss: 0.10086648163529073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2014 lambda_k: 1 Loss: 0.10079787830817485\n",
      "Iteration: 2015 lambda_k: 1 Loss: 0.10072929178787973\n",
      "Iteration: 2016 lambda_k: 1 Loss: 0.10066072208172717\n",
      "Iteration: 2017 lambda_k: 1 Loss: 0.10059216919712549\n",
      "Iteration: 2018 lambda_k: 1 Loss: 0.1005236331415693\n",
      "Iteration: 2019 lambda_k: 1 Loss: 0.10045511392263932\n",
      "Iteration: 2020 lambda_k: 1 Loss: 0.10038661154800202\n",
      "Iteration: 2021 lambda_k: 1 Loss: 0.10031812602540965\n",
      "Iteration: 2022 lambda_k: 1 Loss: 0.10024965736269974\n",
      "Iteration: 2023 lambda_k: 1 Loss: 0.10018120556779514\n",
      "Iteration: 2024 lambda_k: 1 Loss: 0.10011277064870358\n",
      "Iteration: 2025 lambda_k: 1 Loss: 0.10004435261351781\n",
      "Iteration: 2026 lambda_k: 1 Loss: 0.0999759514704149\n",
      "Iteration: 2027 lambda_k: 1 Loss: 0.09990756722765647\n",
      "Iteration: 2028 lambda_k: 1 Loss: 0.09983919989358835\n",
      "Iteration: 2029 lambda_k: 1 Loss: 0.09977084947664029\n",
      "Iteration: 2030 lambda_k: 1 Loss: 0.09970251598532597\n",
      "Iteration: 2031 lambda_k: 1 Loss: 0.0996341994282426\n",
      "Iteration: 2032 lambda_k: 1 Loss: 0.09956589981407082\n",
      "Iteration: 2033 lambda_k: 1 Loss: 0.09949761715157465\n",
      "Iteration: 2034 lambda_k: 1 Loss: 0.09942935144960105\n",
      "Iteration: 2035 lambda_k: 1 Loss: 0.09936110271707992\n",
      "Iteration: 2036 lambda_k: 1 Loss: 0.09929287096302397\n",
      "Iteration: 2037 lambda_k: 1 Loss: 0.09922465619652836\n",
      "Iteration: 2038 lambda_k: 1 Loss: 0.09915645842677066\n",
      "Iteration: 2039 lambda_k: 1 Loss: 0.09908827766301072\n",
      "Iteration: 2040 lambda_k: 1 Loss: 0.09902011391459034\n",
      "Iteration: 2041 lambda_k: 1 Loss: 0.09895196719093334\n",
      "Iteration: 2042 lambda_k: 1 Loss: 0.09888383750154521\n",
      "Iteration: 2043 lambda_k: 1 Loss: 0.098815724856013\n",
      "Iteration: 2044 lambda_k: 1 Loss: 0.09874762926400531\n",
      "Iteration: 2045 lambda_k: 1 Loss: 0.0986795507352718\n",
      "Iteration: 2046 lambda_k: 1 Loss: 0.09861148927964346\n",
      "Iteration: 2047 lambda_k: 1 Loss: 0.09854344490703222\n",
      "Iteration: 2048 lambda_k: 1 Loss: 0.09847541762743081\n",
      "Iteration: 2049 lambda_k: 1 Loss: 0.0984074074509127\n",
      "Iteration: 2050 lambda_k: 1 Loss: 0.09833941438763187\n",
      "Iteration: 2051 lambda_k: 1 Loss: 0.09827143844782282\n",
      "Iteration: 2052 lambda_k: 1 Loss: 0.09820347964180032\n",
      "Iteration: 2053 lambda_k: 1 Loss: 0.09813553797995919\n",
      "Iteration: 2054 lambda_k: 1 Loss: 0.09806761347277451\n",
      "Iteration: 2055 lambda_k: 1 Loss: 0.09799970613080107\n",
      "Iteration: 2056 lambda_k: 1 Loss: 0.09793181596467358\n",
      "Iteration: 2057 lambda_k: 1 Loss: 0.09786394298510634\n",
      "Iteration: 2058 lambda_k: 1 Loss: 0.09779608720289328\n",
      "Iteration: 2059 lambda_k: 1 Loss: 0.09772824862890772\n",
      "Iteration: 2060 lambda_k: 1 Loss: 0.09766042727410232\n",
      "Iteration: 2061 lambda_k: 1 Loss: 0.09759262314950894\n",
      "Iteration: 2062 lambda_k: 1 Loss: 0.09752483626623848\n",
      "Iteration: 2063 lambda_k: 1 Loss: 0.097457066635481\n",
      "Iteration: 2064 lambda_k: 1 Loss: 0.09738931426850536\n",
      "Iteration: 2065 lambda_k: 1 Loss: 0.09732157917665918\n",
      "Iteration: 2066 lambda_k: 1 Loss: 0.09725386137136882\n",
      "Iteration: 2067 lambda_k: 1 Loss: 0.0971861608641392\n",
      "Iteration: 2068 lambda_k: 1 Loss: 0.09711847766655383\n",
      "Iteration: 2069 lambda_k: 1 Loss: 0.09705081179027454\n",
      "Iteration: 2070 lambda_k: 1 Loss: 0.09698316324704148\n",
      "Iteration: 2071 lambda_k: 1 Loss: 0.09691553204867308\n",
      "Iteration: 2072 lambda_k: 1 Loss: 0.09684791820706591\n",
      "Iteration: 2073 lambda_k: 1 Loss: 0.0967803217341945\n",
      "Iteration: 2074 lambda_k: 1 Loss: 0.09671274264211153\n",
      "Iteration: 2075 lambda_k: 1 Loss: 0.09664518094294745\n",
      "Iteration: 2076 lambda_k: 1 Loss: 0.09657763664891059\n",
      "Iteration: 2077 lambda_k: 1 Loss: 0.096510109772287\n",
      "Iteration: 2078 lambda_k: 1 Loss: 0.0964426003254404\n",
      "Iteration: 2079 lambda_k: 1 Loss: 0.09637510832081213\n",
      "Iteration: 2080 lambda_k: 1 Loss: 0.0963076337709211\n",
      "Iteration: 2081 lambda_k: 1 Loss: 0.09624017668836363\n",
      "Iteration: 2082 lambda_k: 1 Loss: 0.09617273708581349\n",
      "Iteration: 2083 lambda_k: 1 Loss: 0.09610531497602172\n",
      "Iteration: 2084 lambda_k: 1 Loss: 0.09603791037181676\n",
      "Iteration: 2085 lambda_k: 1 Loss: 0.09597052328610416\n",
      "Iteration: 2086 lambda_k: 1 Loss: 0.09590315373186666\n",
      "Iteration: 2087 lambda_k: 1 Loss: 0.09583580172216423\n",
      "Iteration: 2088 lambda_k: 1 Loss: 0.09576846727013373\n",
      "Iteration: 2089 lambda_k: 1 Loss: 0.09570115038898916\n",
      "Iteration: 2090 lambda_k: 1 Loss: 0.09563385109202138\n",
      "Iteration: 2091 lambda_k: 1 Loss: 0.09556656939259829\n",
      "Iteration: 2092 lambda_k: 1 Loss: 0.09549930530416455\n",
      "Iteration: 2093 lambda_k: 1 Loss: 0.09543205884024177\n",
      "Iteration: 2094 lambda_k: 1 Loss: 0.09536483001442816\n",
      "Iteration: 2095 lambda_k: 1 Loss: 0.0952976188403989\n",
      "Iteration: 2096 lambda_k: 1 Loss: 0.09523042533190583\n",
      "Iteration: 2097 lambda_k: 1 Loss: 0.09516324950277733\n",
      "Iteration: 2098 lambda_k: 1 Loss: 0.0950960913669186\n",
      "Iteration: 2099 lambda_k: 1 Loss: 0.09502895093831139\n",
      "Iteration: 2100 lambda_k: 1 Loss: 0.09496182823101401\n",
      "Iteration: 2101 lambda_k: 1 Loss: 0.09489472325916147\n",
      "Iteration: 2102 lambda_k: 1 Loss: 0.09482763603696515\n",
      "Iteration: 2103 lambda_k: 1 Loss: 0.09476056657871308\n",
      "Iteration: 2104 lambda_k: 1 Loss: 0.09469351489876975\n",
      "Iteration: 2105 lambda_k: 1 Loss: 0.09462648101157603\n",
      "Iteration: 2106 lambda_k: 1 Loss: 0.09455946493164946\n",
      "Iteration: 2107 lambda_k: 1 Loss: 0.09449246667358381\n",
      "Iteration: 2108 lambda_k: 1 Loss: 0.09442548625204941\n",
      "Iteration: 2109 lambda_k: 1 Loss: 0.09435852368179301\n",
      "Iteration: 2110 lambda_k: 1 Loss: 0.09429157897763775\n",
      "Iteration: 2111 lambda_k: 1 Loss: 0.09422465215448313\n",
      "Iteration: 2112 lambda_k: 1 Loss: 0.09415774322730512\n",
      "Iteration: 2113 lambda_k: 1 Loss: 0.09409085221463481\n",
      "Iteration: 2114 lambda_k: 1 Loss: 0.09402397912461066\n",
      "Iteration: 2115 lambda_k: 1 Loss: 0.09395712397594871\n",
      "Iteration: 2116 lambda_k: 1 Loss: 0.09389028678393065\n",
      "Iteration: 2117 lambda_k: 1 Loss: 0.09382346756391438\n",
      "Iteration: 2118 lambda_k: 1 Loss: 0.09375666633133423\n",
      "Iteration: 2119 lambda_k: 1 Loss: 0.0936898831017009\n",
      "Iteration: 2120 lambda_k: 1 Loss: 0.09362311789060158\n",
      "Iteration: 2121 lambda_k: 1 Loss: 0.09355637071369977\n",
      "Iteration: 2122 lambda_k: 1 Loss: 0.0934896415867355\n",
      "Iteration: 2123 lambda_k: 1 Loss: 0.09342293052552526\n",
      "Iteration: 2124 lambda_k: 1 Loss: 0.09335623754596196\n",
      "Iteration: 2125 lambda_k: 1 Loss: 0.09328956266401499\n",
      "Iteration: 2126 lambda_k: 1 Loss: 0.09322290589573025\n",
      "Iteration: 2127 lambda_k: 1 Loss: 0.09315626725723018\n",
      "Iteration: 2128 lambda_k: 1 Loss: 0.09308964676471375\n",
      "Iteration: 2129 lambda_k: 1 Loss: 0.09302304443445654\n",
      "Iteration: 2130 lambda_k: 1 Loss: 0.09295646028281068\n",
      "Iteration: 2131 lambda_k: 1 Loss: 0.09288989432620488\n",
      "Iteration: 2132 lambda_k: 1 Loss: 0.0928233465811446\n",
      "Iteration: 2133 lambda_k: 1 Loss: 0.0927568170642119\n",
      "Iteration: 2134 lambda_k: 1 Loss: 0.09269030579206557\n",
      "Iteration: 2135 lambda_k: 1 Loss: 0.09262381278144119\n",
      "Iteration: 2136 lambda_k: 1 Loss: 0.09255733804915109\n",
      "Iteration: 2137 lambda_k: 1 Loss: 0.09249088161208438\n",
      "Iteration: 2138 lambda_k: 1 Loss: 0.09242444348720712\n",
      "Iteration: 2139 lambda_k: 1 Loss: 0.09235802369156214\n",
      "Iteration: 2140 lambda_k: 1 Loss: 0.09229162224226936\n",
      "Iteration: 2141 lambda_k: 1 Loss: 0.09222523915652554\n",
      "Iteration: 2142 lambda_k: 1 Loss: 0.09215887445160464\n",
      "Iteration: 2143 lambda_k: 1 Loss: 0.09209252814485752\n",
      "Iteration: 2144 lambda_k: 1 Loss: 0.09202620025371226\n",
      "Iteration: 2145 lambda_k: 1 Loss: 0.09195989079567408\n",
      "Iteration: 2146 lambda_k: 1 Loss: 0.09189359978832552\n",
      "Iteration: 2147 lambda_k: 1 Loss: 0.09182732724932628\n",
      "Iteration: 2148 lambda_k: 1 Loss: 0.09176107319641348\n",
      "Iteration: 2149 lambda_k: 1 Loss: 0.0916948376474016\n",
      "Iteration: 2150 lambda_k: 1 Loss: 0.09162862062018262\n",
      "Iteration: 2151 lambda_k: 1 Loss: 0.09156242213272603\n",
      "Iteration: 2152 lambda_k: 1 Loss: 0.0914962422030789\n",
      "Iteration: 2153 lambda_k: 1 Loss: 0.09143008084797564\n",
      "Iteration: 2154 lambda_k: 1 Loss: 0.09136393808842402\n",
      "Iteration: 2155 lambda_k: 1 Loss: 0.09129781394128728\n",
      "Iteration: 2156 lambda_k: 1 Loss: 0.09123170842492322\n",
      "Iteration: 2157 lambda_k: 1 Loss: 0.09116562155776749\n",
      "Iteration: 2158 lambda_k: 1 Loss: 0.09109955335833383\n",
      "Iteration: 2159 lambda_k: 1 Loss: 0.09103350384521387\n",
      "Iteration: 2160 lambda_k: 1 Loss: 0.09096747303707751\n",
      "Iteration: 2161 lambda_k: 1 Loss: 0.09090146095267282\n",
      "Iteration: 2162 lambda_k: 1 Loss: 0.09083546761082621\n",
      "Iteration: 2163 lambda_k: 1 Loss: 0.09076949303044252\n",
      "Iteration: 2164 lambda_k: 1 Loss: 0.09070353723050528\n",
      "Iteration: 2165 lambda_k: 1 Loss: 0.09063760023007686\n",
      "Iteration: 2166 lambda_k: 1 Loss: 0.09057168204828743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2167 lambda_k: 1 Loss: 0.09050578270436041\n",
      "Iteration: 2168 lambda_k: 1 Loss: 0.09043990221759493\n",
      "Iteration: 2169 lambda_k: 1 Loss: 0.09037404060736715\n",
      "Iteration: 2170 lambda_k: 1 Loss: 0.09030819789313216\n",
      "Iteration: 2171 lambda_k: 1 Loss: 0.09024237409442395\n",
      "Iteration: 2172 lambda_k: 1 Loss: 0.09017656923085575\n",
      "Iteration: 2173 lambda_k: 1 Loss: 0.09011078332211982\n",
      "Iteration: 2174 lambda_k: 1 Loss: 0.09004501638798779\n",
      "Iteration: 2175 lambda_k: 1 Loss: 0.08997926844831063\n",
      "Iteration: 2176 lambda_k: 1 Loss: 0.08991353952301875\n",
      "Iteration: 2177 lambda_k: 1 Loss: 0.08984782963212216\n",
      "Iteration: 2178 lambda_k: 1 Loss: 0.08978213879571058\n",
      "Iteration: 2179 lambda_k: 1 Loss: 0.08971646703395335\n",
      "Iteration: 2180 lambda_k: 1 Loss: 0.08965081436709982\n",
      "Iteration: 2181 lambda_k: 1 Loss: 0.0895851808154792\n",
      "Iteration: 2182 lambda_k: 1 Loss: 0.08951956639950089\n",
      "Iteration: 2183 lambda_k: 1 Loss: 0.08945397113965428\n",
      "Iteration: 2184 lambda_k: 1 Loss: 0.08938839505650922\n",
      "Iteration: 2185 lambda_k: 1 Loss: 0.08932283817071597\n",
      "Iteration: 2186 lambda_k: 1 Loss: 0.08925730050300514\n",
      "Iteration: 2187 lambda_k: 1 Loss: 0.08919178207418803\n",
      "Iteration: 2188 lambda_k: 1 Loss: 0.08912628290515667\n",
      "Iteration: 2189 lambda_k: 1 Loss: 0.089060803016884\n",
      "Iteration: 2190 lambda_k: 1 Loss: 0.08899534243042381\n",
      "Iteration: 2191 lambda_k: 1 Loss: 0.08892990116691106\n",
      "Iteration: 2192 lambda_k: 1 Loss: 0.08886447924756183\n",
      "Iteration: 2193 lambda_k: 1 Loss: 0.08879907669367357\n",
      "Iteration: 2194 lambda_k: 1 Loss: 0.0887336935266251\n",
      "Iteration: 2195 lambda_k: 1 Loss: 0.08866832976787685\n",
      "Iteration: 2196 lambda_k: 1 Loss: 0.08860298543897094\n",
      "Iteration: 2197 lambda_k: 1 Loss: 0.08853766056153127\n",
      "Iteration: 2198 lambda_k: 1 Loss: 0.08847235515726373\n",
      "Iteration: 2199 lambda_k: 1 Loss: 0.08840706924795613\n",
      "Iteration: 2200 lambda_k: 1 Loss: 0.08834180285547862\n",
      "Iteration: 2201 lambda_k: 1 Loss: 0.08827655600178363\n",
      "Iteration: 2202 lambda_k: 1 Loss: 0.08821132870890601\n",
      "Iteration: 2203 lambda_k: 1 Loss: 0.08814612099896318\n",
      "Iteration: 2204 lambda_k: 1 Loss: 0.08808093289415542\n",
      "Iteration: 2205 lambda_k: 1 Loss: 0.08801576441676565\n",
      "Iteration: 2206 lambda_k: 1 Loss: 0.08795061558915997\n",
      "Iteration: 2207 lambda_k: 1 Loss: 0.0878854864337875\n",
      "Iteration: 2208 lambda_k: 1 Loss: 0.08782037697318071\n",
      "Iteration: 2209 lambda_k: 1 Loss: 0.08775528722995542\n",
      "Iteration: 2210 lambda_k: 1 Loss: 0.08769021722681107\n",
      "Iteration: 2211 lambda_k: 1 Loss: 0.08762516698653078\n",
      "Iteration: 2212 lambda_k: 1 Loss: 0.08756013653198143\n",
      "Iteration: 2213 lambda_k: 1 Loss: 0.08749512588611405\n",
      "Iteration: 2214 lambda_k: 1 Loss: 0.08743013507196368\n",
      "Iteration: 2215 lambda_k: 1 Loss: 0.08736516411264966\n",
      "Iteration: 2216 lambda_k: 1 Loss: 0.08730021303137582\n",
      "Iteration: 2217 lambda_k: 1 Loss: 0.08723528185143054\n",
      "Iteration: 2218 lambda_k: 1 Loss: 0.08717037059618701\n",
      "Iteration: 2219 lambda_k: 1 Loss: 0.08710547928910323\n",
      "Iteration: 2220 lambda_k: 1 Loss: 0.08704060795372232\n",
      "Iteration: 2221 lambda_k: 1 Loss: 0.08697575661367254\n",
      "Iteration: 2222 lambda_k: 1 Loss: 0.0869109252926676\n",
      "Iteration: 2223 lambda_k: 1 Loss: 0.08684611401450663\n",
      "Iteration: 2224 lambda_k: 1 Loss: 0.08678132280307459\n",
      "Iteration: 2225 lambda_k: 1 Loss: 0.08671655168234214\n",
      "Iteration: 2226 lambda_k: 1 Loss: 0.086651800676366\n",
      "Iteration: 2227 lambda_k: 1 Loss: 0.08658706980928914\n",
      "Iteration: 2228 lambda_k: 1 Loss: 0.08652235910534078\n",
      "Iteration: 2229 lambda_k: 1 Loss: 0.08645766858883673\n",
      "Iteration: 2230 lambda_k: 1 Loss: 0.08639299828417937\n",
      "Iteration: 2231 lambda_k: 1 Loss: 0.08632834821585803\n",
      "Iteration: 2232 lambda_k: 1 Loss: 0.08626371840844896\n",
      "Iteration: 2233 lambda_k: 1 Loss: 0.08619910888661572\n",
      "Iteration: 2234 lambda_k: 1 Loss: 0.08613451967510907\n",
      "Iteration: 2235 lambda_k: 1 Loss: 0.08606995079876748\n",
      "Iteration: 2236 lambda_k: 1 Loss: 0.08600540228251695\n",
      "Iteration: 2237 lambda_k: 1 Loss: 0.08594087415137155\n",
      "Iteration: 2238 lambda_k: 1 Loss: 0.08587636643043328\n",
      "Iteration: 2239 lambda_k: 1 Loss: 0.08581187914489244\n",
      "Iteration: 2240 lambda_k: 1 Loss: 0.08574741232002775\n",
      "Iteration: 2241 lambda_k: 1 Loss: 0.08568296598120652\n",
      "Iteration: 2242 lambda_k: 1 Loss: 0.08561854015388491\n",
      "Iteration: 2243 lambda_k: 1 Loss: 0.08555413486360797\n",
      "Iteration: 2244 lambda_k: 1 Loss: 0.08548975013600996\n",
      "Iteration: 2245 lambda_k: 1 Loss: 0.08542538599681444\n",
      "Iteration: 2246 lambda_k: 1 Loss: 0.08536104247183463\n",
      "Iteration: 2247 lambda_k: 1 Loss: 0.08529671958697331\n",
      "Iteration: 2248 lambda_k: 1 Loss: 0.08523241736822323\n",
      "Iteration: 2249 lambda_k: 1 Loss: 0.08516813584166731\n",
      "Iteration: 2250 lambda_k: 1 Loss: 0.08510387503347878\n",
      "Iteration: 2251 lambda_k: 1 Loss: 0.08503963496992119\n",
      "Iteration: 2252 lambda_k: 1 Loss: 0.08497541567734898\n",
      "Iteration: 2253 lambda_k: 1 Loss: 0.08491121718220732\n",
      "Iteration: 2254 lambda_k: 1 Loss: 0.08484703951103259\n",
      "Iteration: 2255 lambda_k: 1 Loss: 0.08478288269045237\n",
      "Iteration: 2256 lambda_k: 1 Loss: 0.0847187467471857\n",
      "Iteration: 2257 lambda_k: 1 Loss: 0.08465463170804337\n",
      "Iteration: 2258 lambda_k: 1 Loss: 0.08459053759992807\n",
      "Iteration: 2259 lambda_k: 1 Loss: 0.08452646444983453\n",
      "Iteration: 2260 lambda_k: 1 Loss: 0.08446241228484976\n",
      "Iteration: 2261 lambda_k: 1 Loss: 0.08439838113215328\n",
      "Iteration: 2262 lambda_k: 1 Loss: 0.08433437101901729\n",
      "Iteration: 2263 lambda_k: 1 Loss: 0.08427038197280705\n",
      "Iteration: 2264 lambda_k: 1 Loss: 0.08420641402098074\n",
      "Iteration: 2265 lambda_k: 1 Loss: 0.08414246719109005\n",
      "Iteration: 2266 lambda_k: 1 Loss: 0.08407854151078013\n",
      "Iteration: 2267 lambda_k: 1 Loss: 0.08401463700778987\n",
      "Iteration: 2268 lambda_k: 1 Loss: 0.08395075370995218\n",
      "Iteration: 2269 lambda_k: 1 Loss: 0.08388689164519414\n",
      "Iteration: 2270 lambda_k: 1 Loss: 0.0838230508415373\n",
      "Iteration: 2271 lambda_k: 1 Loss: 0.08375923132709773\n",
      "Iteration: 2272 lambda_k: 1 Loss: 0.08369543313008646\n",
      "Iteration: 2273 lambda_k: 1 Loss: 0.08363165627880946\n",
      "Iteration: 2274 lambda_k: 1 Loss: 0.08356790080166814\n",
      "Iteration: 2275 lambda_k: 1 Loss: 0.08350416672715928\n",
      "Iteration: 2276 lambda_k: 1 Loss: 0.08344045408387554\n",
      "Iteration: 2277 lambda_k: 1 Loss: 0.08337676290050536\n",
      "Iteration: 2278 lambda_k: 1 Loss: 0.08331309320583354\n",
      "Iteration: 2279 lambda_k: 1 Loss: 0.08324944502874114\n",
      "Iteration: 2280 lambda_k: 1 Loss: 0.08318581839820602\n",
      "Iteration: 2281 lambda_k: 1 Loss: 0.08312221334330275\n",
      "Iteration: 2282 lambda_k: 1 Loss: 0.08305862989320313\n",
      "Iteration: 2283 lambda_k: 1 Loss: 0.08299506807717631\n",
      "Iteration: 2284 lambda_k: 1 Loss: 0.0829315279245889\n",
      "Iteration: 2285 lambda_k: 1 Loss: 0.08286800946490537\n",
      "Iteration: 2286 lambda_k: 1 Loss: 0.08280451272768824\n",
      "Iteration: 2287 lambda_k: 1 Loss: 0.08274103774259832\n",
      "Iteration: 2288 lambda_k: 1 Loss: 0.08267758453939486\n",
      "Iteration: 2289 lambda_k: 1 Loss: 0.08261415314793594\n",
      "Iteration: 2290 lambda_k: 1 Loss: 0.08255074359817863\n",
      "Iteration: 2291 lambda_k: 1 Loss: 0.08248735592017921\n",
      "Iteration: 2292 lambda_k: 1 Loss: 0.08242399014409343\n",
      "Iteration: 2293 lambda_k: 1 Loss: 0.0823606463001768\n",
      "Iteration: 2294 lambda_k: 1 Loss: 0.08229732441878478\n",
      "Iteration: 2295 lambda_k: 1 Loss: 0.08223402453037303\n",
      "Iteration: 2296 lambda_k: 1 Loss: 0.08217074666549772\n",
      "Iteration: 2297 lambda_k: 1 Loss: 0.08210749085481572\n",
      "Iteration: 2298 lambda_k: 1 Loss: 0.08204425712908477\n",
      "Iteration: 2299 lambda_k: 1 Loss: 0.08198104551916396\n",
      "Iteration: 2300 lambda_k: 1 Loss: 0.08191785605601375\n",
      "Iteration: 2301 lambda_k: 1 Loss: 0.08185468877069632\n",
      "Iteration: 2302 lambda_k: 1 Loss: 0.08179154369437593\n",
      "Iteration: 2303 lambda_k: 1 Loss: 0.08172842085831886\n",
      "Iteration: 2304 lambda_k: 1 Loss: 0.08166532029389414\n",
      "Iteration: 2305 lambda_k: 1 Loss: 0.08160224203257331\n",
      "Iteration: 2306 lambda_k: 1 Loss: 0.08153918610593103\n",
      "Iteration: 2307 lambda_k: 1 Loss: 0.0814761525456452\n",
      "Iteration: 2308 lambda_k: 1 Loss: 0.08141314138349721\n",
      "Iteration: 2309 lambda_k: 1 Loss: 0.08135015265137228\n",
      "Iteration: 2310 lambda_k: 1 Loss: 0.08128718638125967\n",
      "Iteration: 2311 lambda_k: 1 Loss: 0.08122424260525293\n",
      "Iteration: 2312 lambda_k: 1 Loss: 0.08116132135555018\n",
      "Iteration: 2313 lambda_k: 1 Loss: 0.08109842266445448\n",
      "Iteration: 2314 lambda_k: 1 Loss: 0.08103554656437385\n",
      "Iteration: 2315 lambda_k: 1 Loss: 0.08097269308782196\n",
      "Iteration: 2316 lambda_k: 1 Loss: 0.08090986226741795\n",
      "Iteration: 2317 lambda_k: 1 Loss: 0.08084705413588676\n",
      "Iteration: 2318 lambda_k: 1 Loss: 0.08078426872605968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2319 lambda_k: 1 Loss: 0.08072150607087444\n",
      "Iteration: 2320 lambda_k: 1 Loss: 0.08065876620337553\n",
      "Iteration: 2321 lambda_k: 1 Loss: 0.0805960491567145\n",
      "Iteration: 2322 lambda_k: 1 Loss: 0.08053335496415012\n",
      "Iteration: 2323 lambda_k: 1 Loss: 0.08047068365904884\n",
      "Iteration: 2324 lambda_k: 1 Loss: 0.0804080352748849\n",
      "Iteration: 2325 lambda_k: 1 Loss: 0.08034540984524072\n",
      "Iteration: 2326 lambda_k: 1 Loss: 0.0802828074038071\n",
      "Iteration: 2327 lambda_k: 1 Loss: 0.0802202279843836\n",
      "Iteration: 2328 lambda_k: 1 Loss: 0.08015767162087868\n",
      "Iteration: 2329 lambda_k: 1 Loss: 0.08009513834731022\n",
      "Iteration: 2330 lambda_k: 1 Loss: 0.08003262819780557\n",
      "Iteration: 2331 lambda_k: 1 Loss: 0.07997014120660194\n",
      "Iteration: 2332 lambda_k: 1 Loss: 0.07990767740804672\n",
      "Iteration: 2333 lambda_k: 1 Loss: 0.0798452368365976\n",
      "Iteration: 2334 lambda_k: 1 Loss: 0.07978281952682315\n",
      "Iteration: 2335 lambda_k: 1 Loss: 0.07972042551340285\n",
      "Iteration: 2336 lambda_k: 1 Loss: 0.07965805483112752\n",
      "Iteration: 2337 lambda_k: 1 Loss: 0.07959570751489961\n",
      "Iteration: 2338 lambda_k: 1 Loss: 0.07953338359973344\n",
      "Iteration: 2339 lambda_k: 1 Loss: 0.07947108312075546\n",
      "Iteration: 2340 lambda_k: 1 Loss: 0.07940880611320472\n",
      "Iteration: 2341 lambda_k: 1 Loss: 0.07934655261243295\n",
      "Iteration: 2342 lambda_k: 1 Loss: 0.0792843226539051\n",
      "Iteration: 2343 lambda_k: 1 Loss: 0.07922211627319936\n",
      "Iteration: 2344 lambda_k: 1 Loss: 0.07915993350600771\n",
      "Iteration: 2345 lambda_k: 1 Loss: 0.07909777438813617\n",
      "Iteration: 2346 lambda_k: 1 Loss: 0.0790356389555049\n",
      "Iteration: 2347 lambda_k: 1 Loss: 0.07897352724414881\n",
      "Iteration: 2348 lambda_k: 1 Loss: 0.07891143929021768\n",
      "Iteration: 2349 lambda_k: 1 Loss: 0.07884937512997642\n",
      "Iteration: 2350 lambda_k: 1 Loss: 0.07878733479980563\n",
      "Iteration: 2351 lambda_k: 1 Loss: 0.07872531833620165\n",
      "Iteration: 2352 lambda_k: 1 Loss: 0.07866332577577696\n",
      "Iteration: 2353 lambda_k: 1 Loss: 0.07860135715526062\n",
      "Iteration: 2354 lambda_k: 1 Loss: 0.0785394125114983\n",
      "Iteration: 2355 lambda_k: 1 Loss: 0.07847749188145291\n",
      "Iteration: 2356 lambda_k: 1 Loss: 0.07841559530220461\n",
      "Iteration: 2357 lambda_k: 1 Loss: 0.07835372281095143\n",
      "Iteration: 2358 lambda_k: 1 Loss: 0.07829187444500944\n",
      "Iteration: 2359 lambda_k: 1 Loss: 0.07823005024181295\n",
      "Iteration: 2360 lambda_k: 1 Loss: 0.07816825023891505\n",
      "Iteration: 2361 lambda_k: 1 Loss: 0.07810647447398775\n",
      "Iteration: 2362 lambda_k: 1 Loss: 0.07804472298482246\n",
      "Iteration: 2363 lambda_k: 1 Loss: 0.07798299580933024\n",
      "Iteration: 2364 lambda_k: 1 Loss: 0.07792129298554208\n",
      "Iteration: 2365 lambda_k: 1 Loss: 0.0778596145516093\n",
      "Iteration: 2366 lambda_k: 1 Loss: 0.0777979605458038\n",
      "Iteration: 2367 lambda_k: 1 Loss: 0.07773633100651851\n",
      "Iteration: 2368 lambda_k: 1 Loss: 0.07767472597226754\n",
      "Iteration: 2369 lambda_k: 1 Loss: 0.07761314548168674\n",
      "Iteration: 2370 lambda_k: 1 Loss: 0.07755158957353374\n",
      "Iteration: 2371 lambda_k: 1 Loss: 0.07749005828668856\n",
      "Iteration: 2372 lambda_k: 1 Loss: 0.0774285516601538\n",
      "Iteration: 2373 lambda_k: 1 Loss: 0.0773670697330551\n",
      "Iteration: 2374 lambda_k: 1 Loss: 0.0773056125446412\n",
      "Iteration: 2375 lambda_k: 1 Loss: 0.07724418013428454\n",
      "Iteration: 2376 lambda_k: 1 Loss: 0.07718277254148155\n",
      "Iteration: 2377 lambda_k: 1 Loss: 0.0771213898058529\n",
      "Iteration: 2378 lambda_k: 1 Loss: 0.07706003196714391\n",
      "Iteration: 2379 lambda_k: 1 Loss: 0.07699869906522487\n",
      "Iteration: 2380 lambda_k: 1 Loss: 0.07693739114009139\n",
      "Iteration: 2381 lambda_k: 1 Loss: 0.07687610823186473\n",
      "Iteration: 2382 lambda_k: 1 Loss: 0.07681485038079217\n",
      "Iteration: 2383 lambda_k: 1 Loss: 0.07675361762724726\n",
      "Iteration: 2384 lambda_k: 1 Loss: 0.07669241001173041\n",
      "Iteration: 2385 lambda_k: 1 Loss: 0.07663122757486888\n",
      "Iteration: 2386 lambda_k: 1 Loss: 0.07657007035741743\n",
      "Iteration: 2387 lambda_k: 1 Loss: 0.07650893840025859\n",
      "Iteration: 2388 lambda_k: 1 Loss: 0.07644783174440285\n",
      "Iteration: 2389 lambda_k: 1 Loss: 0.07638675043098925\n",
      "Iteration: 2390 lambda_k: 1 Loss: 0.07632569450128555\n",
      "Iteration: 2391 lambda_k: 1 Loss: 0.07626466399668878\n",
      "Iteration: 2392 lambda_k: 1 Loss: 0.07620365895872534\n",
      "Iteration: 2393 lambda_k: 1 Loss: 0.0761426794290516\n",
      "Iteration: 2394 lambda_k: 1 Loss: 0.07608172544945402\n",
      "Iteration: 2395 lambda_k: 1 Loss: 0.07602079706184975\n",
      "Iteration: 2396 lambda_k: 1 Loss: 0.07595989430828679\n",
      "Iteration: 2397 lambda_k: 1 Loss: 0.07589901723094453\n",
      "Iteration: 2398 lambda_k: 1 Loss: 0.07583816587213386\n",
      "Iteration: 2399 lambda_k: 1 Loss: 0.07577734027429792\n",
      "Iteration: 2400 lambda_k: 1 Loss: 0.075716540480012\n",
      "Iteration: 2401 lambda_k: 1 Loss: 0.07565576653198428\n",
      "Iteration: 2402 lambda_k: 1 Loss: 0.07559501847305593\n",
      "Iteration: 2403 lambda_k: 1 Loss: 0.07553429634620173\n",
      "Iteration: 2404 lambda_k: 1 Loss: 0.07547360019453024\n",
      "Iteration: 2405 lambda_k: 1 Loss: 0.07541293006128424\n",
      "Iteration: 2406 lambda_k: 1 Loss: 0.07535228598984106\n",
      "Iteration: 2407 lambda_k: 1 Loss: 0.07529166802371307\n",
      "Iteration: 2408 lambda_k: 1 Loss: 0.07523107620654787\n",
      "Iteration: 2409 lambda_k: 1 Loss: 0.07517051058212883\n",
      "Iteration: 2410 lambda_k: 1 Loss: 0.07510997119437529\n",
      "Iteration: 2411 lambda_k: 1 Loss: 0.07504945808734322\n",
      "Iteration: 2412 lambda_k: 1 Loss: 0.07498897130522525\n",
      "Iteration: 2413 lambda_k: 1 Loss: 0.07492851089235127\n",
      "Iteration: 2414 lambda_k: 1 Loss: 0.07486807689318868\n",
      "Iteration: 2415 lambda_k: 1 Loss: 0.07480766935234298\n",
      "Iteration: 2416 lambda_k: 1 Loss: 0.0747472883145579\n",
      "Iteration: 2417 lambda_k: 1 Loss: 0.07468693382471589\n",
      "Iteration: 2418 lambda_k: 1 Loss: 0.07462660592783851\n",
      "Iteration: 2419 lambda_k: 1 Loss: 0.07456630466908683\n",
      "Iteration: 2420 lambda_k: 1 Loss: 0.07450603009376179\n",
      "Iteration: 2421 lambda_k: 1 Loss: 0.07444578224730455\n",
      "Iteration: 2422 lambda_k: 1 Loss: 0.07438556117529692\n",
      "Iteration: 2423 lambda_k: 1 Loss: 0.07432536692346176\n",
      "Iteration: 2424 lambda_k: 1 Loss: 0.07426519953766325\n",
      "Iteration: 2425 lambda_k: 1 Loss: 0.07420505906390747\n",
      "Iteration: 2426 lambda_k: 1 Loss: 0.07414494554834267\n",
      "Iteration: 2427 lambda_k: 1 Loss: 0.07408485903725966\n",
      "Iteration: 2428 lambda_k: 1 Loss: 0.07402479957709224\n",
      "Iteration: 2429 lambda_k: 1 Loss: 0.07396476721441757\n",
      "Iteration: 2430 lambda_k: 1 Loss: 0.07390476199595655\n",
      "Iteration: 2431 lambda_k: 1 Loss: 0.07384478396857433\n",
      "Iteration: 2432 lambda_k: 1 Loss: 0.07378483317928049\n",
      "Iteration: 2433 lambda_k: 1 Loss: 0.07372490967522956\n",
      "Iteration: 2434 lambda_k: 1 Loss: 0.07366501350372157\n",
      "Iteration: 2435 lambda_k: 1 Loss: 0.07360514471220209\n",
      "Iteration: 2436 lambda_k: 1 Loss: 0.07354530334826301\n",
      "Iteration: 2437 lambda_k: 1 Loss: 0.07348548945964267\n",
      "Iteration: 2438 lambda_k: 1 Loss: 0.0734257030942263\n",
      "Iteration: 2439 lambda_k: 1 Loss: 0.07336594430004666\n",
      "Iteration: 2440 lambda_k: 1 Loss: 0.07330621312528413\n",
      "Iteration: 2441 lambda_k: 1 Loss: 0.0732465096182673\n",
      "Iteration: 2442 lambda_k: 1 Loss: 0.07318683382747324\n",
      "Iteration: 2443 lambda_k: 1 Loss: 0.0731271858015281\n",
      "Iteration: 2444 lambda_k: 1 Loss: 0.07306756558920728\n",
      "Iteration: 2445 lambda_k: 1 Loss: 0.07300797323943616\n",
      "Iteration: 2446 lambda_k: 1 Loss: 0.07294840880129007\n",
      "Iteration: 2447 lambda_k: 1 Loss: 0.07288887232399521\n",
      "Iteration: 2448 lambda_k: 1 Loss: 0.07282936385692854\n",
      "Iteration: 2449 lambda_k: 1 Loss: 0.07276988344961853\n",
      "Iteration: 2450 lambda_k: 1 Loss: 0.07271043115174557\n",
      "Iteration: 2451 lambda_k: 1 Loss: 0.07265100701314224\n",
      "Iteration: 2452 lambda_k: 1 Loss: 0.07259161108379379\n",
      "Iteration: 2453 lambda_k: 1 Loss: 0.07253224341383857\n",
      "Iteration: 2454 lambda_k: 1 Loss: 0.07247290405356843\n",
      "Iteration: 2455 lambda_k: 1 Loss: 0.07241359305342908\n",
      "Iteration: 2456 lambda_k: 1 Loss: 0.0723543104640206\n",
      "Iteration: 2457 lambda_k: 1 Loss: 0.07229505633609792\n",
      "Iteration: 2458 lambda_k: 1 Loss: 0.07223583072057095\n",
      "Iteration: 2459 lambda_k: 1 Loss: 0.07217663366850531\n",
      "Iteration: 2460 lambda_k: 1 Loss: 0.0721174652311227\n",
      "Iteration: 2461 lambda_k: 1 Loss: 0.07205832545980106\n",
      "Iteration: 2462 lambda_k: 1 Loss: 0.07199921440607536\n",
      "Iteration: 2463 lambda_k: 1 Loss: 0.07194013212163781\n",
      "Iteration: 2464 lambda_k: 1 Loss: 0.0718810786583383\n",
      "Iteration: 2465 lambda_k: 1 Loss: 0.07182205406818486\n",
      "Iteration: 2466 lambda_k: 1 Loss: 0.07176305840334415\n",
      "Iteration: 2467 lambda_k: 1 Loss: 0.07170409171614177\n",
      "Iteration: 2468 lambda_k: 1 Loss: 0.07164515405906265\n",
      "Iteration: 2469 lambda_k: 1 Loss: 0.07158624548475173\n",
      "Iteration: 2470 lambda_k: 1 Loss: 0.07152736604601408\n",
      "Iteration: 2471 lambda_k: 1 Loss: 0.0714685157958156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2472 lambda_k: 1 Loss: 0.0714096947872833\n",
      "Iteration: 2473 lambda_k: 1 Loss: 0.07135090307370572\n",
      "Iteration: 2474 lambda_k: 1 Loss: 0.07129214070853336\n",
      "Iteration: 2475 lambda_k: 1 Loss: 0.07123340774537928\n",
      "Iteration: 2476 lambda_k: 1 Loss: 0.07117470423801935\n",
      "Iteration: 2477 lambda_k: 1 Loss: 0.07111603024039265\n",
      "Iteration: 2478 lambda_k: 1 Loss: 0.07105738580660215\n",
      "Iteration: 2479 lambda_k: 1 Loss: 0.070998770990915\n",
      "Iteration: 2480 lambda_k: 1 Loss: 0.07094018584776295\n",
      "Iteration: 2481 lambda_k: 1 Loss: 0.0708816304317427\n",
      "Iteration: 2482 lambda_k: 1 Loss: 0.07082310479761653\n",
      "Iteration: 2483 lambda_k: 1 Loss: 0.07076460900031267\n",
      "Iteration: 2484 lambda_k: 1 Loss: 0.07070614309492565\n",
      "Iteration: 2485 lambda_k: 1 Loss: 0.07064770713671693\n",
      "Iteration: 2486 lambda_k: 1 Loss: 0.07058930118111517\n",
      "Iteration: 2487 lambda_k: 1 Loss: 0.07053092528371668\n",
      "Iteration: 2488 lambda_k: 1 Loss: 0.07047257950028604\n",
      "Iteration: 2489 lambda_k: 1 Loss: 0.07041426388675634\n",
      "Iteration: 2490 lambda_k: 1 Loss: 0.07035597849922964\n",
      "Iteration: 2491 lambda_k: 1 Loss: 0.07029772339397768\n",
      "Iteration: 2492 lambda_k: 1 Loss: 0.07023949862744192\n",
      "Iteration: 2493 lambda_k: 1 Loss: 0.0701813042562342\n",
      "Iteration: 2494 lambda_k: 1 Loss: 0.0701231403371374\n",
      "Iteration: 2495 lambda_k: 1 Loss: 0.07006500692710542\n",
      "Iteration: 2496 lambda_k: 1 Loss: 0.07000690408326402\n",
      "Iteration: 2497 lambda_k: 1 Loss: 0.0699488318629111\n",
      "Iteration: 2498 lambda_k: 1 Loss: 0.06989079032351714\n",
      "Iteration: 2499 lambda_k: 1 Loss: 0.06983277952272574\n",
      "Iteration: 2500 lambda_k: 1 Loss: 0.06977479951835389\n",
      "Iteration: 2501 lambda_k: 1 Loss: 0.06971685036839277\n",
      "Iteration: 2502 lambda_k: 1 Loss: 0.06965893213100778\n",
      "Iteration: 2503 lambda_k: 1 Loss: 0.06960104486453934\n",
      "Iteration: 2504 lambda_k: 1 Loss: 0.06954318862750308\n",
      "Iteration: 2505 lambda_k: 1 Loss: 0.06948536347859048\n",
      "Iteration: 2506 lambda_k: 1 Loss: 0.06942756947666927\n",
      "Iteration: 2507 lambda_k: 1 Loss: 0.06936980668078385\n",
      "Iteration: 2508 lambda_k: 1 Loss: 0.06931207515015574\n",
      "Iteration: 2509 lambda_k: 1 Loss: 0.06925437494418409\n",
      "Iteration: 2510 lambda_k: 1 Loss: 0.06919670612244612\n",
      "Iteration: 2511 lambda_k: 1 Loss: 0.06913906874469761\n",
      "Iteration: 2512 lambda_k: 1 Loss: 0.06908146287087316\n",
      "Iteration: 2513 lambda_k: 1 Loss: 0.06902388856108704\n",
      "Iteration: 2514 lambda_k: 1 Loss: 0.0689663458756332\n",
      "Iteration: 2515 lambda_k: 1 Loss: 0.06890883487498609\n",
      "Iteration: 2516 lambda_k: 1 Loss: 0.06885135561980087\n",
      "Iteration: 2517 lambda_k: 1 Loss: 0.068793908170914\n",
      "Iteration: 2518 lambda_k: 1 Loss: 0.06873649258934375\n",
      "Iteration: 2519 lambda_k: 1 Loss: 0.06867910893629046\n",
      "Iteration: 2520 lambda_k: 1 Loss: 0.06862175727313724\n",
      "Iteration: 2521 lambda_k: 1 Loss: 0.06856443766145026\n",
      "Iteration: 2522 lambda_k: 1 Loss: 0.06850715016297931\n",
      "Iteration: 2523 lambda_k: 1 Loss: 0.0684498948396581\n",
      "Iteration: 2524 lambda_k: 1 Loss: 0.06839267175360499\n",
      "Iteration: 2525 lambda_k: 1 Loss: 0.0683354809671232\n",
      "Iteration: 2526 lambda_k: 1 Loss: 0.06827832254270151\n",
      "Iteration: 2527 lambda_k: 1 Loss: 0.06822119654301453\n",
      "Iteration: 2528 lambda_k: 1 Loss: 0.06816410303092324\n",
      "Iteration: 2529 lambda_k: 1 Loss: 0.06810704206947531\n",
      "Iteration: 2530 lambda_k: 1 Loss: 0.0680500137219059\n",
      "Iteration: 2531 lambda_k: 1 Loss: 0.06799301805163788\n",
      "Iteration: 2532 lambda_k: 1 Loss: 0.06793605512228226\n",
      "Iteration: 2533 lambda_k: 1 Loss: 0.0678791249976388\n",
      "Iteration: 2534 lambda_k: 1 Loss: 0.06782222774169641\n",
      "Iteration: 2535 lambda_k: 1 Loss: 0.06776536341863364\n",
      "Iteration: 2536 lambda_k: 1 Loss: 0.06770853209281898\n",
      "Iteration: 2537 lambda_k: 1 Loss: 0.06765173382881173\n",
      "Iteration: 2538 lambda_k: 1 Loss: 0.067594968691362\n",
      "Iteration: 2539 lambda_k: 1 Loss: 0.06753823674541154\n",
      "Iteration: 2540 lambda_k: 1 Loss: 0.06748153805609385\n",
      "Iteration: 2541 lambda_k: 1 Loss: 0.06742487268873511\n",
      "Iteration: 2542 lambda_k: 1 Loss: 0.0673682407088542\n",
      "Iteration: 2543 lambda_k: 1 Loss: 0.06731164218216337\n",
      "Iteration: 2544 lambda_k: 1 Loss: 0.0672550771745688\n",
      "Iteration: 2545 lambda_k: 1 Loss: 0.06719854575217094\n",
      "Iteration: 2546 lambda_k: 1 Loss: 0.06714204798126489\n",
      "Iteration: 2547 lambda_k: 1 Loss: 0.06708558392834113\n",
      "Iteration: 2548 lambda_k: 1 Loss: 0.06702915366008584\n",
      "Iteration: 2549 lambda_k: 1 Loss: 0.06697275724338123\n",
      "Iteration: 2550 lambda_k: 1 Loss: 0.06691639474530696\n",
      "Iteration: 2551 lambda_k: 1 Loss: 0.06686006623313906\n",
      "Iteration: 2552 lambda_k: 1 Loss: 0.06680377177435057\n",
      "Iteration: 2553 lambda_k: 1 Loss: 0.06674751143661317\n",
      "Iteration: 2554 lambda_k: 1 Loss: 0.066691285287797\n",
      "Iteration: 2555 lambda_k: 1 Loss: 0.06663509339597116\n",
      "Iteration: 2556 lambda_k: 1 Loss: 0.06657893582940431\n",
      "Iteration: 2557 lambda_k: 1 Loss: 0.06652281265656503\n",
      "Iteration: 2558 lambda_k: 1 Loss: 0.06646672394612219\n",
      "Iteration: 2559 lambda_k: 1 Loss: 0.06641066976694564\n",
      "Iteration: 2560 lambda_k: 1 Loss: 0.06635465018810643\n",
      "Iteration: 2561 lambda_k: 1 Loss: 0.06629866527887748\n",
      "Iteration: 2562 lambda_k: 1 Loss: 0.06624271510873403\n",
      "Iteration: 2563 lambda_k: 1 Loss: 0.06618679974735396\n",
      "Iteration: 2564 lambda_k: 1 Loss: 0.0661309192646184\n",
      "Iteration: 2565 lambda_k: 1 Loss: 0.06607507373061214\n",
      "Iteration: 2566 lambda_k: 1 Loss: 0.06601926321562417\n",
      "Iteration: 2567 lambda_k: 1 Loss: 0.06596348779014802\n",
      "Iteration: 2568 lambda_k: 1 Loss: 0.06590774752488247\n",
      "Iteration: 2569 lambda_k: 1 Loss: 0.06585204249073177\n",
      "Iteration: 2570 lambda_k: 1 Loss: 0.06579637275880633\n",
      "Iteration: 2571 lambda_k: 1 Loss: 0.06574073840042308\n",
      "Iteration: 2572 lambda_k: 1 Loss: 0.06568513948710608\n",
      "Iteration: 2573 lambda_k: 1 Loss: 0.06562957609058703\n",
      "Iteration: 2574 lambda_k: 1 Loss: 0.06557404828257635\n",
      "Iteration: 2575 lambda_k: 1 Loss: 0.06551855613609328\n",
      "Iteration: 2576 lambda_k: 1 Loss: 0.06546309972196179\n",
      "Iteration: 2577 lambda_k: 1 Loss: 0.06540767911406979\n",
      "Iteration: 2578 lambda_k: 1 Loss: 0.0653522943847535\n",
      "Iteration: 2579 lambda_k: 1 Loss: 0.06529694560699957\n",
      "Iteration: 2580 lambda_k: 1 Loss: 0.06524163285400686\n",
      "Iteration: 2581 lambda_k: 1 Loss: 0.06518635622471372\n",
      "Iteration: 2582 lambda_k: 1 Loss: 0.06513111572108804\n",
      "Iteration: 2583 lambda_k: 1 Loss: 0.0650759114789068\n",
      "Iteration: 2584 lambda_k: 1 Loss: 0.06502074356107358\n",
      "Iteration: 2585 lambda_k: 1 Loss: 0.06496561203714915\n",
      "Iteration: 2586 lambda_k: 1 Loss: 0.06491051698163837\n",
      "Iteration: 2587 lambda_k: 1 Loss: 0.06485545846918946\n",
      "Iteration: 2588 lambda_k: 1 Loss: 0.06480043657469874\n",
      "Iteration: 2589 lambda_k: 1 Loss: 0.06474545137327817\n",
      "Iteration: 2590 lambda_k: 1 Loss: 0.06469050294025509\n",
      "Iteration: 2591 lambda_k: 1 Loss: 0.06463559135117233\n",
      "Iteration: 2592 lambda_k: 1 Loss: 0.06458071668178897\n",
      "Iteration: 2593 lambda_k: 1 Loss: 0.06452587900808078\n",
      "Iteration: 2594 lambda_k: 1 Loss: 0.06447107840624036\n",
      "Iteration: 2595 lambda_k: 1 Loss: 0.06441631495267805\n",
      "Iteration: 2596 lambda_k: 1 Loss: 0.06436158872402192\n",
      "Iteration: 2597 lambda_k: 1 Loss: 0.06430689979711865\n",
      "Iteration: 2598 lambda_k: 1 Loss: 0.06425224824903364\n",
      "Iteration: 2599 lambda_k: 1 Loss: 0.0641976341570517\n",
      "Iteration: 2600 lambda_k: 1 Loss: 0.06414305759867729\n",
      "Iteration: 2601 lambda_k: 1 Loss: 0.06408851865163513\n",
      "Iteration: 2602 lambda_k: 1 Loss: 0.0640340173938706\n",
      "Iteration: 2603 lambda_k: 1 Loss: 0.06397955390355023\n",
      "Iteration: 2604 lambda_k: 1 Loss: 0.06392512825906199\n",
      "Iteration: 2605 lambda_k: 1 Loss: 0.06387074053901592\n",
      "Iteration: 2606 lambda_k: 1 Loss: 0.06381639082224448\n",
      "Iteration: 2607 lambda_k: 1 Loss: 0.06376207918780287\n",
      "Iteration: 2608 lambda_k: 1 Loss: 0.06370780571496974\n",
      "Iteration: 2609 lambda_k: 1 Loss: 0.0636535704832475\n",
      "Iteration: 2610 lambda_k: 1 Loss: 0.06359937357236273\n",
      "Iteration: 2611 lambda_k: 1 Loss: 0.06354521506226593\n",
      "Iteration: 2612 lambda_k: 1 Loss: 0.06349109503313365\n",
      "Iteration: 2613 lambda_k: 1 Loss: 0.06343701356536796\n",
      "Iteration: 2614 lambda_k: 1 Loss: 0.06338297073959653\n",
      "Iteration: 2615 lambda_k: 1 Loss: 0.0633289666366733\n",
      "Iteration: 2616 lambda_k: 1 Loss: 0.06327500133767919\n",
      "Iteration: 2617 lambda_k: 1 Loss: 0.06322107492392222\n",
      "Iteration: 2618 lambda_k: 1 Loss: 0.06316718747693807\n",
      "Iteration: 2619 lambda_k: 1 Loss: 0.06311333907849057\n",
      "Iteration: 2620 lambda_k: 1 Loss: 0.06305952981057192\n",
      "Iteration: 2621 lambda_k: 1 Loss: 0.06300575975540339\n",
      "Iteration: 2622 lambda_k: 1 Loss: 0.0629520289954355\n",
      "Iteration: 2623 lambda_k: 1 Loss: 0.06289833761334863\n",
      "Iteration: 2624 lambda_k: 1 Loss: 0.06284468569205325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2625 lambda_k: 1 Loss: 0.06279107331469043\n",
      "Iteration: 2626 lambda_k: 1 Loss: 0.06273750056463241\n",
      "Iteration: 2627 lambda_k: 1 Loss: 0.0626839675254827\n",
      "Iteration: 2628 lambda_k: 1 Loss: 0.06263047428107668\n",
      "Iteration: 2629 lambda_k: 1 Loss: 0.0625770209154821\n",
      "Iteration: 2630 lambda_k: 1 Loss: 0.0625236075129993\n",
      "Iteration: 2631 lambda_k: 1 Loss: 0.06247023415816177\n",
      "Iteration: 2632 lambda_k: 1 Loss: 0.06241690093573635\n",
      "Iteration: 2633 lambda_k: 1 Loss: 0.062363607930723895\n",
      "Iteration: 2634 lambda_k: 1 Loss: 0.062310355228359475\n",
      "Iteration: 2635 lambda_k: 1 Loss: 0.062257142914112905\n",
      "Iteration: 2636 lambda_k: 1 Loss: 0.06220397107368906\n",
      "Iteration: 2637 lambda_k: 1 Loss: 0.062150839818514894\n",
      "Iteration: 2638 lambda_k: 1 Loss: 0.062097749188829474\n",
      "Iteration: 2639 lambda_k: 1 Loss: 0.06204469928257466\n",
      "Iteration: 2640 lambda_k: 1 Loss: 0.06199169018500002\n",
      "Iteration: 2641 lambda_k: 1 Loss: 0.06193872200343199\n",
      "Iteration: 2642 lambda_k: 1 Loss: 0.061885794818435785\n",
      "Iteration: 2643 lambda_k: 1 Loss: 0.06183290871376939\n",
      "Iteration: 2644 lambda_k: 1 Loss: 0.06178006377662466\n",
      "Iteration: 2645 lambda_k: 1 Loss: 0.06172726009533044\n",
      "Iteration: 2646 lambda_k: 1 Loss: 0.061674497758143855\n",
      "Iteration: 2647 lambda_k: 1 Loss: 0.06162177685332091\n",
      "Iteration: 2648 lambda_k: 1 Loss: 0.061569097469348626\n",
      "Iteration: 2649 lambda_k: 1 Loss: 0.06151645969499418\n",
      "Iteration: 2650 lambda_k: 1 Loss: 0.06146386361929583\n",
      "Iteration: 2651 lambda_k: 1 Loss: 0.06141130933152981\n",
      "Iteration: 2652 lambda_k: 1 Loss: 0.06135879692120765\n",
      "Iteration: 2653 lambda_k: 1 Loss: 0.06130632647808178\n",
      "Iteration: 2654 lambda_k: 1 Loss: 0.061253898092148165\n",
      "Iteration: 2655 lambda_k: 1 Loss: 0.06120151185364638\n",
      "Iteration: 2656 lambda_k: 1 Loss: 0.061149167853059294\n",
      "Iteration: 2657 lambda_k: 1 Loss: 0.06109686618111306\n",
      "Iteration: 2658 lambda_k: 1 Loss: 0.06104460692877747\n",
      "Iteration: 2659 lambda_k: 1 Loss: 0.06099239018726646\n",
      "Iteration: 2660 lambda_k: 1 Loss: 0.06094021604803818\n",
      "Iteration: 2661 lambda_k: 1 Loss: 0.060888084602795545\n",
      "Iteration: 2662 lambda_k: 1 Loss: 0.06083599594348629\n",
      "Iteration: 2663 lambda_k: 1 Loss: 0.06078395016230343\n",
      "Iteration: 2664 lambda_k: 1 Loss: 0.06073194735168556\n",
      "Iteration: 2665 lambda_k: 1 Loss: 0.0606799876043171\n",
      "Iteration: 2666 lambda_k: 1 Loss: 0.06062807101312856\n",
      "Iteration: 2667 lambda_k: 1 Loss: 0.06057619767129684\n",
      "Iteration: 2668 lambda_k: 1 Loss: 0.060524367672245734\n",
      "Iteration: 2669 lambda_k: 1 Loss: 0.06047258110964587\n",
      "Iteration: 2670 lambda_k: 1 Loss: 0.060420838077415454\n",
      "Iteration: 2671 lambda_k: 1 Loss: 0.060369138669720136\n",
      "Iteration: 2672 lambda_k: 1 Loss: 0.06031748298097512\n",
      "Iteration: 2673 lambda_k: 1 Loss: 0.06026587110584196\n",
      "Iteration: 2674 lambda_k: 1 Loss: 0.060214303139229916\n",
      "Iteration: 2675 lambda_k: 1 Loss: 0.060162779176297906\n",
      "Iteration: 2676 lambda_k: 1 Loss: 0.06011129931245428\n",
      "Iteration: 2677 lambda_k: 1 Loss: 0.060059863643356644\n",
      "Iteration: 2678 lambda_k: 1 Loss: 0.06000847226491231\n",
      "Iteration: 2679 lambda_k: 1 Loss: 0.059957125273278455\n",
      "Iteration: 2680 lambda_k: 1 Loss: 0.05990582276486238\n",
      "Iteration: 2681 lambda_k: 1 Loss: 0.05985456483632204\n",
      "Iteration: 2682 lambda_k: 1 Loss: 0.059803351584565956\n",
      "Iteration: 2683 lambda_k: 1 Loss: 0.05975218310675371\n",
      "Iteration: 2684 lambda_k: 1 Loss: 0.05970105950029611\n",
      "Iteration: 2685 lambda_k: 1 Loss: 0.05964998086285545\n",
      "Iteration: 2686 lambda_k: 1 Loss: 0.059598947292345876\n",
      "Iteration: 2687 lambda_k: 1 Loss: 0.05954795888693347\n",
      "Iteration: 2688 lambda_k: 1 Loss: 0.05949701574503655\n",
      "Iteration: 2689 lambda_k: 1 Loss: 0.05944611796532602\n",
      "Iteration: 2690 lambda_k: 1 Loss: 0.05939526564672544\n",
      "Iteration: 2691 lambda_k: 1 Loss: 0.059344458888411354\n",
      "Iteration: 2692 lambda_k: 1 Loss: 0.05929369778981362\n",
      "Iteration: 2693 lambda_k: 1 Loss: 0.05924298245061525\n",
      "Iteration: 2694 lambda_k: 1 Loss: 0.059192312970753135\n",
      "Iteration: 2695 lambda_k: 1 Loss: 0.05914168945041789\n",
      "Iteration: 2696 lambda_k: 1 Loss: 0.05909111199005425\n",
      "Iteration: 2697 lambda_k: 1 Loss: 0.059040580690361284\n",
      "Iteration: 2698 lambda_k: 1 Loss: 0.058990095652292414\n",
      "Iteration: 2699 lambda_k: 1 Loss: 0.05893965697705579\n",
      "Iteration: 2700 lambda_k: 1 Loss: 0.058889264766114426\n",
      "Iteration: 2701 lambda_k: 1 Loss: 0.05883891912118653\n",
      "Iteration: 2702 lambda_k: 1 Loss: 0.05878862014424529\n",
      "Iteration: 2703 lambda_k: 1 Loss: 0.05873836793751948\n",
      "Iteration: 2704 lambda_k: 1 Loss: 0.05868816260349346\n",
      "Iteration: 2705 lambda_k: 1 Loss: 0.058638004244907393\n",
      "Iteration: 2706 lambda_k: 1 Loss: 0.05858789296475724\n",
      "Iteration: 2707 lambda_k: 1 Loss: 0.058537828866295216\n",
      "Iteration: 2708 lambda_k: 1 Loss: 0.05848781205302969\n",
      "Iteration: 2709 lambda_k: 1 Loss: 0.058437842628725464\n",
      "Iteration: 2710 lambda_k: 1 Loss: 0.05838792069740385\n",
      "Iteration: 2711 lambda_k: 1 Loss: 0.05833804636334291\n",
      "Iteration: 2712 lambda_k: 1 Loss: 0.05828821973107739\n",
      "Iteration: 2713 lambda_k: 1 Loss: 0.058238440905399126\n",
      "Iteration: 2714 lambda_k: 1 Loss: 0.058188709991356904\n",
      "Iteration: 2715 lambda_k: 1 Loss: 0.05813902709425679\n",
      "Iteration: 2716 lambda_k: 1 Loss: 0.05808939231966213\n",
      "Iteration: 2717 lambda_k: 1 Loss: 0.058039805773393724\n",
      "Iteration: 2718 lambda_k: 1 Loss: 0.05799026756152977\n",
      "Iteration: 2719 lambda_k: 1 Loss: 0.057940777790406045\n",
      "Iteration: 2720 lambda_k: 1 Loss: 0.05789133656661619\n",
      "Iteration: 2721 lambda_k: 1 Loss: 0.05784194399701141\n",
      "Iteration: 2722 lambda_k: 1 Loss: 0.05779260018870082\n",
      "Iteration: 2723 lambda_k: 1 Loss: 0.057743305249051635\n",
      "Iteration: 2724 lambda_k: 1 Loss: 0.0576940592856889\n",
      "Iteration: 2725 lambda_k: 1 Loss: 0.05764486240649519\n",
      "Iteration: 2726 lambda_k: 1 Loss: 0.057595714719612646\n",
      "Iteration: 2727 lambda_k: 1 Loss: 0.05754661633344074\n",
      "Iteration: 2728 lambda_k: 1 Loss: 0.05749756735663705\n",
      "Iteration: 2729 lambda_k: 1 Loss: 0.05744856789811745\n",
      "Iteration: 2730 lambda_k: 1 Loss: 0.057399618067056096\n",
      "Iteration: 2731 lambda_k: 1 Loss: 0.057350717972885386\n",
      "Iteration: 2732 lambda_k: 1 Loss: 0.05730186772529601\n",
      "Iteration: 2733 lambda_k: 1 Loss: 0.05725306743423719\n",
      "Iteration: 2734 lambda_k: 1 Loss: 0.05720431720991618\n",
      "Iteration: 2735 lambda_k: 1 Loss: 0.05715561716279866\n",
      "Iteration: 2736 lambda_k: 1 Loss: 0.05710696740360872\n",
      "Iteration: 2737 lambda_k: 1 Loss: 0.057058368043328554\n",
      "Iteration: 2738 lambda_k: 1 Loss: 0.05700981919319878\n",
      "Iteration: 2739 lambda_k: 1 Loss: 0.05696132096471831\n",
      "Iteration: 2740 lambda_k: 1 Loss: 0.05691287346964403\n",
      "Iteration: 2741 lambda_k: 1 Loss: 0.05686447681999118\n",
      "Iteration: 2742 lambda_k: 1 Loss: 0.05681613112803293\n",
      "Iteration: 2743 lambda_k: 1 Loss: 0.05676783650630067\n",
      "Iteration: 2744 lambda_k: 1 Loss: 0.05671959306759519\n",
      "Iteration: 2745 lambda_k: 1 Loss: 0.056671400924966794\n",
      "Iteration: 2746 lambda_k: 1 Loss: 0.056623260191707166\n",
      "Iteration: 2747 lambda_k: 1 Loss: 0.05657517098137598\n",
      "Iteration: 2748 lambda_k: 1 Loss: 0.05652713340779424\n",
      "Iteration: 2749 lambda_k: 1 Loss: 0.05647914758504066\n",
      "Iteration: 2750 lambda_k: 1 Loss: 0.056431213627450565\n",
      "Iteration: 2751 lambda_k: 1 Loss: 0.0563833316496165\n",
      "Iteration: 2752 lambda_k: 1 Loss: 0.056335501766388345\n",
      "Iteration: 2753 lambda_k: 1 Loss: 0.05628772409287297\n",
      "Iteration: 2754 lambda_k: 1 Loss: 0.0562399987444343\n",
      "Iteration: 2755 lambda_k: 1 Loss: 0.05619232583669285\n",
      "Iteration: 2756 lambda_k: 1 Loss: 0.0561447054855258\n",
      "Iteration: 2757 lambda_k: 1 Loss: 0.05609713780706676\n",
      "Iteration: 2758 lambda_k: 1 Loss: 0.056049622917705585\n",
      "Iteration: 2759 lambda_k: 1 Loss: 0.05600216093408817\n",
      "Iteration: 2760 lambda_k: 1 Loss: 0.055954751978530386\n",
      "Iteration: 2761 lambda_k: 1 Loss: 0.05590739615846511\n",
      "Iteration: 2762 lambda_k: 1 Loss: 0.05586009359415972\n",
      "Iteration: 2763 lambda_k: 1 Loss: 0.055812844404805266\n",
      "Iteration: 2764 lambda_k: 1 Loss: 0.05576564870851978\n",
      "Iteration: 2765 lambda_k: 1 Loss: 0.05571850662327111\n",
      "Iteration: 2766 lambda_k: 1 Loss: 0.05567141826740813\n",
      "Iteration: 2767 lambda_k: 1 Loss: 0.05562438375963811\n",
      "Iteration: 2768 lambda_k: 1 Loss: 0.05557740321892385\n",
      "Iteration: 2769 lambda_k: 1 Loss: 0.055530476764461094\n",
      "Iteration: 2770 lambda_k: 1 Loss: 0.05548360451569244\n",
      "Iteration: 2771 lambda_k: 1 Loss: 0.05543678657099528\n",
      "Iteration: 2772 lambda_k: 1 Loss: 0.055390023088483835\n",
      "Iteration: 2773 lambda_k: 1 Loss: 0.05534331417941213\n",
      "Iteration: 2774 lambda_k: 1 Loss: 0.055296659956528\n",
      "Iteration: 2775 lambda_k: 1 Loss: 0.05525006053882836\n",
      "Iteration: 2776 lambda_k: 1 Loss: 0.055203516048131604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2777 lambda_k: 1 Loss: 0.05515702660621541\n",
      "Iteration: 2778 lambda_k: 1 Loss: 0.05511059233458567\n",
      "Iteration: 2779 lambda_k: 1 Loss: 0.055064213354892484\n",
      "Iteration: 2780 lambda_k: 1 Loss: 0.05501788980109634\n",
      "Iteration: 2781 lambda_k: 1 Loss: 0.05497162177389807\n",
      "Iteration: 2782 lambda_k: 1 Loss: 0.05492540940032213\n",
      "Iteration: 2783 lambda_k: 1 Loss: 0.054879252807866805\n",
      "Iteration: 2784 lambda_k: 1 Loss: 0.054833152120768267\n",
      "Iteration: 2785 lambda_k: 1 Loss: 0.054787107461756426\n",
      "Iteration: 2786 lambda_k: 1 Loss: 0.054741118953906674\n",
      "Iteration: 2787 lambda_k: 1 Loss: 0.05469518672087028\n",
      "Iteration: 2788 lambda_k: 1 Loss: 0.05464931088663652\n",
      "Iteration: 2789 lambda_k: 1 Loss: 0.05460349157541602\n",
      "Iteration: 2790 lambda_k: 1 Loss: 0.05455772891164308\n",
      "Iteration: 2791 lambda_k: 1 Loss: 0.054512023019995776\n",
      "Iteration: 2792 lambda_k: 1 Loss: 0.054466374025401304\n",
      "Iteration: 2793 lambda_k: 1 Loss: 0.05442078205303378\n",
      "Iteration: 2794 lambda_k: 1 Loss: 0.05437524722831195\n",
      "Iteration: 2795 lambda_k: 1 Loss: 0.0543297696768983\n",
      "Iteration: 2796 lambda_k: 1 Loss: 0.05428434952469869\n",
      "Iteration: 2797 lambda_k: 1 Loss: 0.05423898689786189\n",
      "Iteration: 2798 lambda_k: 1 Loss: 0.05419368192277884\n",
      "Iteration: 2799 lambda_k: 1 Loss: 0.05414843472608206\n",
      "Iteration: 2800 lambda_k: 1 Loss: 0.054103245434644794\n",
      "Iteration: 2801 lambda_k: 1 Loss: 0.05405811417558082\n",
      "Iteration: 2802 lambda_k: 1 Loss: 0.05401304107624332\n",
      "Iteration: 2803 lambda_k: 1 Loss: 0.05396802626422454\n",
      "Iteration: 2804 lambda_k: 1 Loss: 0.05392306986735504\n",
      "Iteration: 2805 lambda_k: 1 Loss: 0.05387817201370294\n",
      "Iteration: 2806 lambda_k: 1 Loss: 0.05383333283157336\n",
      "Iteration: 2807 lambda_k: 1 Loss: 0.05378855244950775\n",
      "Iteration: 2808 lambda_k: 1 Loss: 0.05374383099628303\n",
      "Iteration: 2809 lambda_k: 1 Loss: 0.05369916860091099\n",
      "Iteration: 2810 lambda_k: 1 Loss: 0.053654565392637715\n",
      "Iteration: 2811 lambda_k: 1 Loss: 0.05361002150094267\n",
      "Iteration: 2812 lambda_k: 1 Loss: 0.053565537055537835\n",
      "Iteration: 2813 lambda_k: 1 Loss: 0.053521112186367396\n",
      "Iteration: 2814 lambda_k: 1 Loss: 0.05347674702360659\n",
      "Iteration: 2815 lambda_k: 1 Loss: 0.053432441697661065\n",
      "Iteration: 2816 lambda_k: 1 Loss: 0.053388196339166145\n",
      "Iteration: 2817 lambda_k: 1 Loss: 0.053344011078985974\n",
      "Iteration: 2818 lambda_k: 1 Loss: 0.05329988604821272\n",
      "Iteration: 2819 lambda_k: 1 Loss: 0.05325582137816578\n",
      "Iteration: 2820 lambda_k: 1 Loss: 0.05321181720039087\n",
      "Iteration: 2821 lambda_k: 1 Loss: 0.0531678736466594\n",
      "Iteration: 2822 lambda_k: 1 Loss: 0.05312399084896719\n",
      "Iteration: 2823 lambda_k: 1 Loss: 0.05308016893953408\n",
      "Iteration: 2824 lambda_k: 1 Loss: 0.05303640805080272\n",
      "Iteration: 2825 lambda_k: 1 Loss: 0.052992708315437884\n",
      "Iteration: 2826 lambda_k: 1 Loss: 0.052949069866325436\n",
      "Iteration: 2827 lambda_k: 1 Loss: 0.05290549283657139\n",
      "Iteration: 2828 lambda_k: 1 Loss: 0.05286197735950101\n",
      "Iteration: 2829 lambda_k: 1 Loss: 0.052818523568657905\n",
      "Iteration: 2830 lambda_k: 1 Loss: 0.05277513159780301\n",
      "Iteration: 2831 lambda_k: 1 Loss: 0.0527318015809136\n",
      "Iteration: 2832 lambda_k: 1 Loss: 0.05268853365218244\n",
      "Iteration: 2833 lambda_k: 1 Loss: 0.05264532794601653\n",
      "Iteration: 2834 lambda_k: 1 Loss: 0.052602184597036306\n",
      "Iteration: 2835 lambda_k: 1 Loss: 0.05255910374007451\n",
      "Iteration: 2836 lambda_k: 1 Loss: 0.05251608551017517\n",
      "Iteration: 2837 lambda_k: 1 Loss: 0.052473130042592395\n",
      "Iteration: 2838 lambda_k: 1 Loss: 0.052430237472789645\n",
      "Iteration: 2839 lambda_k: 1 Loss: 0.052387407936438236\n",
      "Iteration: 2840 lambda_k: 1 Loss: 0.05234464156941659\n",
      "Iteration: 2841 lambda_k: 1 Loss: 0.05230193850780888\n",
      "Iteration: 2842 lambda_k: 1 Loss: 0.05225929888790392\n",
      "Iteration: 2843 lambda_k: 1 Loss: 0.052216722846194205\n",
      "Iteration: 2844 lambda_k: 1 Loss: 0.052174210519374445\n",
      "Iteration: 2845 lambda_k: 1 Loss: 0.05213176204434065\n",
      "Iteration: 2846 lambda_k: 1 Loss: 0.05208937755818883\n",
      "Iteration: 2847 lambda_k: 1 Loss: 0.052047057198213856\n",
      "Iteration: 2848 lambda_k: 1 Loss: 0.05200480110190804\n",
      "Iteration: 2849 lambda_k: 1 Loss: 0.05196260940696018\n",
      "Iteration: 2850 lambda_k: 1 Loss: 0.05192048225125412\n",
      "Iteration: 2851 lambda_k: 1 Loss: 0.0518784197728675\n",
      "Iteration: 2852 lambda_k: 1 Loss: 0.05183642211007042\n",
      "Iteration: 2853 lambda_k: 1 Loss: 0.05179448940132439\n",
      "Iteration: 2854 lambda_k: 1 Loss: 0.05175262178528085\n",
      "Iteration: 2855 lambda_k: 1 Loss: 0.05171081940077968\n",
      "Iteration: 2856 lambda_k: 1 Loss: 0.05166908238684811\n",
      "Iteration: 2857 lambda_k: 1 Loss: 0.05162741088269926\n",
      "Iteration: 2858 lambda_k: 1 Loss: 0.05158580502773071\n",
      "Iteration: 2859 lambda_k: 1 Loss: 0.05154426496152317\n",
      "Iteration: 2860 lambda_k: 1 Loss: 0.05150279082383913\n",
      "Iteration: 2861 lambda_k: 1 Loss: 0.051461382754621365\n",
      "Iteration: 2862 lambda_k: 1 Loss: 0.05142004089399137\n",
      "Iteration: 2863 lambda_k: 1 Loss: 0.051378765382248136\n",
      "Iteration: 2864 lambda_k: 1 Loss: 0.05133755635986654\n",
      "Iteration: 2865 lambda_k: 1 Loss: 0.05129641396749592\n",
      "Iteration: 2866 lambda_k: 1 Loss: 0.051255338345958475\n",
      "Iteration: 2867 lambda_k: 1 Loss: 0.05121432963624786\n",
      "Iteration: 2868 lambda_k: 1 Loss: 0.05117338797952751\n",
      "Iteration: 2869 lambda_k: 1 Loss: 0.0511325135171292\n",
      "Iteration: 2870 lambda_k: 1 Loss: 0.05109170639055145\n",
      "Iteration: 2871 lambda_k: 1 Loss: 0.05105096674145789\n",
      "Iteration: 2872 lambda_k: 1 Loss: 0.05101029471167567\n",
      "Iteration: 2873 lambda_k: 1 Loss: 0.05096969044319388\n",
      "Iteration: 2874 lambda_k: 1 Loss: 0.05092915407816197\n",
      "Iteration: 2875 lambda_k: 1 Loss: 0.05088868575888789\n",
      "Iteration: 2876 lambda_k: 1 Loss: 0.050848285627836554\n",
      "Iteration: 2877 lambda_k: 1 Loss: 0.050807953827628136\n",
      "Iteration: 2878 lambda_k: 1 Loss: 0.050767690501036446\n",
      "Iteration: 2879 lambda_k: 1 Loss: 0.05072749579098698\n",
      "Iteration: 2880 lambda_k: 1 Loss: 0.05068736984055538\n",
      "Iteration: 2881 lambda_k: 1 Loss: 0.05064731279296563\n",
      "Iteration: 2882 lambda_k: 1 Loss: 0.05060732479158825\n",
      "Iteration: 2883 lambda_k: 1 Loss: 0.05056740597993842\n",
      "Iteration: 2884 lambda_k: 1 Loss: 0.05052755650167444\n",
      "Iteration: 2885 lambda_k: 1 Loss: 0.05048777650059569\n",
      "Iteration: 2886 lambda_k: 1 Loss: 0.050448066120640685\n",
      "Iteration: 2887 lambda_k: 1 Loss: 0.05040842550588547\n",
      "Iteration: 2888 lambda_k: 1 Loss: 0.05036885480054153\n",
      "Iteration: 2889 lambda_k: 1 Loss: 0.05032935414895453\n",
      "Iteration: 2890 lambda_k: 1 Loss: 0.050289923695600904\n",
      "Iteration: 2891 lambda_k: 1 Loss: 0.0502505635886618\n",
      "Iteration: 2892 lambda_k: 1 Loss: 0.050211273966537656\n",
      "Iteration: 2893 lambda_k: 1 Loss: 0.05017205497553514\n",
      "Iteration: 2894 lambda_k: 1 Loss: 0.0501329067619456\n",
      "Iteration: 2895 lambda_k: 1 Loss: 0.05009382947112418\n",
      "Iteration: 2896 lambda_k: 1 Loss: 0.05005482324814758\n",
      "Iteration: 2897 lambda_k: 1 Loss: 0.05001588823827273\n",
      "Iteration: 2898 lambda_k: 1 Loss: 0.049977024586958727\n",
      "Iteration: 2899 lambda_k: 1 Loss: 0.04993823243979203\n",
      "Iteration: 2900 lambda_k: 1 Loss: 0.04989951194245959\n",
      "Iteration: 2901 lambda_k: 1 Loss: 0.04986086324075252\n",
      "Iteration: 2902 lambda_k: 1 Loss: 0.04982228648056534\n",
      "Iteration: 2903 lambda_k: 1 Loss: 0.04978378180790845\n",
      "Iteration: 2904 lambda_k: 1 Loss: 0.04974534936889693\n",
      "Iteration: 2905 lambda_k: 1 Loss: 0.04970698930974273\n",
      "Iteration: 2906 lambda_k: 1 Loss: 0.04966870177671738\n",
      "Iteration: 2907 lambda_k: 1 Loss: 0.049630486915340825\n",
      "Iteration: 2908 lambda_k: 1 Loss: 0.049592344873498916\n",
      "Iteration: 2909 lambda_k: 1 Loss: 0.04955427579702488\n",
      "Iteration: 2910 lambda_k: 1 Loss: 0.049516279832886034\n",
      "Iteration: 2911 lambda_k: 1 Loss: 0.04947834781624528\n",
      "Iteration: 2912 lambda_k: 1 Loss: 0.04944042386370612\n",
      "Iteration: 2913 lambda_k: 1 Loss: 0.04940277200347844\n",
      "Iteration: 2914 lambda_k: 1 Loss: 0.04936526520282441\n",
      "Iteration: 2915 lambda_k: 1 Loss: 0.04932781410511002\n",
      "Iteration: 2916 lambda_k: 1 Loss: 0.049290392619420316\n",
      "Iteration: 2917 lambda_k: 1 Loss: 0.04925301392577911\n",
      "Iteration: 2918 lambda_k: 1 Loss: 0.04921569871308687\n",
      "Iteration: 2919 lambda_k: 1 Loss: 0.04917845823408488\n",
      "Iteration: 2920 lambda_k: 1 Loss: 0.049141292869664836\n",
      "Iteration: 2921 lambda_k: 1 Loss: 0.04910419765064271\n",
      "Iteration: 2922 lambda_k: 1 Loss: 0.04906716747391724\n",
      "Iteration: 2923 lambda_k: 1 Loss: 0.049030199306003885\n",
      "Iteration: 2924 lambda_k: 1 Loss: 0.048993291954864175\n",
      "Iteration: 2925 lambda_k: 1 Loss: 0.048956444988785694\n",
      "Iteration: 2926 lambda_k: 1 Loss: 0.04891965791010659\n",
      "Iteration: 2927 lambda_k: 1 Loss: 0.04888292988653222\n",
      "Iteration: 2928 lambda_k: 1 Loss: 0.04884625985165701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 2929 lambda_k: 1 Loss: 0.04880964669485737\n",
      "Iteration: 2930 lambda_k: 1 Loss: 0.048773089379629535\n",
      "Iteration: 2931 lambda_k: 1 Loss: 0.04873658695594341\n",
      "Iteration: 2932 lambda_k: 1 Loss: 0.04870013856858581\n",
      "Iteration: 2933 lambda_k: 1 Loss: 0.04866374337447376\n",
      "Iteration: 2934 lambda_k: 1 Loss: 0.048627400540841526\n",
      "Iteration: 2935 lambda_k: 1 Loss: 0.04859110924781335\n",
      "Iteration: 2936 lambda_k: 1 Loss: 0.048554868691495556\n",
      "Iteration: 2937 lambda_k: 1 Loss: 0.04851867808622789\n",
      "Iteration: 2938 lambda_k: 1 Loss: 0.048482536675910105\n",
      "Iteration: 2939 lambda_k: 1 Loss: 0.048446443695427846\n",
      "Iteration: 2940 lambda_k: 1 Loss: 0.04841039841059669\n",
      "Iteration: 2941 lambda_k: 1 Loss: 0.04837440010921986\n",
      "Iteration: 2942 lambda_k: 1 Loss: 0.0483384480877465\n",
      "Iteration: 2943 lambda_k: 1 Loss: 0.04830254165575525\n",
      "Iteration: 2944 lambda_k: 1 Loss: 0.048266680133405404\n",
      "Iteration: 2945 lambda_k: 1 Loss: 0.04823086285232152\n",
      "Iteration: 2946 lambda_k: 1 Loss: 0.04819508915934102\n",
      "Iteration: 2947 lambda_k: 1 Loss: 0.04815935841125174\n",
      "Iteration: 2948 lambda_k: 1 Loss: 0.04812366997489644\n",
      "Iteration: 2949 lambda_k: 1 Loss: 0.04808802322828438\n",
      "Iteration: 2950 lambda_k: 1 Loss: 0.04805241756008309\n",
      "Iteration: 2951 lambda_k: 1 Loss: 0.04801685236888662\n",
      "Iteration: 2952 lambda_k: 1 Loss: 0.047981327062167706\n",
      "Iteration: 2953 lambda_k: 1 Loss: 0.04794584100647771\n",
      "Iteration: 2954 lambda_k: 1 Loss: 0.04791039323160439\n",
      "Iteration: 2955 lambda_k: 1 Loss: 0.047872216283212456\n",
      "Iteration: 2956 lambda_k: 1 Loss: 0.04783586200741825\n",
      "Iteration: 2957 lambda_k: 1 Loss: 0.047801200922934176\n",
      "Iteration: 2958 lambda_k: 1 Loss: 0.047766939523470164\n",
      "Iteration: 2959 lambda_k: 1 Loss: 0.04773256924289333\n",
      "Iteration: 2960 lambda_k: 1 Loss: 0.04769815651579277\n",
      "Iteration: 2961 lambda_k: 1 Loss: 0.04766393258046932\n",
      "Iteration: 2962 lambda_k: 1 Loss: 0.04763003427214949\n",
      "Iteration: 2963 lambda_k: 1 Loss: 0.047596458862982534\n",
      "Iteration: 2964 lambda_k: 1 Loss: 0.04756312811594389\n",
      "Iteration: 2965 lambda_k: 1 Loss: 0.04752995888697521\n",
      "Iteration: 2966 lambda_k: 1 Loss: 0.047496896789256726\n",
      "Iteration: 2967 lambda_k: 1 Loss: 0.04746391551994741\n",
      "Iteration: 2968 lambda_k: 1 Loss: 0.047431002214514094\n",
      "Iteration: 2969 lambda_k: 1 Loss: 0.04739814534570717\n",
      "Iteration: 2970 lambda_k: 1 Loss: 0.04736533050425184\n",
      "Iteration: 2971 lambda_k: 1 Loss: 0.04733254167387603\n",
      "Iteration: 2972 lambda_k: 1 Loss: 0.04729976387505695\n",
      "Iteration: 2973 lambda_k: 1 Loss: 0.047266984739004377\n",
      "Iteration: 2974 lambda_k: 1 Loss: 0.047234194648318927\n",
      "Iteration: 2975 lambda_k: 1 Loss: 0.04720138611659775\n",
      "Iteration: 2976 lambda_k: 1 Loss: 0.04716855311009685\n",
      "Iteration: 2977 lambda_k: 1 Loss: 0.04713569063051659\n",
      "Iteration: 2978 lambda_k: 1 Loss: 0.047102794548149925\n",
      "Iteration: 2979 lambda_k: 1 Loss: 0.047069861551306755\n",
      "Iteration: 2980 lambda_k: 1 Loss: 0.04703688910355585\n",
      "Iteration: 2981 lambda_k: 1 Loss: 0.04700387536928133\n",
      "Iteration: 2982 lambda_k: 1 Loss: 0.04697081911575451\n",
      "Iteration: 2983 lambda_k: 1 Loss: 0.046937719613435604\n",
      "Iteration: 2984 lambda_k: 1 Loss: 0.0469045765493069\n",
      "Iteration: 2985 lambda_k: 1 Loss: 0.04687138995700157\n",
      "Iteration: 2986 lambda_k: 1 Loss: 0.046838160160729454\n",
      "Iteration: 2987 lambda_k: 1 Loss: 0.04680488772844715\n",
      "Iteration: 2988 lambda_k: 1 Loss: 0.046771573431009864\n",
      "Iteration: 2989 lambda_k: 1 Loss: 0.04673821820582307\n",
      "Iteration: 2990 lambda_k: 1 Loss: 0.04670482312462473\n",
      "Iteration: 2991 lambda_k: 1 Loss: 0.04667138936536094\n",
      "Iteration: 2992 lambda_k: 1 Loss: 0.046637918188009615\n",
      "Iteration: 2993 lambda_k: 1 Loss: 0.04660441091399808\n",
      "Iteration: 2994 lambda_k: 1 Loss: 0.04657086890873872\n",
      "Iteration: 2995 lambda_k: 1 Loss: 0.04653729356680329\n",
      "Iteration: 2996 lambda_k: 1 Loss: 0.04650368629932912\n",
      "Iteration: 2997 lambda_k: 1 Loss: 0.046470048523336346\n",
      "Iteration: 2998 lambda_k: 1 Loss: 0.04643638165270923\n",
      "Iteration: 2999 lambda_k: 1 Loss: 0.046402687090636136\n",
      "Iteration: 3000 lambda_k: 1 Loss: 0.046368966223326785\n",
      "Iteration: 3001 lambda_k: 1 Loss: 0.04633522041484185\n",
      "Iteration: 3002 lambda_k: 1 Loss: 0.04630145100288246\n",
      "Iteration: 3003 lambda_k: 1 Loss: 0.04626765929540595\n",
      "Iteration: 3004 lambda_k: 1 Loss: 0.04623384656795013\n",
      "Iteration: 3005 lambda_k: 1 Loss: 0.04620001406156625\n",
      "Iteration: 3006 lambda_k: 1 Loss: 0.04616616298127409\n",
      "Iteration: 3007 lambda_k: 1 Loss: 0.04613229449496468\n",
      "Iteration: 3008 lambda_k: 1 Loss: 0.04609840973268564\n",
      "Iteration: 3009 lambda_k: 1 Loss: 0.046064509786252095\n",
      "Iteration: 3010 lambda_k: 1 Loss: 0.04603059570913289\n",
      "Iteration: 3011 lambda_k: 1 Loss: 0.04599666851656908\n",
      "Iteration: 3012 lambda_k: 1 Loss: 0.045962729185886855\n",
      "Iteration: 3013 lambda_k: 1 Loss: 0.04592877865697266\n",
      "Iteration: 3014 lambda_k: 1 Loss: 0.04589481783288092\n",
      "Iteration: 3015 lambda_k: 1 Loss: 0.04586084758055175\n",
      "Iteration: 3016 lambda_k: 1 Loss: 0.04582686873161621\n",
      "Iteration: 3017 lambda_k: 1 Loss: 0.04579288208327129\n",
      "Iteration: 3018 lambda_k: 1 Loss: 0.045758888399208525\n",
      "Iteration: 3019 lambda_k: 1 Loss: 0.04572488841058317\n",
      "Iteration: 3020 lambda_k: 1 Loss: 0.04569088281701199\n",
      "Iteration: 3021 lambda_k: 1 Loss: 0.045656872287589675\n",
      "Iteration: 3022 lambda_k: 1 Loss: 0.045622857461915294\n",
      "Iteration: 3023 lambda_k: 1 Loss: 0.04558883895112224\n",
      "Iteration: 3024 lambda_k: 1 Loss: 0.0455548173389045\n",
      "Iteration: 3025 lambda_k: 1 Loss: 0.04552079318253498\n",
      "Iteration: 3026 lambda_k: 1 Loss: 0.045486767013871554\n",
      "Iteration: 3027 lambda_k: 1 Loss: 0.04545273934034676\n",
      "Iteration: 3028 lambda_k: 1 Loss: 0.04541871064593852\n",
      "Iteration: 3029 lambda_k: 1 Loss: 0.04538468139211978\n",
      "Iteration: 3030 lambda_k: 1 Loss: 0.045350652018785007\n",
      "Iteration: 3031 lambda_k: 1 Loss: 0.04531662294515187\n",
      "Iteration: 3032 lambda_k: 1 Loss: 0.045282594570637325\n",
      "Iteration: 3033 lambda_k: 1 Loss: 0.04524856727570711\n",
      "Iteration: 3034 lambda_k: 1 Loss: 0.04521454142269838\n",
      "Iteration: 3035 lambda_k: 1 Loss: 0.04518051735661486\n",
      "Iteration: 3036 lambda_k: 1 Loss: 0.04514649540589451\n",
      "Iteration: 3037 lambda_k: 1 Loss: 0.04511247588314999\n",
      "Iteration: 3038 lambda_k: 1 Loss: 0.04507845908588182\n",
      "Iteration: 3039 lambda_k: 1 Loss: 0.04504444529716469\n",
      "Iteration: 3040 lambda_k: 1 Loss: 0.04501043478630727\n",
      "Iteration: 3041 lambda_k: 1 Loss: 0.04497642780948608\n",
      "Iteration: 3042 lambda_k: 1 Loss: 0.04494242461035384\n",
      "Iteration: 3043 lambda_k: 1 Loss: 0.04490842542062308\n",
      "Iteration: 3044 lambda_k: 1 Loss: 0.044874430460625565\n",
      "Iteration: 3045 lambda_k: 1 Loss: 0.044840439939847994\n",
      "Iteration: 3046 lambda_k: 1 Loss: 0.04480645405744539\n",
      "Iteration: 3047 lambda_k: 1 Loss: 0.0447724730027316\n",
      "Iteration: 3048 lambda_k: 1 Loss: 0.044738496955649174\n",
      "Iteration: 3049 lambda_k: 1 Loss: 0.04470452608721805\n",
      "Iteration: 3050 lambda_k: 1 Loss: 0.044670560559964684\n",
      "Iteration: 3051 lambda_k: 1 Loss: 0.044636600528331634\n",
      "Iteration: 3052 lambda_k: 1 Loss: 0.044602646139068974\n",
      "Iteration: 3053 lambda_k: 1 Loss: 0.044568697531607526\n",
      "Iteration: 3054 lambda_k: 1 Loss: 0.04453475483841543\n",
      "Iteration: 3055 lambda_k: 1 Loss: 0.044500818185337916\n",
      "Iteration: 3056 lambda_k: 1 Loss: 0.044466887691921614\n",
      "Iteration: 3057 lambda_k: 1 Loss: 0.044432963471723465\n",
      "Iteration: 3058 lambda_k: 1 Loss: 0.04439904563260542\n",
      "Iteration: 3059 lambda_k: 1 Loss: 0.04436513427701507\n",
      "Iteration: 3060 lambda_k: 1 Loss: 0.04433122950225324\n",
      "Iteration: 3061 lambda_k: 1 Loss: 0.044297331400728446\n",
      "Iteration: 3062 lambda_k: 1 Loss: 0.044263440060199735\n",
      "Iteration: 3063 lambda_k: 1 Loss: 0.04422955556400758\n",
      "Iteration: 3064 lambda_k: 1 Loss: 0.044195677991293654\n",
      "Iteration: 3065 lambda_k: 1 Loss: 0.044161807417210305\n",
      "Iteration: 3066 lambda_k: 1 Loss: 0.04412794391311944\n",
      "Iteration: 3067 lambda_k: 1 Loss: 0.044094087546782346\n",
      "Iteration: 3068 lambda_k: 1 Loss: 0.04406023838253966\n",
      "Iteration: 3069 lambda_k: 1 Loss: 0.044026396481483134\n",
      "Iteration: 3070 lambda_k: 1 Loss: 0.04399256190161844\n",
      "Iteration: 3071 lambda_k: 1 Loss: 0.04395873469802069\n",
      "Iteration: 3072 lambda_k: 1 Loss: 0.04392491492298146\n",
      "Iteration: 3073 lambda_k: 1 Loss: 0.04389110262614947\n",
      "Iteration: 3074 lambda_k: 1 Loss: 0.043857297854663545\n",
      "Iteration: 3075 lambda_k: 1 Loss: 0.0438235006532795\n",
      "Iteration: 3076 lambda_k: 1 Loss: 0.04378971106449075\n",
      "Iteration: 3077 lambda_k: 1 Loss: 0.043755929128642485\n",
      "Iteration: 3078 lambda_k: 1 Loss: 0.04372215488404065\n",
      "Iteration: 3079 lambda_k: 1 Loss: 0.04368838836705526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3080 lambda_k: 1 Loss: 0.04365462961221874\n",
      "Iteration: 3081 lambda_k: 1 Loss: 0.04362087865231904\n",
      "Iteration: 3082 lambda_k: 1 Loss: 0.043587135518488536\n",
      "Iteration: 3083 lambda_k: 1 Loss: 0.04355340024028801\n",
      "Iteration: 3084 lambda_k: 1 Loss: 0.04351967284578687\n",
      "Iteration: 3085 lambda_k: 1 Loss: 0.0434859533616391\n",
      "Iteration: 3086 lambda_k: 1 Loss: 0.04345224181315524\n",
      "Iteration: 3087 lambda_k: 1 Loss: 0.04341853822437115\n",
      "Iteration: 3088 lambda_k: 1 Loss: 0.043384842618112984\n",
      "Iteration: 3089 lambda_k: 1 Loss: 0.04335115501605897\n",
      "Iteration: 3090 lambda_k: 1 Loss: 0.043317475438798304\n",
      "Iteration: 3091 lambda_k: 1 Loss: 0.043283803905886604\n",
      "Iteration: 3092 lambda_k: 1 Loss: 0.043250140435898955\n",
      "Iteration: 3093 lambda_k: 1 Loss: 0.04321648504648018\n",
      "Iteration: 3094 lambda_k: 1 Loss: 0.04318283775439242\n",
      "Iteration: 3095 lambda_k: 1 Loss: 0.04314919857556041\n",
      "Iteration: 3096 lambda_k: 1 Loss: 0.04311556752511454\n",
      "Iteration: 3097 lambda_k: 1 Loss: 0.04308194461743161\n",
      "Iteration: 3098 lambda_k: 1 Loss: 0.0430483298661735\n",
      "Iteration: 3099 lambda_k: 1 Loss: 0.04301472328432394\n",
      "Iteration: 3100 lambda_k: 1 Loss: 0.04298112488422336\n",
      "Iteration: 3101 lambda_k: 1 Loss: 0.042947534677602\n",
      "Iteration: 3102 lambda_k: 1 Loss: 0.04291395267561138\n",
      "Iteration: 3103 lambda_k: 1 Loss: 0.042880378888854015\n",
      "Iteration: 3104 lambda_k: 1 Loss: 0.04284681332741167\n",
      "Iteration: 3105 lambda_k: 1 Loss: 0.04281325600087239\n",
      "Iteration: 3106 lambda_k: 1 Loss: 0.04277970691835567\n",
      "Iteration: 3107 lambda_k: 1 Loss: 0.04274616608853688\n",
      "Iteration: 3108 lambda_k: 1 Loss: 0.04271263351966997\n",
      "Iteration: 3109 lambda_k: 1 Loss: 0.04267910921960944\n",
      "Iteration: 3110 lambda_k: 1 Loss: 0.0426455931958307\n",
      "Iteration: 3111 lambda_k: 1 Loss: 0.04261208545544988\n",
      "Iteration: 3112 lambda_k: 1 Loss: 0.04257858600524232\n",
      "Iteration: 3113 lambda_k: 1 Loss: 0.042545094851659984\n",
      "Iteration: 3114 lambda_k: 1 Loss: 0.04251161200084845\n",
      "Iteration: 3115 lambda_k: 1 Loss: 0.042478137458662656\n",
      "Iteration: 3116 lambda_k: 1 Loss: 0.04244467123068176\n",
      "Iteration: 3117 lambda_k: 1 Loss: 0.042411213322223626\n",
      "Iteration: 3118 lambda_k: 1 Loss: 0.04237776373835806\n",
      "Iteration: 3119 lambda_k: 1 Loss: 0.042344322483919984\n",
      "Iteration: 3120 lambda_k: 1 Loss: 0.04231088956352126\n",
      "Iteration: 3121 lambda_k: 1 Loss: 0.04227746498156235\n",
      "Iteration: 3122 lambda_k: 1 Loss: 0.04224404874224318\n",
      "Iteration: 3123 lambda_k: 1 Loss: 0.04221064084957351\n",
      "Iteration: 3124 lambda_k: 1 Loss: 0.04217724130738272\n",
      "Iteration: 3125 lambda_k: 1 Loss: 0.0421438501193293\n",
      "Iteration: 3126 lambda_k: 1 Loss: 0.04211046728890946\n",
      "Iteration: 3127 lambda_k: 1 Loss: 0.04207709281946544\n",
      "Iteration: 3128 lambda_k: 1 Loss: 0.04204372671419372\n",
      "Iteration: 3129 lambda_k: 1 Loss: 0.0420103689761522\n",
      "Iteration: 3130 lambda_k: 1 Loss: 0.04197701960826752\n",
      "Iteration: 3131 lambda_k: 1 Loss: 0.041943678613341674\n",
      "Iteration: 3132 lambda_k: 1 Loss: 0.04191034599405869\n",
      "Iteration: 3133 lambda_k: 1 Loss: 0.04187702175299023\n",
      "Iteration: 3134 lambda_k: 1 Loss: 0.041843705892601696\n",
      "Iteration: 3135 lambda_k: 1 Loss: 0.04181039841525742\n",
      "Iteration: 3136 lambda_k: 1 Loss: 0.041777099323226013\n",
      "Iteration: 3137 lambda_k: 1 Loss: 0.041743808618685145\n",
      "Iteration: 3138 lambda_k: 1 Loss: 0.04171052630372604\n",
      "Iteration: 3139 lambda_k: 1 Loss: 0.04167725238035813\n",
      "Iteration: 3140 lambda_k: 1 Loss: 0.041643986850512876\n",
      "Iteration: 3141 lambda_k: 1 Loss: 0.0416107297160479\n",
      "Iteration: 3142 lambda_k: 1 Loss: 0.04157748097875067\n",
      "Iteration: 3143 lambda_k: 1 Loss: 0.04154424064034201\n",
      "Iteration: 3144 lambda_k: 1 Loss: 0.04151100870247925\n",
      "Iteration: 3145 lambda_k: 1 Loss: 0.041477785166759706\n",
      "Iteration: 3146 lambda_k: 1 Loss: 0.041444570034723245\n",
      "Iteration: 3147 lambda_k: 1 Loss: 0.04141136330785559\n",
      "Iteration: 3148 lambda_k: 1 Loss: 0.04137816498759052\n",
      "Iteration: 3149 lambda_k: 1 Loss: 0.04134497507531263\n",
      "Iteration: 3150 lambda_k: 1 Loss: 0.04131179357235972\n",
      "Iteration: 3151 lambda_k: 1 Loss: 0.04127862048002505\n",
      "Iteration: 3152 lambda_k: 1 Loss: 0.041245455799559363\n",
      "Iteration: 3153 lambda_k: 1 Loss: 0.04121229953217299\n",
      "Iteration: 3154 lambda_k: 1 Loss: 0.041179151679037726\n",
      "Iteration: 3155 lambda_k: 1 Loss: 0.04114601224128873\n",
      "Iteration: 3156 lambda_k: 1 Loss: 0.04111288122002608\n",
      "Iteration: 3157 lambda_k: 1 Loss: 0.041079758616316416\n",
      "Iteration: 3158 lambda_k: 1 Loss: 0.04104664443119458\n",
      "Iteration: 3159 lambda_k: 1 Loss: 0.0410135386656648\n",
      "Iteration: 3160 lambda_k: 1 Loss: 0.04098044132070246\n",
      "Iteration: 3161 lambda_k: 1 Loss: 0.04094735239725492\n",
      "Iteration: 3162 lambda_k: 1 Loss: 0.04091427189624299\n",
      "Iteration: 3163 lambda_k: 1 Loss: 0.040881199818562045\n",
      "Iteration: 3164 lambda_k: 1 Loss: 0.040848136165083114\n",
      "Iteration: 3165 lambda_k: 1 Loss: 0.0408150809366537\n",
      "Iteration: 3166 lambda_k: 1 Loss: 0.04078203413409911\n",
      "Iteration: 3167 lambda_k: 1 Loss: 0.04074899575822293\n",
      "Iteration: 3168 lambda_k: 1 Loss: 0.0407159658098081\n",
      "Iteration: 3169 lambda_k: 1 Loss: 0.040682944289617905\n",
      "Iteration: 3170 lambda_k: 1 Loss: 0.040649931198396314\n",
      "Iteration: 3171 lambda_k: 1 Loss: 0.040616926536868964\n",
      "Iteration: 3172 lambda_k: 1 Loss: 0.04058393030574376\n",
      "Iteration: 3173 lambda_k: 1 Loss: 0.0405509425057116\n",
      "Iteration: 3174 lambda_k: 1 Loss: 0.040517963137446766\n",
      "Iteration: 3175 lambda_k: 1 Loss: 0.040484992201607624\n",
      "Iteration: 3176 lambda_k: 1 Loss: 0.04045202969883719\n",
      "Iteration: 3177 lambda_k: 1 Loss: 0.04041907562976353\n",
      "Iteration: 3178 lambda_k: 1 Loss: 0.0403861299950002\n",
      "Iteration: 3179 lambda_k: 1 Loss: 0.04035319279514679\n",
      "Iteration: 3180 lambda_k: 1 Loss: 0.04032026403078919\n",
      "Iteration: 3181 lambda_k: 1 Loss: 0.04028734370250023\n",
      "Iteration: 3182 lambda_k: 1 Loss: 0.04025443181083969\n",
      "Iteration: 3183 lambda_k: 1 Loss: 0.040221528356354834\n",
      "Iteration: 3184 lambda_k: 1 Loss: 0.04018863333958082\n",
      "Iteration: 3185 lambda_k: 1 Loss: 0.040155746761040785\n",
      "Iteration: 3186 lambda_k: 1 Loss: 0.04012286862124618\n",
      "Iteration: 3187 lambda_k: 1 Loss: 0.04008999892069723\n",
      "Iteration: 3188 lambda_k: 1 Loss: 0.04005713765988287\n",
      "Iteration: 3189 lambda_k: 1 Loss: 0.04002428483928119\n",
      "Iteration: 3190 lambda_k: 1 Loss: 0.03999144045935946\n",
      "Iteration: 3191 lambda_k: 1 Loss: 0.03995860452057458\n",
      "Iteration: 3192 lambda_k: 1 Loss: 0.03992577702337299\n",
      "Iteration: 3193 lambda_k: 1 Loss: 0.03989295796819101\n",
      "Iteration: 3194 lambda_k: 1 Loss: 0.039860147355455025\n",
      "Iteration: 3195 lambda_k: 1 Loss: 0.039827345185581536\n",
      "Iteration: 3196 lambda_k: 1 Loss: 0.039794551458977236\n",
      "Iteration: 3197 lambda_k: 1 Loss: 0.03976176617603935\n",
      "Iteration: 3198 lambda_k: 1 Loss: 0.03972898933715553\n",
      "Iteration: 3199 lambda_k: 1 Loss: 0.03969622094270415\n",
      "Iteration: 3200 lambda_k: 1 Loss: 0.03966346099305426\n",
      "Iteration: 3201 lambda_k: 1 Loss: 0.0396307094885658\n",
      "Iteration: 3202 lambda_k: 1 Loss: 0.039597966429589515\n",
      "Iteration: 3203 lambda_k: 1 Loss: 0.03956523181646723\n",
      "Iteration: 3204 lambda_k: 1 Loss: 0.03953250564953181\n",
      "Iteration: 3205 lambda_k: 1 Loss: 0.039499787929107286\n",
      "Iteration: 3206 lambda_k: 1 Loss: 0.039467078655508775\n",
      "Iteration: 3207 lambda_k: 1 Loss: 0.0394343778290428\n",
      "Iteration: 3208 lambda_k: 1 Loss: 0.039401685450007023\n",
      "Iteration: 3209 lambda_k: 1 Loss: 0.0393690015186906\n",
      "Iteration: 3210 lambda_k: 1 Loss: 0.03933632603537398\n",
      "Iteration: 3211 lambda_k: 1 Loss: 0.03930365900032902\n",
      "Iteration: 3212 lambda_k: 1 Loss: 0.039271000413819084\n",
      "Iteration: 3213 lambda_k: 1 Loss: 0.03923835027609897\n",
      "Iteration: 3214 lambda_k: 1 Loss: 0.03920570858741499\n",
      "Iteration: 3215 lambda_k: 1 Loss: 0.039173075348005085\n",
      "Iteration: 3216 lambda_k: 1 Loss: 0.039140450558098665\n",
      "Iteration: 3217 lambda_k: 1 Loss: 0.03910783421791674\n",
      "Iteration: 3218 lambda_k: 1 Loss: 0.039075226327671866\n",
      "Iteration: 3219 lambda_k: 1 Loss: 0.039042626887568314\n",
      "Iteration: 3220 lambda_k: 1 Loss: 0.03901003589780187\n",
      "Iteration: 3221 lambda_k: 1 Loss: 0.038977453358559934\n",
      "Iteration: 3222 lambda_k: 1 Loss: 0.03894487927002168\n",
      "Iteration: 3223 lambda_k: 1 Loss: 0.03891231363235779\n",
      "Iteration: 3224 lambda_k: 1 Loss: 0.038879756445730516\n",
      "Iteration: 3225 lambda_k: 1 Loss: 0.038847207710294006\n",
      "Iteration: 3226 lambda_k: 1 Loss: 0.03881466742619389\n",
      "Iteration: 3227 lambda_k: 1 Loss: 0.038782135593567475\n",
      "Iteration: 3228 lambda_k: 1 Loss: 0.03874961221254376\n",
      "Iteration: 3229 lambda_k: 1 Loss: 0.03871709728324333\n",
      "Iteration: 3230 lambda_k: 1 Loss: 0.03868459080577845\n",
      "Iteration: 3231 lambda_k: 1 Loss: 0.03865209278025303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3232 lambda_k: 1 Loss: 0.03861960320676263\n",
      "Iteration: 3233 lambda_k: 1 Loss: 0.038587122085394485\n",
      "Iteration: 3234 lambda_k: 1 Loss: 0.03855464941622745\n",
      "Iteration: 3235 lambda_k: 1 Loss: 0.03852218519933201\n",
      "Iteration: 3236 lambda_k: 1 Loss: 0.03848972943477023\n",
      "Iteration: 3237 lambda_k: 1 Loss: 0.03845728212259583\n",
      "Iteration: 3238 lambda_k: 1 Loss: 0.038424843262854266\n",
      "Iteration: 3239 lambda_k: 1 Loss: 0.03839241285558238\n",
      "Iteration: 3240 lambda_k: 1 Loss: 0.03835999090080882\n",
      "Iteration: 3241 lambda_k: 1 Loss: 0.03832757739855372\n",
      "Iteration: 3242 lambda_k: 1 Loss: 0.03829517234882884\n",
      "Iteration: 3243 lambda_k: 1 Loss: 0.03826277575163764\n",
      "Iteration: 3244 lambda_k: 1 Loss: 0.03823038760697505\n",
      "Iteration: 3245 lambda_k: 1 Loss: 0.038198007914827525\n",
      "Iteration: 3246 lambda_k: 1 Loss: 0.038165636675173226\n",
      "Iteration: 3247 lambda_k: 1 Loss: 0.0381332738879819\n",
      "Iteration: 3248 lambda_k: 1 Loss: 0.038100919553214735\n",
      "Iteration: 3249 lambda_k: 1 Loss: 0.0380685736708246\n",
      "Iteration: 3250 lambda_k: 1 Loss: 0.03803623624075585\n",
      "Iteration: 3251 lambda_k: 1 Loss: 0.03800390726294449\n",
      "Iteration: 3252 lambda_k: 1 Loss: 0.03797158673731791\n",
      "Iteration: 3253 lambda_k: 1 Loss: 0.03793927466379527\n",
      "Iteration: 3254 lambda_k: 1 Loss: 0.03790697104228704\n",
      "Iteration: 3255 lambda_k: 1 Loss: 0.03787467587269542\n",
      "Iteration: 3256 lambda_k: 1 Loss: 0.03784238915491405\n",
      "Iteration: 3257 lambda_k: 1 Loss: 0.03781011088882809\n",
      "Iteration: 3258 lambda_k: 1 Loss: 0.03777784107431435\n",
      "Iteration: 3259 lambda_k: 1 Loss: 0.03774557971124109\n",
      "Iteration: 3260 lambda_k: 1 Loss: 0.037713326799468164\n",
      "Iteration: 3261 lambda_k: 1 Loss: 0.037681082338846865\n",
      "Iteration: 3262 lambda_k: 1 Loss: 0.0376488463292201\n",
      "Iteration: 3263 lambda_k: 1 Loss: 0.03761661877042225\n",
      "Iteration: 3264 lambda_k: 1 Loss: 0.03758439966227935\n",
      "Iteration: 3265 lambda_k: 1 Loss: 0.037552189004608875\n",
      "Iteration: 3266 lambda_k: 1 Loss: 0.03751998679721979\n",
      "Iteration: 3267 lambda_k: 1 Loss: 0.03748779303991268\n",
      "Iteration: 3268 lambda_k: 1 Loss: 0.037455607732479745\n",
      "Iteration: 3269 lambda_k: 1 Loss: 0.03742343087470457\n",
      "Iteration: 3270 lambda_k: 1 Loss: 0.03739126246636244\n",
      "Iteration: 3271 lambda_k: 1 Loss: 0.03735910250722006\n",
      "Iteration: 3272 lambda_k: 1 Loss: 0.037326950997035785\n",
      "Iteration: 3273 lambda_k: 1 Loss: 0.037294807935559546\n",
      "Iteration: 3274 lambda_k: 1 Loss: 0.03726267332253281\n",
      "Iteration: 3275 lambda_k: 1 Loss: 0.037230547157688594\n",
      "Iteration: 3276 lambda_k: 1 Loss: 0.03719842944075147\n",
      "Iteration: 3277 lambda_k: 1 Loss: 0.03716632017143774\n",
      "Iteration: 3278 lambda_k: 1 Loss: 0.03713421934945518\n",
      "Iteration: 3279 lambda_k: 1 Loss: 0.037102126974503165\n",
      "Iteration: 3280 lambda_k: 1 Loss: 0.037070043046272844\n",
      "Iteration: 3281 lambda_k: 1 Loss: 0.03703796756444676\n",
      "Iteration: 3282 lambda_k: 1 Loss: 0.03700590052869922\n",
      "Iteration: 3283 lambda_k: 1 Loss: 0.03697384193869613\n",
      "Iteration: 3284 lambda_k: 1 Loss: 0.036941791794095055\n",
      "Iteration: 3285 lambda_k: 1 Loss: 0.03690975009454523\n",
      "Iteration: 3286 lambda_k: 1 Loss: 0.03687771683968756\n",
      "Iteration: 3287 lambda_k: 1 Loss: 0.03684569202915456\n",
      "Iteration: 3288 lambda_k: 1 Loss: 0.036813675662570565\n",
      "Iteration: 3289 lambda_k: 1 Loss: 0.0367816677395515\n",
      "Iteration: 3290 lambda_k: 1 Loss: 0.03674966825970508\n",
      "Iteration: 3291 lambda_k: 1 Loss: 0.03671767722263082\n",
      "Iteration: 3292 lambda_k: 1 Loss: 0.0366856946279198\n",
      "Iteration: 3293 lambda_k: 1 Loss: 0.03665372047515492\n",
      "Iteration: 3294 lambda_k: 1 Loss: 0.03662175476391091\n",
      "Iteration: 3295 lambda_k: 1 Loss: 0.0365897974937542\n",
      "Iteration: 3296 lambda_k: 1 Loss: 0.036557848664243144\n",
      "Iteration: 3297 lambda_k: 1 Loss: 0.03652590827492776\n",
      "Iteration: 3298 lambda_k: 1 Loss: 0.03649397632534999\n",
      "Iteration: 3299 lambda_k: 1 Loss: 0.0364620528150436\n",
      "Iteration: 3300 lambda_k: 1 Loss: 0.03643013774353428\n",
      "Iteration: 3301 lambda_k: 1 Loss: 0.03639823111033941\n",
      "Iteration: 3302 lambda_k: 1 Loss: 0.036366332914968526\n",
      "Iteration: 3303 lambda_k: 1 Loss: 0.03633444315692288\n",
      "Iteration: 3304 lambda_k: 1 Loss: 0.036302561835695725\n",
      "Iteration: 3305 lambda_k: 1 Loss: 0.03627068895077227\n",
      "Iteration: 3306 lambda_k: 1 Loss: 0.03623882450162966\n",
      "Iteration: 3307 lambda_k: 1 Loss: 0.03620696848773705\n",
      "Iteration: 3308 lambda_k: 1 Loss: 0.0361751209085556\n",
      "Iteration: 3309 lambda_k: 1 Loss: 0.03614328176353842\n",
      "Iteration: 3310 lambda_k: 1 Loss: 0.03611145105213085\n",
      "Iteration: 3311 lambda_k: 1 Loss: 0.036079628773770064\n",
      "Iteration: 3312 lambda_k: 1 Loss: 0.03604781492788541\n",
      "Iteration: 3313 lambda_k: 1 Loss: 0.03601600951389843\n",
      "Iteration: 3314 lambda_k: 1 Loss: 0.03598421253122266\n",
      "Iteration: 3315 lambda_k: 1 Loss: 0.03595242397926379\n",
      "Iteration: 3316 lambda_k: 1 Loss: 0.03592064385741975\n",
      "Iteration: 3317 lambda_k: 1 Loss: 0.03588887216508056\n",
      "Iteration: 3318 lambda_k: 1 Loss: 0.035857108901628555\n",
      "Iteration: 3319 lambda_k: 1 Loss: 0.03582535406643824\n",
      "Iteration: 3320 lambda_k: 1 Loss: 0.03579360765887637\n",
      "Iteration: 3321 lambda_k: 1 Loss: 0.035761869678301965\n",
      "Iteration: 3322 lambda_k: 1 Loss: 0.035730140124066403\n",
      "Iteration: 3323 lambda_k: 1 Loss: 0.0356984189955133\n",
      "Iteration: 3324 lambda_k: 1 Loss: 0.03566670629197864\n",
      "Iteration: 3325 lambda_k: 1 Loss: 0.03563500201279074\n",
      "Iteration: 3326 lambda_k: 1 Loss: 0.035603306157270385\n",
      "Iteration: 3327 lambda_k: 1 Loss: 0.03557161872473069\n",
      "Iteration: 3328 lambda_k: 1 Loss: 0.03553993971447731\n",
      "Iteration: 3329 lambda_k: 1 Loss: 0.035508269125808185\n",
      "Iteration: 3330 lambda_k: 1 Loss: 0.035476606958014\n",
      "Iteration: 3331 lambda_k: 1 Loss: 0.03544495321037766\n",
      "Iteration: 3332 lambda_k: 1 Loss: 0.03541330788217475\n",
      "Iteration: 3333 lambda_k: 1 Loss: 0.03538167097267348\n",
      "Iteration: 3334 lambda_k: 1 Loss: 0.0353500424811345\n",
      "Iteration: 3335 lambda_k: 1 Loss: 0.035318422406811184\n",
      "Iteration: 3336 lambda_k: 1 Loss: 0.035286810748949446\n",
      "Iteration: 3337 lambda_k: 1 Loss: 0.03525520750678783\n",
      "Iteration: 3338 lambda_k: 1 Loss: 0.0352236126795577\n",
      "Iteration: 3339 lambda_k: 1 Loss: 0.035192026266483094\n",
      "Iteration: 3340 lambda_k: 1 Loss: 0.035160448266780636\n",
      "Iteration: 3341 lambda_k: 1 Loss: 0.035128878679659886\n",
      "Iteration: 3342 lambda_k: 1 Loss: 0.03509731750432312\n",
      "Iteration: 3343 lambda_k: 1 Loss: 0.03506576473996547\n",
      "Iteration: 3344 lambda_k: 1 Loss: 0.03503422038577481\n",
      "Iteration: 3345 lambda_k: 1 Loss: 0.035002684440932005\n",
      "Iteration: 3346 lambda_k: 1 Loss: 0.034971156904610695\n",
      "Iteration: 3347 lambda_k: 1 Loss: 0.03493963777597746\n",
      "Iteration: 3348 lambda_k: 1 Loss: 0.03490812705419191\n",
      "Iteration: 3349 lambda_k: 1 Loss: 0.0348766247384066\n",
      "Iteration: 3350 lambda_k: 1 Loss: 0.034845130827767\n",
      "Iteration: 3351 lambda_k: 1 Loss: 0.03481364532141172\n",
      "Iteration: 3352 lambda_k: 1 Loss: 0.034782168218472305\n",
      "Iteration: 3353 lambda_k: 1 Loss: 0.03475069951807351\n",
      "Iteration: 3354 lambda_k: 1 Loss: 0.03471923921933316\n",
      "Iteration: 3355 lambda_k: 1 Loss: 0.0346877873213622\n",
      "Iteration: 3356 lambda_k: 1 Loss: 0.03465634382326464\n",
      "Iteration: 3357 lambda_k: 1 Loss: 0.03462490872413787\n",
      "Iteration: 3358 lambda_k: 1 Loss: 0.03459348202307235\n",
      "Iteration: 3359 lambda_k: 1 Loss: 0.03456206371915185\n",
      "Iteration: 3360 lambda_k: 1 Loss: 0.0345306538114534\n",
      "Iteration: 3361 lambda_k: 1 Loss: 0.034499252299047406\n",
      "Iteration: 3362 lambda_k: 1 Loss: 0.03446785918099748\n",
      "Iteration: 3363 lambda_k: 1 Loss: 0.03443647445636069\n",
      "Iteration: 3364 lambda_k: 1 Loss: 0.03440509812418744\n",
      "Iteration: 3365 lambda_k: 1 Loss: 0.034373730183521564\n",
      "Iteration: 3366 lambda_k: 1 Loss: 0.03434237063340037\n",
      "Iteration: 3367 lambda_k: 1 Loss: 0.03431101947285454\n",
      "Iteration: 3368 lambda_k: 1 Loss: 0.03427967670090836\n",
      "Iteration: 3369 lambda_k: 1 Loss: 0.034248342316579715\n",
      "Iteration: 3370 lambda_k: 1 Loss: 0.03421701631887981\n",
      "Iteration: 3371 lambda_k: 1 Loss: 0.034185698706813594\n",
      "Iteration: 3372 lambda_k: 1 Loss: 0.03415438947937967\n",
      "Iteration: 3373 lambda_k: 1 Loss: 0.03412308863557019\n",
      "Iteration: 3374 lambda_k: 1 Loss: 0.03409179617437099\n",
      "Iteration: 3375 lambda_k: 1 Loss: 0.034060512094761616\n",
      "Iteration: 3376 lambda_k: 1 Loss: 0.03402923639571534\n",
      "Iteration: 3377 lambda_k: 1 Loss: 0.033997969076199265\n",
      "Iteration: 3378 lambda_k: 1 Loss: 0.03396671013517417\n",
      "Iteration: 3379 lambda_k: 1 Loss: 0.033935459571594696\n",
      "Iteration: 3380 lambda_k: 1 Loss: 0.03390421738440929\n",
      "Iteration: 3381 lambda_k: 1 Loss: 0.03387298357256033\n",
      "Iteration: 3382 lambda_k: 1 Loss: 0.03384175813498406\n",
      "Iteration: 3383 lambda_k: 1 Loss: 0.03381054107061068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3384 lambda_k: 1 Loss: 0.03377933237836427\n",
      "Iteration: 3385 lambda_k: 1 Loss: 0.033748132057163024\n",
      "Iteration: 3386 lambda_k: 1 Loss: 0.033716940105919024\n",
      "Iteration: 3387 lambda_k: 1 Loss: 0.03368575652353847\n",
      "Iteration: 3388 lambda_k: 1 Loss: 0.03365458130892162\n",
      "Iteration: 3389 lambda_k: 1 Loss: 0.03362341446096285\n",
      "Iteration: 3390 lambda_k: 1 Loss: 0.03359225597855061\n",
      "Iteration: 3391 lambda_k: 1 Loss: 0.03356110586056754\n",
      "Iteration: 3392 lambda_k: 1 Loss: 0.0335299641058904\n",
      "Iteration: 3393 lambda_k: 1 Loss: 0.033498830713390285\n",
      "Iteration: 3394 lambda_k: 1 Loss: 0.03346770568193252\n",
      "Iteration: 3395 lambda_k: 1 Loss: 0.033436589010376654\n",
      "Iteration: 3396 lambda_k: 1 Loss: 0.03340548069757647\n",
      "Iteration: 3397 lambda_k: 1 Loss: 0.0333743807423802\n",
      "Iteration: 3398 lambda_k: 1 Loss: 0.03334328914363034\n",
      "Iteration: 3399 lambda_k: 1 Loss: 0.03331220590016387\n",
      "Iteration: 3400 lambda_k: 1 Loss: 0.0332811310108121\n",
      "Iteration: 3401 lambda_k: 1 Loss: 0.03325006447440083\n",
      "Iteration: 3402 lambda_k: 1 Loss: 0.033219006289750275\n",
      "Iteration: 3403 lambda_k: 1 Loss: 0.03318795645567518\n",
      "Iteration: 3404 lambda_k: 1 Loss: 0.03315691497098488\n",
      "Iteration: 3405 lambda_k: 1 Loss: 0.033125881834483194\n",
      "Iteration: 3406 lambda_k: 1 Loss: 0.033094857044968465\n",
      "Iteration: 3407 lambda_k: 1 Loss: 0.03306384060123378\n",
      "Iteration: 3408 lambda_k: 1 Loss: 0.03303283250206686\n",
      "Iteration: 3409 lambda_k: 1 Loss: 0.03300183274624993\n",
      "Iteration: 3410 lambda_k: 1 Loss: 0.032970841332560154\n",
      "Iteration: 3411 lambda_k: 1 Loss: 0.032939858259769215\n",
      "Iteration: 3412 lambda_k: 1 Loss: 0.03290888352664363\n",
      "Iteration: 3413 lambda_k: 1 Loss: 0.0328779171319447\n",
      "Iteration: 3414 lambda_k: 1 Loss: 0.03284695907442855\n",
      "Iteration: 3415 lambda_k: 1 Loss: 0.03281600935284605\n",
      "Iteration: 3416 lambda_k: 1 Loss: 0.03278506796594301\n",
      "Iteration: 3417 lambda_k: 1 Loss: 0.03275413491246014\n",
      "Iteration: 3418 lambda_k: 1 Loss: 0.032723210191133056\n",
      "Iteration: 3419 lambda_k: 1 Loss: 0.03269229380069236\n",
      "Iteration: 3420 lambda_k: 1 Loss: 0.0326613857398635\n",
      "Iteration: 3421 lambda_k: 1 Loss: 0.03263048600736704\n",
      "Iteration: 3422 lambda_k: 1 Loss: 0.03259959460191848\n",
      "Iteration: 3423 lambda_k: 1 Loss: 0.03256871152222849\n",
      "Iteration: 3424 lambda_k: 1 Loss: 0.032537836767002816\n",
      "Iteration: 3425 lambda_k: 1 Loss: 0.03250697033494223\n",
      "Iteration: 3426 lambda_k: 1 Loss: 0.03247611222474262\n",
      "Iteration: 3427 lambda_k: 1 Loss: 0.03244526243509512\n",
      "Iteration: 3428 lambda_k: 1 Loss: 0.032414420964686136\n",
      "Iteration: 3429 lambda_k: 1 Loss: 0.03238358781219704\n",
      "Iteration: 3430 lambda_k: 1 Loss: 0.03235276297630469\n",
      "Iteration: 3431 lambda_k: 1 Loss: 0.03232194645568117\n",
      "Iteration: 3432 lambda_k: 1 Loss: 0.03229113824899375\n",
      "Iteration: 3433 lambda_k: 1 Loss: 0.03226033835490515\n",
      "Iteration: 3434 lambda_k: 1 Loss: 0.03222954677207336\n",
      "Iteration: 3435 lambda_k: 1 Loss: 0.03219876349915178\n",
      "Iteration: 3436 lambda_k: 1 Loss: 0.032167988534789256\n",
      "Iteration: 3437 lambda_k: 1 Loss: 0.03213722187762994\n",
      "Iteration: 3438 lambda_k: 1 Loss: 0.03210646352631365\n",
      "Iteration: 3439 lambda_k: 1 Loss: 0.03207571347947547\n",
      "Iteration: 3440 lambda_k: 1 Loss: 0.03204497173574617\n",
      "Iteration: 3441 lambda_k: 1 Loss: 0.03201423829375197\n",
      "Iteration: 3442 lambda_k: 1 Loss: 0.03198351315211465\n",
      "Iteration: 3443 lambda_k: 1 Loss: 0.03195279630945163\n",
      "Iteration: 3444 lambda_k: 1 Loss: 0.03192208776437586\n",
      "Iteration: 3445 lambda_k: 1 Loss: 0.03189138751549605\n",
      "Iteration: 3446 lambda_k: 1 Loss: 0.03186069556141649\n",
      "Iteration: 3447 lambda_k: 1 Loss: 0.031830011900737226\n",
      "Iteration: 3448 lambda_k: 1 Loss: 0.031799336532054\n",
      "Iteration: 3449 lambda_k: 1 Loss: 0.031768669453958204\n",
      "Iteration: 3450 lambda_k: 1 Loss: 0.031738010665037134\n",
      "Iteration: 3451 lambda_k: 1 Loss: 0.03170736016387384\n",
      "Iteration: 3452 lambda_k: 1 Loss: 0.031676717949047146\n",
      "Iteration: 3453 lambda_k: 1 Loss: 0.03164608401913182\n",
      "Iteration: 3454 lambda_k: 1 Loss: 0.03161545837269837\n",
      "Iteration: 3455 lambda_k: 1 Loss: 0.03158484100831328\n",
      "Iteration: 3456 lambda_k: 1 Loss: 0.03155423192453904\n",
      "Iteration: 3457 lambda_k: 1 Loss: 0.03152363111993386\n",
      "Iteration: 3458 lambda_k: 1 Loss: 0.03149303859305215\n",
      "Iteration: 3459 lambda_k: 1 Loss: 0.03146245434244416\n",
      "Iteration: 3460 lambda_k: 1 Loss: 0.03143187836665624\n",
      "Iteration: 3461 lambda_k: 1 Loss: 0.031401310664230825\n",
      "Iteration: 3462 lambda_k: 1 Loss: 0.03137075123370623\n",
      "Iteration: 3463 lambda_k: 1 Loss: 0.03134020007361714\n",
      "Iteration: 3464 lambda_k: 1 Loss: 0.03130965718249408\n",
      "Iteration: 3465 lambda_k: 1 Loss: 0.031279122558863906\n",
      "Iteration: 3466 lambda_k: 1 Loss: 0.031248596201249666\n",
      "Iteration: 3467 lambda_k: 1 Loss: 0.031218078108170455\n",
      "Iteration: 3468 lambda_k: 1 Loss: 0.03118756827814167\n",
      "Iteration: 3469 lambda_k: 1 Loss: 0.03115706670967489\n",
      "Iteration: 3470 lambda_k: 1 Loss: 0.031126573401278036\n",
      "Iteration: 3471 lambda_k: 1 Loss: 0.03109608835145523\n",
      "Iteration: 3472 lambda_k: 1 Loss: 0.031065611558706963\n",
      "Iteration: 3473 lambda_k: 1 Loss: 0.031035143021530067\n",
      "Iteration: 3474 lambda_k: 1 Loss: 0.031004682738417718\n",
      "Iteration: 3475 lambda_k: 1 Loss: 0.03097423070785939\n",
      "Iteration: 3476 lambda_k: 1 Loss: 0.030943786928341124\n",
      "Iteration: 3477 lambda_k: 1 Loss: 0.030913351398345265\n",
      "Iteration: 3478 lambda_k: 1 Loss: 0.030882924116350664\n",
      "Iteration: 3479 lambda_k: 1 Loss: 0.030852505080832596\n",
      "Iteration: 3480 lambda_k: 1 Loss: 0.030822094290262805\n",
      "Iteration: 3481 lambda_k: 1 Loss: 0.03079169174310971\n",
      "Iteration: 3482 lambda_k: 1 Loss: 0.03076129743783816\n",
      "Iteration: 3483 lambda_k: 1 Loss: 0.030730911372909595\n",
      "Iteration: 3484 lambda_k: 1 Loss: 0.03070053354678209\n",
      "Iteration: 3485 lambda_k: 1 Loss: 0.030670163957910175\n",
      "Iteration: 3486 lambda_k: 1 Loss: 0.03063980260474517\n",
      "Iteration: 3487 lambda_k: 1 Loss: 0.030609449485734984\n",
      "Iteration: 3488 lambda_k: 1 Loss: 0.030579104599324163\n",
      "Iteration: 3489 lambda_k: 1 Loss: 0.030548767943954055\n",
      "Iteration: 3490 lambda_k: 1 Loss: 0.030518439518062622\n",
      "Iteration: 3491 lambda_k: 1 Loss: 0.030488119320084748\n",
      "Iteration: 3492 lambda_k: 1 Loss: 0.0304578073484519\n",
      "Iteration: 3493 lambda_k: 1 Loss: 0.030427503601592427\n",
      "Iteration: 3494 lambda_k: 1 Loss: 0.030397208077931396\n",
      "Iteration: 3495 lambda_k: 1 Loss: 0.030366920775890795\n",
      "Iteration: 3496 lambda_k: 1 Loss: 0.030336641693889475\n",
      "Iteration: 3497 lambda_k: 1 Loss: 0.030306370830343096\n",
      "Iteration: 3498 lambda_k: 1 Loss: 0.030276108183664243\n",
      "Iteration: 3499 lambda_k: 1 Loss: 0.030245853752262426\n",
      "Iteration: 3500 lambda_k: 1 Loss: 0.030215607534544067\n",
      "Iteration: 3501 lambda_k: 1 Loss: 0.03018536952891258\n",
      "Iteration: 3502 lambda_k: 1 Loss: 0.030155139733768356\n",
      "Iteration: 3503 lambda_k: 1 Loss: 0.030124918147508752\n",
      "Iteration: 3504 lambda_k: 1 Loss: 0.030094704768528272\n",
      "Iteration: 3505 lambda_k: 1 Loss: 0.03006449959521829\n",
      "Iteration: 3506 lambda_k: 1 Loss: 0.03003430262596731\n",
      "Iteration: 3507 lambda_k: 1 Loss: 0.030004113859160957\n",
      "Iteration: 3508 lambda_k: 1 Loss: 0.029973933293181963\n",
      "Iteration: 3509 lambda_k: 1 Loss: 0.02994376092641019\n",
      "Iteration: 3510 lambda_k: 1 Loss: 0.029913596757222567\n",
      "Iteration: 3511 lambda_k: 1 Loss: 0.02988344078399328\n",
      "Iteration: 3512 lambda_k: 1 Loss: 0.02985329300509367\n",
      "Iteration: 3513 lambda_k: 1 Loss: 0.02982315341889218\n",
      "Iteration: 3514 lambda_k: 1 Loss: 0.029793022023754705\n",
      "Iteration: 3515 lambda_k: 1 Loss: 0.029762898818044208\n",
      "Iteration: 3516 lambda_k: 1 Loss: 0.02973278380012099\n",
      "Iteration: 3517 lambda_k: 1 Loss: 0.0297026769683427\n",
      "Iteration: 3518 lambda_k: 1 Loss: 0.02967257832106416\n",
      "Iteration: 3519 lambda_k: 1 Loss: 0.0296424878566375\n",
      "Iteration: 3520 lambda_k: 1 Loss: 0.029612405573412444\n",
      "Iteration: 3521 lambda_k: 1 Loss: 0.029582331469735816\n",
      "Iteration: 3522 lambda_k: 1 Loss: 0.029552265543951885\n",
      "Iteration: 3523 lambda_k: 1 Loss: 0.029522207794402466\n",
      "Iteration: 3524 lambda_k: 1 Loss: 0.02949215821942661\n",
      "Iteration: 3525 lambda_k: 1 Loss: 0.02946211681736092\n",
      "Iteration: 3526 lambda_k: 1 Loss: 0.029432083586539502\n",
      "Iteration: 3527 lambda_k: 1 Loss: 0.029402058525293765\n",
      "Iteration: 3528 lambda_k: 1 Loss: 0.029372041631952856\n",
      "Iteration: 3529 lambda_k: 1 Loss: 0.029342032904843166\n",
      "Iteration: 3530 lambda_k: 1 Loss: 0.029312032342288925\n",
      "Iteration: 3531 lambda_k: 1 Loss: 0.02928203994261168\n",
      "Iteration: 3532 lambda_k: 1 Loss: 0.02925205570413063\n",
      "Iteration: 3533 lambda_k: 1 Loss: 0.029222079625162652\n",
      "Iteration: 3534 lambda_k: 1 Loss: 0.029192111704022063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3535 lambda_k: 1 Loss: 0.029162151939020994\n",
      "Iteration: 3536 lambda_k: 1 Loss: 0.029132200328469048\n",
      "Iteration: 3537 lambda_k: 1 Loss: 0.02910225687067366\n",
      "Iteration: 3538 lambda_k: 1 Loss: 0.029072321563939817\n",
      "Iteration: 3539 lambda_k: 1 Loss: 0.02904239440657029\n",
      "Iteration: 3540 lambda_k: 1 Loss: 0.029012475396865547\n",
      "Iteration: 3541 lambda_k: 1 Loss: 0.028982564533123766\n",
      "Iteration: 3542 lambda_k: 1 Loss: 0.02895266181364094\n",
      "Iteration: 3543 lambda_k: 1 Loss: 0.028922767236710813\n",
      "Iteration: 3544 lambda_k: 1 Loss: 0.028892880800624843\n",
      "Iteration: 3545 lambda_k: 1 Loss: 0.028863002503672366\n",
      "Iteration: 3546 lambda_k: 1 Loss: 0.028833132344140585\n",
      "Iteration: 3547 lambda_k: 1 Loss: 0.028803270320314482\n",
      "Iteration: 3548 lambda_k: 1 Loss: 0.028773416430476872\n",
      "Iteration: 3549 lambda_k: 1 Loss: 0.028743570672908517\n",
      "Iteration: 3550 lambda_k: 1 Loss: 0.028713733045888073\n",
      "Iteration: 3551 lambda_k: 1 Loss: 0.028683903547692083\n",
      "Iteration: 3552 lambda_k: 1 Loss: 0.028654082176595007\n",
      "Iteration: 3553 lambda_k: 1 Loss: 0.02862426893086922\n",
      "Iteration: 3554 lambda_k: 1 Loss: 0.02859446380878511\n",
      "Iteration: 3555 lambda_k: 1 Loss: 0.028564666808611115\n",
      "Iteration: 3556 lambda_k: 1 Loss: 0.028534877928613516\n",
      "Iteration: 3557 lambda_k: 1 Loss: 0.028505097167056705\n",
      "Iteration: 3558 lambda_k: 1 Loss: 0.028475324522203124\n",
      "Iteration: 3559 lambda_k: 1 Loss: 0.02844555999231315\n",
      "Iteration: 3560 lambda_k: 1 Loss: 0.02841580357564528\n",
      "Iteration: 3561 lambda_k: 1 Loss: 0.028386055270456127\n",
      "Iteration: 3562 lambda_k: 1 Loss: 0.028356315075000325\n",
      "Iteration: 3563 lambda_k: 1 Loss: 0.028326582987530723\n",
      "Iteration: 3564 lambda_k: 1 Loss: 0.028296859006298233\n",
      "Iteration: 3565 lambda_k: 1 Loss: 0.028267143129551885\n",
      "Iteration: 3566 lambda_k: 1 Loss: 0.028237435355538888\n",
      "Iteration: 3567 lambda_k: 1 Loss: 0.028207735682504623\n",
      "Iteration: 3568 lambda_k: 1 Loss: 0.02817804410869269\n",
      "Iteration: 3569 lambda_k: 1 Loss: 0.02814836063234483\n",
      "Iteration: 3570 lambda_k: 1 Loss: 0.028118685251701123\n",
      "Iteration: 3571 lambda_k: 1 Loss: 0.028089017964999703\n",
      "Iteration: 3572 lambda_k: 1 Loss: 0.028059358770477143\n",
      "Iteration: 3573 lambda_k: 1 Loss: 0.028029707666368184\n",
      "Iteration: 3574 lambda_k: 1 Loss: 0.02800006465090588\n",
      "Iteration: 3575 lambda_k: 1 Loss: 0.027970429722321572\n",
      "Iteration: 3576 lambda_k: 1 Loss: 0.027940802878844834\n",
      "Iteration: 3577 lambda_k: 1 Loss: 0.027911184118703754\n",
      "Iteration: 3578 lambda_k: 1 Loss: 0.027881573440124638\n",
      "Iteration: 3579 lambda_k: 1 Loss: 0.027851970841332153\n",
      "Iteration: 3580 lambda_k: 1 Loss: 0.02782237632054937\n",
      "Iteration: 3581 lambda_k: 1 Loss: 0.027792789875997714\n",
      "Iteration: 3582 lambda_k: 1 Loss: 0.02776321150589709\n",
      "Iteration: 3583 lambda_k: 1 Loss: 0.02773364120846567\n",
      "Iteration: 3584 lambda_k: 1 Loss: 0.027704078981920288\n",
      "Iteration: 3585 lambda_k: 1 Loss: 0.027674524824476018\n",
      "Iteration: 3586 lambda_k: 1 Loss: 0.027644978734346456\n",
      "Iteration: 3587 lambda_k: 1 Loss: 0.027615440709743692\n",
      "Iteration: 3588 lambda_k: 1 Loss: 0.027585910748878315\n",
      "Iteration: 3589 lambda_k: 1 Loss: 0.027556388849959357\n",
      "Iteration: 3590 lambda_k: 1 Loss: 0.02752687501119451\n",
      "Iteration: 3591 lambda_k: 1 Loss: 0.027497369230789822\n",
      "Iteration: 3592 lambda_k: 1 Loss: 0.027467871506949966\n",
      "Iteration: 3593 lambda_k: 1 Loss: 0.02743838183787818\n",
      "Iteration: 3594 lambda_k: 1 Loss: 0.02740890022177638\n",
      "Iteration: 3595 lambda_k: 1 Loss: 0.027379426656844882\n",
      "Iteration: 3596 lambda_k: 1 Loss: 0.027349961141282735\n",
      "Iteration: 3597 lambda_k: 1 Loss: 0.027320503673287515\n",
      "Iteration: 3598 lambda_k: 1 Loss: 0.027291054251055498\n",
      "Iteration: 3599 lambda_k: 1 Loss: 0.0272616128727816\n",
      "Iteration: 3600 lambda_k: 1 Loss: 0.02723217953665932\n",
      "Iteration: 3601 lambda_k: 1 Loss: 0.0272027542408809\n",
      "Iteration: 3602 lambda_k: 1 Loss: 0.027173336983637338\n",
      "Iteration: 3603 lambda_k: 1 Loss: 0.027143927763118168\n",
      "Iteration: 3604 lambda_k: 1 Loss: 0.02711452657751172\n",
      "Iteration: 3605 lambda_k: 1 Loss: 0.027085133425005015\n",
      "Iteration: 3606 lambda_k: 1 Loss: 0.02705574830378382\n",
      "Iteration: 3607 lambda_k: 1 Loss: 0.027026371212032718\n",
      "Iteration: 3608 lambda_k: 1 Loss: 0.026997002147934934\n",
      "Iteration: 3609 lambda_k: 1 Loss: 0.026967641109672626\n",
      "Iteration: 3610 lambda_k: 1 Loss: 0.026938288095426557\n",
      "Iteration: 3611 lambda_k: 1 Loss: 0.026908943103376486\n",
      "Iteration: 3612 lambda_k: 1 Loss: 0.026879606131700828\n",
      "Iteration: 3613 lambda_k: 1 Loss: 0.02685027717857691\n",
      "Iteration: 3614 lambda_k: 1 Loss: 0.026820956242180907\n",
      "Iteration: 3615 lambda_k: 1 Loss: 0.026791643320687838\n",
      "Iteration: 3616 lambda_k: 1 Loss: 0.026762338412271533\n",
      "Iteration: 3617 lambda_k: 1 Loss: 0.02673304151510474\n",
      "Iteration: 3618 lambda_k: 1 Loss: 0.02670375262735917\n",
      "Iteration: 3619 lambda_k: 1 Loss: 0.02667447174720527\n",
      "Iteration: 3620 lambda_k: 1 Loss: 0.02664519887281259\n",
      "Iteration: 3621 lambda_k: 1 Loss: 0.026615934002349424\n",
      "Iteration: 3622 lambda_k: 1 Loss: 0.02658667713398316\n",
      "Iteration: 3623 lambda_k: 1 Loss: 0.026557428265880065\n",
      "Iteration: 3624 lambda_k: 1 Loss: 0.026528187396205414\n",
      "Iteration: 3625 lambda_k: 1 Loss: 0.026498954523123414\n",
      "Iteration: 3626 lambda_k: 1 Loss: 0.026469729644797366\n",
      "Iteration: 3627 lambda_k: 1 Loss: 0.026440512759389335\n",
      "Iteration: 3628 lambda_k: 1 Loss: 0.026411303865060687\n",
      "Iteration: 3629 lambda_k: 1 Loss: 0.026382102959971638\n",
      "Iteration: 3630 lambda_k: 1 Loss: 0.02635291004228149\n",
      "Iteration: 3631 lambda_k: 1 Loss: 0.026323725110148563\n",
      "Iteration: 3632 lambda_k: 1 Loss: 0.026294548161730238\n",
      "Iteration: 3633 lambda_k: 1 Loss: 0.026265379195183063\n",
      "Iteration: 3634 lambda_k: 1 Loss: 0.02623621820866254\n",
      "Iteration: 3635 lambda_k: 1 Loss: 0.026207065200323332\n",
      "Iteration: 3636 lambda_k: 1 Loss: 0.02617792016831927\n",
      "Iteration: 3637 lambda_k: 1 Loss: 0.026148783110803157\n",
      "Iteration: 3638 lambda_k: 1 Loss: 0.026119654025927072\n",
      "Iteration: 3639 lambda_k: 1 Loss: 0.026090532911842126\n",
      "Iteration: 3640 lambda_k: 1 Loss: 0.026061419766698655\n",
      "Iteration: 3641 lambda_k: 1 Loss: 0.02603231458864612\n",
      "Iteration: 3642 lambda_k: 1 Loss: 0.026003217375833176\n",
      "Iteration: 3643 lambda_k: 1 Loss: 0.025974128126407627\n",
      "Iteration: 3644 lambda_k: 1 Loss: 0.02594504683851651\n",
      "Iteration: 3645 lambda_k: 1 Loss: 0.02591597351030607\n",
      "Iteration: 3646 lambda_k: 1 Loss: 0.025886908139921797\n",
      "Iteration: 3647 lambda_k: 1 Loss: 0.025857850725508346\n",
      "Iteration: 3648 lambda_k: 1 Loss: 0.02582880126520967\n",
      "Iteration: 3649 lambda_k: 1 Loss: 0.025799759757168944\n",
      "Iteration: 3650 lambda_k: 1 Loss: 0.025770726199528686\n",
      "Iteration: 3651 lambda_k: 1 Loss: 0.025741700590430506\n",
      "Iteration: 3652 lambda_k: 1 Loss: 0.02571268292801549\n",
      "Iteration: 3653 lambda_k: 1 Loss: 0.02568367321042395\n",
      "Iteration: 3654 lambda_k: 1 Loss: 0.025654671435795456\n",
      "Iteration: 3655 lambda_k: 1 Loss: 0.025625677602268925\n",
      "Iteration: 3656 lambda_k: 1 Loss: 0.02559669170798261\n",
      "Iteration: 3657 lambda_k: 1 Loss: 0.025567713751074198\n",
      "Iteration: 3658 lambda_k: 1 Loss: 0.025538743729680524\n",
      "Iteration: 3659 lambda_k: 1 Loss: 0.025509781641937908\n",
      "Iteration: 3660 lambda_k: 1 Loss: 0.025480827485982075\n",
      "Iteration: 3661 lambda_k: 1 Loss: 0.025451881259948038\n",
      "Iteration: 3662 lambda_k: 1 Loss: 0.025422942961970254\n",
      "Iteration: 3663 lambda_k: 1 Loss: 0.025394012590182525\n",
      "Iteration: 3664 lambda_k: 1 Loss: 0.0253650901427181\n",
      "Iteration: 3665 lambda_k: 1 Loss: 0.02533617561770969\n",
      "Iteration: 3666 lambda_k: 1 Loss: 0.025307269013289342\n",
      "Iteration: 3667 lambda_k: 1 Loss: 0.025278370327588666\n",
      "Iteration: 3668 lambda_k: 1 Loss: 0.025249479558738568\n",
      "Iteration: 3669 lambda_k: 1 Loss: 0.02522059670486959\n",
      "Iteration: 3670 lambda_k: 1 Loss: 0.02519172176411162\n",
      "Iteration: 3671 lambda_k: 1 Loss: 0.025162854734594092\n",
      "Iteration: 3672 lambda_k: 1 Loss: 0.02513399561444592\n",
      "Iteration: 3673 lambda_k: 1 Loss: 0.02510514440179545\n",
      "Iteration: 3674 lambda_k: 1 Loss: 0.025076301094770628\n",
      "Iteration: 3675 lambda_k: 1 Loss: 0.025047465691498804\n",
      "Iteration: 3676 lambda_k: 1 Loss: 0.025018638190107027\n",
      "Iteration: 3677 lambda_k: 1 Loss: 0.024989818588721742\n",
      "Iteration: 3678 lambda_k: 1 Loss: 0.024961006885469057\n",
      "Iteration: 3679 lambda_k: 1 Loss: 0.024932203078474505\n",
      "Iteration: 3680 lambda_k: 1 Loss: 0.02490340716586326\n",
      "Iteration: 3681 lambda_k: 1 Loss: 0.024874619145760137\n",
      "Iteration: 3682 lambda_k: 1 Loss: 0.02484583901628949\n",
      "Iteration: 3683 lambda_k: 1 Loss: 0.02481706677557521\n",
      "Iteration: 3684 lambda_k: 1 Loss: 0.024788302421740863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 3685 lambda_k: 1 Loss: 0.024759545952909592\n",
      "Iteration: 3686 lambda_k: 1 Loss: 0.024730797367204196\n",
      "Iteration: 3687 lambda_k: 1 Loss: 0.024702056662747073\n",
      "Iteration: 3688 lambda_k: 1 Loss: 0.024673323837660303\n",
      "Iteration: 3689 lambda_k: 1 Loss: 0.02464459889006563\n",
      "Iteration: 3690 lambda_k: 1 Loss: 0.024615881818084367\n",
      "Iteration: 3691 lambda_k: 1 Loss: 0.02458717261983759\n",
      "Iteration: 3692 lambda_k: 1 Loss: 0.024558471293446096\n",
      "Iteration: 3693 lambda_k: 1 Loss: 0.0245297778370302\n",
      "Iteration: 3694 lambda_k: 1 Loss: 0.024501092248710107\n",
      "Iteration: 3695 lambda_k: 1 Loss: 0.024472414526605663\n",
      "Iteration: 3696 lambda_k: 1 Loss: 0.024443744668836285\n",
      "Iteration: 3697 lambda_k: 1 Loss: 0.024415082673521382\n",
      "Iteration: 3698 lambda_k: 1 Loss: 0.02438642853877989\n",
      "Iteration: 3699 lambda_k: 1 Loss: 0.024357782262730623\n",
      "Iteration: 3700 lambda_k: 1 Loss: 0.02432914384349203\n",
      "Iteration: 3701 lambda_k: 1 Loss: 0.024300513279182336\n",
      "Iteration: 3702 lambda_k: 1 Loss: 0.024271890567919632\n",
      "Iteration: 3703 lambda_k: 1 Loss: 0.02424327570782178\n",
      "Iteration: 3704 lambda_k: 1 Loss: 0.02421466869700627\n",
      "Iteration: 3705 lambda_k: 1 Loss: 0.024186069533590593\n",
      "Iteration: 3706 lambda_k: 1 Loss: 0.02415747821569194\n",
      "Iteration: 3707 lambda_k: 1 Loss: 0.02412889474142729\n",
      "Iteration: 3708 lambda_k: 1 Loss: 0.024100319108913484\n",
      "Iteration: 3709 lambda_k: 1 Loss: 0.02407175131626724\n",
      "Iteration: 3710 lambda_k: 1 Loss: 0.024043191361605095\n",
      "Iteration: 3711 lambda_k: 1 Loss: 0.02401463924304338\n",
      "Iteration: 3712 lambda_k: 1 Loss: 0.023986094958698287\n",
      "Iteration: 3713 lambda_k: 1 Loss: 0.023957558506685926\n",
      "Iteration: 3714 lambda_k: 1 Loss: 0.023929029885122285\n",
      "Iteration: 3715 lambda_k: 1 Loss: 0.023900509092123164\n",
      "Iteration: 3716 lambda_k: 1 Loss: 0.023871996125804328\n",
      "Iteration: 3717 lambda_k: 1 Loss: 0.023843490984281433\n",
      "Iteration: 3718 lambda_k: 1 Loss: 0.023814993665670005\n",
      "Iteration: 3719 lambda_k: 1 Loss: 0.023786504168085452\n",
      "Iteration: 3720 lambda_k: 1 Loss: 0.023758022489643215\n",
      "Iteration: 3721 lambda_k: 1 Loss: 0.02372954862845858\n",
      "Iteration: 3722 lambda_k: 1 Loss: 0.02370108258264684\n",
      "Iteration: 3723 lambda_k: 1 Loss: 0.023672624350323114\n",
      "Iteration: 3724 lambda_k: 1 Loss: 0.023644173929602653\n",
      "Iteration: 3725 lambda_k: 1 Loss: 0.02361573131860058\n",
      "Iteration: 3726 lambda_k: 1 Loss: 0.02358729651543202\n",
      "Iteration: 3727 lambda_k: 1 Loss: 0.023558869518212032\n",
      "Iteration: 3728 lambda_k: 1 Loss: 0.023530450325055716\n",
      "Iteration: 3729 lambda_k: 1 Loss: 0.023502038934078123\n",
      "Iteration: 3730 lambda_k: 1 Loss: 0.023473635343394396\n",
      "Iteration: 3731 lambda_k: 1 Loss: 0.02344523955111956\n",
      "Iteration: 3732 lambda_k: 1 Loss: 0.023416851555368805\n",
      "Iteration: 3733 lambda_k: 1 Loss: 0.02338847135425724\n",
      "Iteration: 3734 lambda_k: 1 Loss: 0.02336009894590012\n",
      "Iteration: 3735 lambda_k: 1 Loss: 0.023331734328412627\n",
      "Iteration: 3736 lambda_k: 1 Loss: 0.02330337749991005\n",
      "Iteration: 3737 lambda_k: 1 Loss: 0.0232750284585078\n",
      "Iteration: 3738 lambda_k: 1 Loss: 0.02324668720232131\n",
      "Iteration: 3739 lambda_k: 1 Loss: 0.023218353729466054\n",
      "Iteration: 3740 lambda_k: 1 Loss: 0.023190028038057652\n",
      "Iteration: 3741 lambda_k: 1 Loss: 0.023161710126211762\n",
      "Iteration: 3742 lambda_k: 1 Loss: 0.0231333999920442\n",
      "Iteration: 3743 lambda_k: 1 Loss: 0.023105097633670874\n",
      "Iteration: 3744 lambda_k: 1 Loss: 0.02307680304920777\n",
      "Iteration: 3745 lambda_k: 1 Loss: 0.023048516236771094\n",
      "Iteration: 3746 lambda_k: 1 Loss: 0.02302023719447711\n",
      "Iteration: 3747 lambda_k: 1 Loss: 0.02299196592044225\n",
      "Iteration: 3748 lambda_k: 1 Loss: 0.0229637024127831\n",
      "Iteration: 3749 lambda_k: 1 Loss: 0.022935446669616322\n",
      "Iteration: 3750 lambda_k: 1 Loss: 0.022907198689058866\n",
      "Iteration: 3751 lambda_k: 1 Loss: 0.022878958469227845\n",
      "Iteration: 3752 lambda_k: 1 Loss: 0.02285072600824045\n",
      "Iteration: 3753 lambda_k: 1 Loss: 0.022822501304214107\n",
      "Iteration: 3754 lambda_k: 1 Loss: 0.022794284355266505\n",
      "Iteration: 3755 lambda_k: 1 Loss: 0.022766075159515415\n",
      "Iteration: 3756 lambda_k: 1 Loss: 0.022737873715078932\n",
      "Iteration: 3757 lambda_k: 1 Loss: 0.02270968002007532\n",
      "Iteration: 3758 lambda_k: 1 Loss: 0.022681494072623102\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# DY\u001b[39;00m\n\u001b[0;32m      3\u001b[0m dy \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 4\u001b[0m DY_list, DY_f_list, DY_z_list, Dual_DY_list, iterations_DY   \u001b[38;5;241m=\u001b[39m \u001b[43mDY\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDavis_Yin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrobenius_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGrad_Phi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mx3\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSigma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m fin \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m      7\u001b[0m Times[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDY\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m fin \u001b[38;5;241m-\u001b[39m dy\n",
      "File \u001b[1;32m~\\OneDrive\\Documentos\\Memoria Alan - Codigos\\Codigos\\davisyin.py:124\u001b[0m, in \u001b[0;36mDavis_Yin\u001b[1;34m(N, M, frobenius_norm, cost_function, Demanda, sol_teo, P)\u001b[0m\n\u001b[0;32m    120\u001b[0m Loss2 \u001b[38;5;241m=\u001b[39m Loss1\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m#(xg1_k, xg2_k, xg3_k), (xf1_k, xf2_k, xf3_k), (z1, z2, z3), (lambda1, lambda2) = Davis_Yin_iteration(z1_k, z2_k, z3_k, cost_function, gamma, lambda_k, Demanda, P)\u001b[39;00m\n\u001b[1;32m--> 124\u001b[0m (xg1_k, xg2_k, xg3_k), (xf1_k, xf2_k, xf3_k), (z1, z2, z3), (lambda1, lambda2) \u001b[38;5;241m=\u001b[39m \u001b[43mDavis_Yin_iteration_pyomo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz1_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz2_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz3_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcost_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_k\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDemanda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    127\u001b[0m Loss1 \u001b[38;5;241m=\u001b[39m norm_adjusted((xg1_k, xg2_k, xg3_k), sol_teo, P, M)\n\u001b[0;32m    128\u001b[0m Loss1 \u001b[38;5;241m=\u001b[39m Loss1\u001b[38;5;241m/\u001b[39mnorm_adjusted(sol_teo, (np\u001b[38;5;241m.\u001b[39mzeros((N,\u001b[38;5;241m1\u001b[39m)),np\u001b[38;5;241m.\u001b[39mzeros((N,M)),np\u001b[38;5;241m.\u001b[39mzeros((N,M))), P, M)\n",
      "File \u001b[1;32m~\\OneDrive\\Documentos\\Memoria Alan - Codigos\\Codigos\\davisyin.py:69\u001b[0m, in \u001b[0;36mDavis_Yin_iteration_pyomo\u001b[1;34m(z1, z2, z3, gradient_of_h, gamma, lambda_k, Demanda, P)\u001b[0m\n\u001b[0;32m     66\u001b[0m grad_x1, grad_x2, grad_x3 \u001b[38;5;241m=\u001b[39m gradient_of_h(xg_1, xg_2, xg_3, P)\n\u001b[0;32m     68\u001b[0m xf_1                \u001b[38;5;241m=\u001b[39m             \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39mxg_1 \u001b[38;5;241m-\u001b[39m z1 \u001b[38;5;241m-\u001b[39m gamma\u001b[38;5;241m*\u001b[39mgrad_x1\n\u001b[1;32m---> 69\u001b[0m xf_2, xf_3, lambda2 \u001b[38;5;241m=\u001b[39m \u001b[43mpro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mP_C_pyo\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxg_2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mz2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgrad_x2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxg_3\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mz3\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgrad_x3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDemanda\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# _, _, lambda2 = pro.P_C_pyo(xg_2, xg_3, P, Demanda, gamma)\u001b[39;00m\n\u001b[0;32m     74\u001b[0m z1 \u001b[38;5;241m=\u001b[39m z1 \u001b[38;5;241m+\u001b[39m lambda_k\u001b[38;5;241m*\u001b[39m(xf_1 \u001b[38;5;241m-\u001b[39m xg_1)\n",
      "File \u001b[1;32m~\\OneDrive\\Documentos\\Memoria Alan - Codigos\\Codigos\\proyecciones.py:385\u001b[0m, in \u001b[0;36mP_C_pyo\u001b[1;34m(x2_, x3_, P, D, gamma, show)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m###########################\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# Solver\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m###########################\u001b[39;00m\n\u001b[0;32m    384\u001b[0m opt \u001b[38;5;241m=\u001b[39m SolverFactory(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mipopt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 385\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtee\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \n\u001b[0;32m    387\u001b[0m \u001b[38;5;66;03m###########################\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# Display\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;66;03m###########################\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Memoria_20240324\\lib\\site-packages\\pyomo\\opt\\base\\solvers.py:609\u001b[0m, in \u001b[0;36mOptSolver.solve\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    607\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_callbacks(_model)\n\u001b[1;32m--> 609\u001b[0m _status \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_solver\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_transformation_data\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformation_data\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Memoria_20240324\\lib\\site-packages\\pyomo\\opt\\solver\\shellcmd.py:267\u001b[0m, in \u001b[0;36mSystemCallSolver._apply_solver\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolver problem files: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_problem_files))\n\u001b[0;32m    266\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m--> 267\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rc, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_command\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_command\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    268\u001b[0m sys\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Bunch(rc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rc, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Memoria_20240324\\lib\\site-packages\\pyomo\\opt\\solver\\shellcmd.py:335\u001b[0m, in \u001b[0;36mSystemCallSolver._execute_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    334\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m TeeStream(\u001b[38;5;241m*\u001b[39mostreams) \u001b[38;5;28;01mas\u001b[39;00m t:\n\u001b[1;32m--> 335\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m            \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTDOUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTDERR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m            \u001b[49m\u001b[43muniversal_newlines\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcwd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcwd\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcwd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    345\u001b[0m         t\u001b[38;5;241m.\u001b[39mSTDOUT\u001b[38;5;241m.\u001b[39mflush()\n\u001b[0;32m    346\u001b[0m         t\u001b[38;5;241m.\u001b[39mSTDERR\u001b[38;5;241m.\u001b[39mflush()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Memoria_20240324\\lib\\subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    504\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 505\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[43mprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    507\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Memoria_20240324\\lib\\subprocess.py:1146\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[1;34m(self, input, timeout)\u001b[0m\n\u001b[0;32m   1144\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1146\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1148\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Memoria_20240324\\lib\\subprocess.py:1209\u001b[0m, in \u001b[0;36mPopen.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1207\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1209\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1211\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[0;32m   1212\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[0;32m   1213\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[0;32m   1214\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[0;32m   1215\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\envs\\Memoria_20240324\\lib\\subprocess.py:1506\u001b[0m, in \u001b[0;36mPopen._wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1503\u001b[0m     timeout_millis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(timeout \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1505\u001b[0m     \u001b[38;5;66;03m# API note: Returns immediately if timeout_millis == 0.\u001b[39;00m\n\u001b[1;32m-> 1506\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWaitForSingleObject\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1507\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mtimeout_millis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1508\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;241m==\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mWAIT_TIMEOUT:\n\u001b[0;32m   1509\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, timeout)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# DY\n",
    "    \n",
    "dy = time.time()\n",
    "DY_list, DY_f_list, DY_z_list, Dual_DY_list, iterations_DY   = DY.Davis_Yin(N, M, frobenius_norm, Grad_Phi, D, (x1,x2,x3), Sigma)\n",
    "fin = time.time()\n",
    "\n",
    "Times[\"DY\"] = fin - dy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f81b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_ = -1 # Minimo en 96633\n",
    "print(f\"Iterations:\\n{iterations_DY}\")\n",
    "print(\"Primal: (x1,x2,x3)\\n\",DY_list[iter_])\n",
    "print(\"Primal: (xf1,xf2,xf3)\\n\",DY_f_list[iter_])\n",
    "print(\"Primal: (z1,z2,z3)\\n\",DY_z_list[iter_])\n",
    "print(\"Dual: (Capacity, Equilibrium)\\n\",Dual_DY_list[iter_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e17b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BA    \n",
    "ba = time.time()\n",
    "x_BA_list, z_BA_list, dual_BA_list, iterations_BA   = BA.Briceno_Arias(N, M, frobenius_norm, Grad_Phi_NA, Sigma, D, (x1,x2,x3),gamma=1e-3, lambdan=1e-3)\n",
    "fin = time.time()\n",
    "\n",
    "Times[\"BA\"] = fin - ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a2ff12",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_ = -2\n",
    "print(\"Iterations:\\n\",iterations_BA)\n",
    "print(\"Primal: (x1,x2,x3)\\n\", x_BA_list[iter_])\n",
    "print(\"Primal: (z1,z2,z3)\\n\", z_BA_list[iter_])\n",
    "print(\"Dual: (Capacity, Equilibrium)\\n\",dual_BA_list[iter_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a848c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adm = time.time()\n",
    "ADMM_list, dual_ADMM_list, iterations_ADMM = admm.ADMM(N, M, (Q1,B1), (Q2,B2), (Q3,B3), Sigma, D, e1, e2, e31, e32, (x1,x2,x3), 1)\n",
    "fin = time.time()\n",
    "\n",
    "Times[\"ADMM\"] = fin - adm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4b857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_ = -2\n",
    "print(\"Iterations:\",iterations_ADMM)\n",
    "print(\"Primal: (x1,x2,x3),(y1,y2,y3),(z1,z2,z3)\\n\",ADMM_list[iter_])\n",
    "print(\"Dual: (Equilibrium)\\n\",dual_ADMM_list[iter_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d7890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iters_list = max([iterations_DY,iterations_BA,iterations_ADMM])\n",
    "max_iters_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8240e72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_adjusted(x_sol, x_teo, sigma):\n",
    "    x_sol_1, x_sol_2, x_sol_3 = x_sol\n",
    "    x_teo_1, x_teo_2, x_teo_3 = x_teo\n",
    "    sigma=sigma[0]\n",
    "    \n",
    "    return LA.norm(x_sol_1-x_teo_1) + sum([sigma[xi]*LA.norm(x_sol_2[:,xi]-x_teo_2[:,xi]) for xi in range(M)]) + sum([sigma[xi]*LA.norm(x_sol_3[:,xi]-x_teo_3[:,xi]) for xi in range(M)])\n",
    "\n",
    "\n",
    "def norm_adjusted_N(x_sol, x_teo, sigma):\n",
    "    x_sol_1, x_sol_2, x_sol_3 = x_sol\n",
    "    x_teo_1, x_teo_2, x_teo_3 = x_teo\n",
    "    sigma=sigma[0]\n",
    "    \n",
    "    return sum([sigma[xi]*LA.norm(x_sol_1[:,xi][:,np.newaxis]-x_teo_1) for xi in range(M)]) + sum([sigma[xi]*LA.norm(x_sol_2[:,xi]-x_teo_2[:,xi]) for xi in range(M)]) + sum([sigma[xi]*LA.norm(x_sol_3[:,xi]-x_teo_3[:,xi]) for xi in range(M)])\n",
    "\n",
    "\n",
    "\n",
    "def generate_list(lista, lista_2, algoritmo, solution, objective_function, Demanda, max_iterations, P):\n",
    "\n",
    "    # unpack solution\n",
    "    x1, x2, x3 = solution\n",
    "\n",
    "    # create a list with index of graphics\n",
    "    iterations = list(range(max_iterations))\n",
    "\n",
    "    # create list to return\n",
    "    x_solution     = []\n",
    "    Fx_solution    = []\n",
    "    Non_anti_sol   = []\n",
    "    equili_solut   = []\n",
    "    capacity_solut = []\n",
    "    demand_solu    = []\n",
    "    dual_solut     = []\n",
    "    \n",
    "    zero_1 = np.zeros((N,1))\n",
    "    zero_1_N = np.zeros((N,M))\n",
    "    zero_2 = np.zeros((N,M))\n",
    "    zero_3 = np.zeros((1,M))\n",
    "    zeroo = (zero_1, zero_2, zero_3)\n",
    "    zeroo_N = (zero_1_N, zero_2, zero_3)\n",
    "    \n",
    "    # create arrays for each graph\n",
    "\n",
    "    if algoritmo == \"DY\":\n",
    "        for x_algo, x_fact in lista:\n",
    "            x1_algo, x2_algo, x3_algo = x_algo\n",
    "            x_solution.append( norm_adjusted(x_algo, (x1,x2,x3), P)/norm_adjusted((x1,x2,x3), zeroo, P) )\n",
    "            Fx_solution.append( abs(objective_function(x1_algo, x2_algo, x3_algo)[0][0] - objective_function(x1, x2, x3)[0][0] )/abs(objective_function(x1, x2, x3)[0][0]) )\n",
    "            Non_anti_sol.append( LA.norm(x1_algo - np.roll(x1_algo, 1, axis=1)) ) #No aplica a DY\n",
    "            equili_solut.append( norm_adjusted((zero_1,zero_2,x2_algo.sum(axis=0) - (D - x3_algo)), zeroo, P) )\n",
    "            capacity_solut.append( norm_adjusted((zero_1,x1_algo - x2_algo,zero_3), zeroo, P) )\n",
    "            demand_solu.append(norm_adjusted((zero_1,zero_2,D - x3_algo), zeroo, P))\n",
    "\n",
    "        for lambda1, lambda2 in lista_2:\n",
    "            dual_solut.append(norm_adjusted((zero_1,zero_2,rho - lambda2),zeroo,P)/norm_adjusted((zero_1,zero_2,rho),zeroo,P))\n",
    "    \n",
    "\n",
    "    elif algoritmo == \"ADMM\":\n",
    "        for elemento in lista:\n",
    "            x1_algo, x2_algo, x3_algo = elemento[0]\n",
    "            x_solution.append( norm_adjusted_N((x1_algo, x2_algo, x3_algo), (x1,x2,x3), P)/norm_adjusted((x1,x2,x3), zeroo, P) )\n",
    "            Fx_solution.append( abs(objective_function(x1_algo, x2_algo, x3_algo)[0][0] - objective_function(x1, x2, x3)[0][0] )/abs(objective_function(x1, x2, x3)[0][0]) )\n",
    "            Non_anti_sol.append( norm_adjusted_N((x1_algo - np.roll(x1_algo, 1, axis=1),zero_2, zero_3), zeroo, P) ) #No aplica a DY\n",
    "            equili_solut.append( norm_adjusted_N((zero_1_N,zero_2,x2_algo.sum(axis=0) - (D - x3_algo)), zeroo, P) )\n",
    "            capacity_solut.append( norm_adjusted_N((zero_1_N,x1_algo - x2_algo,zero_3), zeroo, P) )\n",
    "            demand_solu.append(norm_adjusted_N((zero_1_N,zero_2,D - x3_algo), zeroo, P))\n",
    "\n",
    "        for lambda2 in lista_2:\n",
    "            dual_solut.append(norm_adjusted_N((zero_1_N,zero_2,rho - lambda2),zeroo,P)/norm_adjusted((zero_1,zero_2,rho),zeroo,P))\n",
    "\n",
    "\n",
    "    elif algoritmo == \"BA\":\n",
    "        for x_algo, x_fact in lista:\n",
    "            x1_algo, x2_algo, x3_algo = x_algo\n",
    "            x_solution.append( norm_adjusted_N((x1_algo, x2_algo, x3_algo), (x1,x2,x3), P)/norm_adjusted((x1,x2,x3), zeroo, P) )\n",
    "            Fx_solution.append( abs(objective_function(x1_algo, x2_algo, x3_algo)[0][0] - objective_function(x1, x2, x3)[0][0] )/abs(objective_function(x1, x2, x3)[0][0]) )\n",
    "            Non_anti_sol.append( norm_adjusted_N((x1_algo - np.roll(x1_algo, 1, axis=1),zero_2, zero_3), zeroo, P) ) #No aplica a DY\n",
    "            equili_solut.append( norm_adjusted_N((zero_1_N,zero_2,x2_algo.sum(axis=0) - (D - x3_algo)), zeroo, P) )\n",
    "            capacity_solut.append( norm_adjusted_N((zero_1_N,x1_algo - x2_algo,zero_3), zeroo, P) )\n",
    "            demand_solu.append(norm_adjusted_N((zero_1_N,zero_2,D - x3_algo), zeroo, P))\n",
    "            \n",
    "        \n",
    "        for lambda1, lambda2 in lista_2:\n",
    "            dual_solut.append(norm_adjusted_N((zero_1_N,zero_2,rho - lambda2),zeroo,P)/norm_adjusted((zero_1,zero_2,rho),zeroo,P))\n",
    "            \n",
    "    \n",
    "    print(\"Completando listas\")\n",
    "    \n",
    "    x_solution     = x_solution     + [None]*(max_iterations-len(lista))\n",
    "    Fx_solution    = Fx_solution    + [None]*(max_iterations-len(lista))\n",
    "    Non_anti_sol   = Non_anti_sol   + [None]*(max_iterations-len(lista))\n",
    "    equili_solut   = equili_solut   + [None]*(max_iterations-len(lista))\n",
    "    capacity_solut = capacity_solut + [None]*(max_iterations-len(lista))\n",
    "    demand_solu    = demand_solu    + [None]*(max_iterations-len(lista))\n",
    "    dual_solut     = dual_solut     + [None]*(max_iterations-len(lista))\n",
    "\n",
    "    k = 0\n",
    "\n",
    "    return iterations[k:], x_solution[k:], Fx_solution[k:], Non_anti_sol[k:], equili_solut[k:], capacity_solut[k:], demand_solu[k:], dual_solut[k:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9094918c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"DY\")\n",
    "iter_DY, x_DY_sol, Fx_DY_sol, Non_anti_DY, equili_DY_solu, capacity_DY_solu, demand_DY_sol, dual_DY_sol = generate_list(DY_list, Dual_DY_list, \"DY\", (x1, x2, x3), objective_function, D, max_iters_list, Sigma)\n",
    "print(\"ADMM\")\n",
    "iter_ADMM, x_ADMM_sol, Fx_ADMM_sol, Non_anti_ADMM, equili_ADMM_solu, capacity_ADMM_solu, demand_ADMM_sol, dual_ADMM_sol  = generate_list(ADMM_list, dual_ADMM_list, \"ADMM\", (x1, x2, x3), objective_function, D, max_iters_list, Sigma)\n",
    "print(\"BA\")\n",
    "iter_BA, x_BA_sol, Fx_BA_sol, Non_anti_BA, equili_BA_solu, capacity_BA_solu, demand_BA_sol, BA_dual_sol = generate_list(x_BA_list, dual_BA_list, \"BA\", (x1, x2, x3), objective_function, D, max_iters_list, Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba168274",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Crear un rango de iteraciones para las gráficas\n",
    "k = 0\n",
    "l = int(max_iters_list / 1) + 1\n",
    "\n",
    "zero_1 = np.zeros((N,1))\n",
    "zero_2 = np.zeros((N,M))\n",
    "zero_3 = np.zeros((1,M))\n",
    "zeroo = (zero_1, zero_2, zero_3)\n",
    "\n",
    "# Definir los niveles teóricos según tu solución teórica\n",
    "nivel_teorico_equilibrio = norm_adjusted((zero_1,zero_2,x2.sum(axis=0) - (D - x3)), zeroo, Sigma)\n",
    "nivel_teorico_capacidad = norm_adjusted((zero_1,x1 - x2,zero_3), zeroo, Sigma)\n",
    "nivel_teorico_demanda = norm_adjusted((zero_1,zero_2,D - x3), zeroo, Sigma)\n",
    "\n",
    "# Variable de sufijo para los nombres de archivo\n",
    "suffix = \"_3\"\n",
    "\n",
    "# Función para configurar y guardar cada gráfico\n",
    "def configurar_grafico(ax, x_data, y_data, labels, colors, title, y_label, width, height, y_lim=None, nivel_teorico=None):\n",
    "    for x, y, label, color in zip(x_data, y_data, labels, colors):\n",
    "        ax.plot(x[k:l], y[k:l], '-', linewidth=1.5, label=label, color=color)\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_xlabel('Iteraciones')\n",
    "    ax.legend()\n",
    "    if y_lim:\n",
    "        ax.set_ylim(y_lim)\n",
    "    if nivel_teorico is not None:\n",
    "        ax.axhline(y=nivel_teorico, color='gray', linestyle='--', linewidth=1)\n",
    "    ax.figure.set_figwidth(width)\n",
    "    ax.figure.set_figheight(height)\n",
    "\n",
    "# Datos para los gráficos\n",
    "iter_data = [iter_DY, iter_ADMM, iter_BA]\n",
    "labels = ['OPSS', 'ADMM', 'FPIS']\n",
    "colors = ['green', 'blue', 'red']\n",
    "\n",
    "# Definir la altura y el ancho deseado para cada gráfico\n",
    "width = 10  # Ajusta esta variable según sea necesario\n",
    "height = 3  # Ajusta esta variable según sea necesario\n",
    "\n",
    "# Crear y guardar cada figura individualmente\n",
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "configurar_grafico(ax, iter_data, [x_DY_sol, x_ADMM_sol, x_BA_sol], labels, colors, 'Distancia al Óptimo', \n",
    "                   r'$\\frac{\\|x^{k} - x^{*}\\|}{\\|x^{*}\\|}$', width, height, y_lim=(0, 1))\n",
    "plt.savefig(f'images/caso{suffix}/distancia_al_optimo{suffix}.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "configurar_grafico(ax, iter_data, [Fx_DY_sol, Fx_ADMM_sol, Fx_BA_sol], labels, colors, 'Diferencia Valor Función Objetivo', \n",
    "                   r'$\\|f(x^{k})-f(x^{*})\\|$', width, height, y_lim=(0, 1))\n",
    "plt.savefig(f'images/caso{suffix}/diferencia_valor_funcion_objetivo{suffix}.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "configurar_grafico(ax, iter_data[1:], [Non_anti_DY, Non_anti_ADMM, Non_anti_BA][1:], labels[1:], colors[1:], 'No-Anticipatividad', \n",
    "                   r'$\\|c^{k}-P_{\\mathcal{N}}(c^{k})\\|$', width, height)#, y_lim=(0, 25))\n",
    "plt.savefig(f'images/caso{suffix}/no_anticipatividad{suffix}.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "configurar_grafico(ax, iter_data, [equili_DY_solu, equili_ADMM_solu, equili_BA_solu], labels, colors, 'Restricción de Equilibrio', \n",
    "                   r'$\\|\\textbf{1}^{T}g^{k}-(D-q^{k})\\|$', width, height, y_lim=(-0.1, 1.0), nivel_teorico=nivel_teorico_equilibrio)\n",
    "plt.savefig(f'images/caso{suffix}/restriccion_de_equilibrio{suffix}.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "configurar_grafico(ax, iter_data, [capacity_DY_solu, capacity_ADMM_solu, capacity_BA_solu], labels, colors, 'Restricción de Capacidad de Producción', \n",
    "                   r'$\\|c^{k} - g^{k}\\|$', width, height, nivel_teorico=nivel_teorico_capacidad)\n",
    "plt.savefig(f'images/caso{suffix}/restriccion_de_capacidad_de_produccion{suffix}.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "configurar_grafico(ax, iter_data, [demand_DY_sol, demand_ADMM_sol, demand_BA_sol], labels, colors, 'Diferencia de Demanda Satisfecha', \n",
    "                   r'$\\|D-q^{k}\\|$', width, height, y_lim=(0, 4000), nivel_teorico=nivel_teorico_demanda)\n",
    "plt.savefig(f'images/caso{suffix}/diferencia_de_demanda_satisfecha{suffix}.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "configurar_grafico(ax, iter_data, [dual_DY_sol, dual_ADMM_sol, BA_dual_sol], labels, colors, 'Diferencia al Precio Óptimo', \n",
    "                   r'$\\frac{\\|\\rho^{k}-\\rho^{*}\\|}{\\|\\rho^{*}\\|}$', width, height, y_lim=(0, 1))\n",
    "plt.savefig(f'images/caso{suffix}/diferencia_al_precio_optimo{suffix}.png', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0041b318",
   "metadata": {},
   "outputs": [],
   "source": [
    "Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36f3d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_DY[-1], x_DY_sol[-1], Fx_DY_sol[-1], Non_anti_DY[-1], equili_DY_solu[-1], capacity_DY_solu[-1], demand_DY_sol[-1], dual_DY_sol[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb25dc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_BA[-1], x_BA_sol[-1], Fx_BA_sol[-1], Non_anti_BA[-1], equili_BA_solu[-1], capacity_BA_solu[-1], demand_BA_sol[-1], BA_dual_sol[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a81cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_ADMM[-1], x_ADMM_sol[-1], Fx_ADMM_sol[-1], Non_anti_ADMM[-1], equili_ADMM_solu[-1], capacity_ADMM_solu[-1], demand_ADMM_sol[-1], dual_ADMM_sol[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c264f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nivel_teorico_equilibrio, nivel_teorico_capacidad, nivel_teorico_demanda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c622cb5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0405fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
